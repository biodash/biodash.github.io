[{"authors":["admin"],"categories":null,"content":"Jelmer Poelstra started at the MCIC (Molecular and Cellular Imaging Center) in June 2020, where he provides bioinformatics support and education. His background is in evolutionary and population genetics, and most of his research has focused on understanding speciation using genomic approaches.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1616606334,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://biodash.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Jelmer Poelstra started at the MCIC (Molecular and Cellular Imaging Center) in June 2020, where he provides bioinformatics support and education. His background is in evolutionary and population genetics, and most of his research has focused on understanding speciation using genomic approaches.","tags":null,"title":"Jelmer Poelstra","type":"authors"},{"authors":["jessica-cooperstone"],"categories":null,"content":"Jessica Cooperstone is an Assistant Professor in Horticulture and Crop Science, and Food Science and Technology at The Ohio State University working at the intersection of plant science and human nutrition.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1616606334,"objectID":"da60494872ddaf739115b5da033f1fed","permalink":"https://biodash.github.io/authors/jessica-cooperstone/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jessica-cooperstone/","section":"authors","summary":"Jessica Cooperstone is an Assistant Professor in Horticulture and Crop Science, and Food Science and Technology at The Ohio State University working at the intersection of plant science and human nutrition.","tags":null,"title":"Jessica Cooperstone","type":"authors"},{"authors":["michael-broe"],"categories":null,"content":"Michael Broe is a Bioinformatics Research Scientist at the Department of Evolution, Ecology, and Organismal Biology.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1616606334,"objectID":"f515857d0961e2ded569db22cc57c70c","permalink":"https://biodash.github.io/authors/michael-broe/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/michael-broe/","section":"authors","summary":"Michael Broe is a Bioinformatics Research Scientist at the Department of Evolution, Ecology, and Organismal Biology.","tags":null,"title":"Michael Broe","type":"authors"},{"authors":["mike-sovic"],"categories":null,"content":"Mike Sovic is a Bioinformatics Research Scientist at CAPS, the Center for Applied Plant Sciences.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1616606334,"objectID":"e25a3ca217243530f65efb3cd930207b","permalink":"https://biodash.github.io/authors/mike-sovic/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/mike-sovic/","section":"authors","summary":"Mike Sovic is a Bioinformatics Research Scientist at CAPS, the Center for Applied Plant Sciences.","tags":null,"title":"Mike Sovic","type":"authors"},{"authors":["stephen-opiyo"],"categories":null,"content":"Stephen Opiyo is a bioinformatics and biostatistics research scientist at MCIC Columbus.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1616606334,"objectID":"9c82e356b8ac88d63b60055c202796b4","permalink":"https://biodash.github.io/authors/stephen-opiyo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/stephen-opiyo/","section":"authors","summary":"Stephen Opiyo is a bioinformatics and biostatistics research scientist at MCIC Columbus.","tags":null,"title":"Stephen Opiyo","type":"authors"},{"authors":["Mike Sovic"],"categories":null,"content":"\nLearning objectives   Create objects in R Recognize and use R functions Differentiate between some common object classes and data structures in R Read in data from a file Install and load R packages    1 \u0026ndash; Intro Nearly everything you do in R will involve objects, functions, or (often) both. In this session, we\u0026rsquo;ll take a quick look at each of these fundamental components for working in R. In addition, we\u0026rsquo;ll get introduced to R packages (since they\u0026rsquo;ll provide many of the functions you\u0026rsquo;ll use), and also practice reading some data in to R.\n2 \u0026ndash; Objects Objects are things in R to which a name can be assigned. They\u0026rsquo;re created using the assignment operator \u0026ldquo;\u0026lt;-\u0026rdquo;, which can be thought of as an arrow (it\u0026rsquo;s actually two separate characters - the less than symbol and dash) that points whatever is on the right side to a name provided on the left side. For example, running the following three lines of code creates objects named \u0026ldquo;x\u0026rdquo;, \u0026ldquo;y\u0026rdquo;, and \u0026ldquo;z\u0026rdquo;, respectively\u0026hellip;\nx \u0026lt;- 3 + 3 y \u0026lt;- TRUE z \u0026lt;- \"cat\"   If you run these lines in RStudio, you\u0026rsquo;ll see the resulting objects listed in the top right panel. This is really helpful for keeping track of object names, as you\u0026rsquo;ll often create many objects during an R session. Calling the objects returns their values\u0026hellip;\nx #\u0026gt; [1] 6 y #\u0026gt; [1] TRUE z #\u0026gt; [1] \"cat\"   3 \u0026ndash; Functions We\u0026rsquo;ll return to objects shortly, but first, let\u0026rsquo;s take a very basic look at functions, which make up a second really important part of R. You can think of objects as being things in R, while functions do things in R. I\u0026rsquo;ll start by writing a very simple function\u0026hellip;\n#define the function cubed_plus10 \u0026lt;- function(number) \u0026#123; number^3+10 \u0026#125; #apply the function cubed_plus10(4) #\u0026gt; [1] 74   No need to get caught up in details of writing the function right now. A couple important things to recognize at this point\u0026hellip;\n We created a function that took some input - the \u0026lsquo;4\u0026rsquo; in the example above, did something to it, and returned some output. To run the function, we used its name, followed by a set of parentheses. All R functions have that general structure. The parentheses might contain 0, 1, or more items (often referred to as options or arguments).  It\u0026rsquo;s useful to be able to create your own functions. But if that sounds a little advanced to you at this point, you can still do a lot with R even without knowing how to write your own, as there are lots that have already been written for you. A number of commonly-used functions are available as soon as you start an R session - these are often referred to as \u0026ldquo;base R\u0026rdquo; functions.\n#some example base R functions date() #\u0026gt; [1] \"Tue Aug 31 10:24:39 2021\" getwd() #\u0026gt; [1] \"/Users/sovic.1/Desktop/docs/Desktop_clear_4-28-21/S18_dev/biodash.github.io/content/codeclub/S02E02_r-intro_part2\" sqrt(25) #\u0026gt; [1] 5   4 \u0026ndash; Object Classes and Data Structures Now that we have at least a basic idea of R functions, we\u0026rsquo;ll turn attention back to objects (and use functions along the way from here on out). The objects we\u0026rsquo;ve created so far have been pretty simple. Let\u0026rsquo;s revisit the three from above\u0026hellip;\nx #\u0026gt; [1] 6 y #\u0026gt; [1] TRUE z #\u0026gt; [1] \"cat\"   There are lots of different kinds, or classes of objects in R, and behind the scenes, each object that\u0026rsquo;s created is immediately assigned to a class (or possibly multiple classes). There\u0026rsquo;s no real limit to the number of classes that exist, as new ones can be created for specialized cases at any time. But there are a fairly small number of object classes you\u0026rsquo;ll encounter a lot in R, so we\u0026rsquo;ll take a look at some of those now. Let\u0026rsquo;s use the class() function to figure out what class R assigned each of our objects to\u0026hellip;\nclass(x) #\u0026gt; [1] \"numeric\" class(y) #\u0026gt; [1] \"logical\" class(z) #\u0026gt; [1] \"character\"   Some very common object classes you\u0026rsquo;ll encounter\u0026hellip;\n  integer double (numeric) logical character factor   I\u0026rsquo;m going to introduce a new term here that\u0026rsquo;s closely tied to object classes, and that\u0026rsquo;s data structures. Again, there are a small number of data structures you\u0026rsquo;ll work with a lot in R. They include\u0026hellip;\n  Vectors Matrices Data Frames Lists Arrays   Today we\u0026rsquo;ll focus in on two of these - vectors and data frames.\n5 \u0026ndash; Vectors Vectors in R share a couple important characteristics\u0026hellip;\n They\u0026rsquo;re one-dimensional. In other words, they can be defined by a length property, with length zero, one, or more. All elements of a vector must be of the same type, or class. Operations can be performed on vectors - vector recycling rules apply (we\u0026rsquo;ll see this in the breakout exercises next).  The c() function is useful for creating vectors in R. It stands for \u0026ldquo;combine\u0026rdquo;, and allows you to combine multiple items into a single vector object\u0026hellip;\nodds \u0026lt;- c(1,3,5,7,9) animals \u0026lt;- c(\"dog\", \"cat\", \"cow\") #view the objects odds #\u0026gt; [1] 1 3 5 7 9 animals #\u0026gt; [1] \"dog\" \"cat\" \"cow\" #check their class class(odds) #\u0026gt; [1] \"numeric\" class(animals) #\u0026gt; [1] \"character\"    Breakout Rooms I (~10 min.) Exercise 1: Create Vector Objects  Create two objects (vectors) named short_vec and long_vec. To short_vec, assign the integers 1 through 5, and to long_vec, assign the integers 1 through 10. View each of the objects and check their class.\n  Hint (click here)  \nThe colon can be used to define a sequence of integers in R, for example, 1:3 represents the vector 1,2,3.    Solution (click here)  short_vec \u0026lt;- 1:5 long_vec \u0026lt;- 1:10 short_vec #\u0026gt; [1] 1 2 3 4 5 long_vec #\u0026gt; [1] 1 2 3 4 5 6 7 8 9 10 class(short_vec) #\u0026gt; [1] \"integer\" class(long_vec) #\u0026gt; [1] \"integer\"      Exercise 2: Vector Operations/Recycling  Now try adding the two vectors, short_vec and long_vec, together. Assign the result to a new object named vec_sum. Think about and talk through what you expect the result might look like before you execute the code.\n  Hint (click here)  \nBefore R performs an operation on any vectors, the vectors involved must be the same length. If they aren\u0026rsquo;t, the shorter vector is \u0026ldquo;recycled\u0026rdquo; until it matches the length of longer vector. Then the operation is performed.    Solution (click here)  vec_sum \u0026lt;- short_vec + long_vec vec_sum #\u0026gt; [1] 2 4 6 8 10 7 9 11 13 15      Exercise 3: Vector Operations/Recycling II  Just to drive this point on vector recycling home a little more, let\u0026rsquo;s do more operation - this time, subtract 3 (itself a vector of length 1) from short_vec. Again, try to predict what will happen before you run it.\n  Solution (click here)  short_vec - 3 #\u0026gt; [1] -2 -1 0 1 2      Keep in mind that all elements of a vector in R have to be of the same class. This means you typically won\u0026rsquo;t see a vector that looks like\u0026hellip;\nmixed_vector \u0026lt;- c(1, \"cat\", 4, \"dog\", TRUE)   You can create such a vector, but in this case, R will view it as a character vector, meaning, for example, the 1 and 4 won\u0026rsquo;t be treated as numbers, but as characters. Such forcing of an element or object into a specific class is often referred to as coercion. Let\u0026rsquo;s go back to our object \u0026lsquo;x\u0026rsquo;\u0026hellip;\nx #\u0026gt; [1] 6 class(x) #\u0026gt; [1] \"numeric\"   Notice it\u0026rsquo;s assigned as numeric. Let\u0026rsquo;s say we wanted R to see it as an integer (just slightly different in R than numeric)\u0026hellip;\nx \u0026lt;- as.integer(x) class(x) #\u0026gt; [1] \"integer\"   We have used the as.integer() function to coerce x into class integer.\n 6 \u0026ndash; Data Frames Data frames are another data structure in R you\u0026rsquo;ll likely use a lot. Some characteristics of data frames\u0026hellip;\n They have two dimensions (rows, columns) Each variable (column) needs to have the same number of entries. All elements of any one column have to be of the same type/class, but different columns can be of different classes.  A good way to think about a data frame is as being analogous to an Excel spreadsheet, with the caveat that all the columns have the same number of entries, which isn\u0026rsquo;t a requirement in an Excel sheet.\nYou can create a data frame by hand with the data.frame() function, but in many cases, you\u0026rsquo;ll create a data frame in R by reading data in from a file with one of a number of functions that are available for that purpose. Let\u0026rsquo;s try it. Here\u0026rsquo;s a small example dataset I generated in Excel\u0026hellip;\nIt\u0026rsquo;s available at the following address\u0026hellip; https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/data_frame/example_df.tsv\n(In this case, the data set comes from online, but often it will be a file on your computer, and the path to the file works the same way as how you\u0026rsquo;ll use the web address below.)\n Breakout Rooms II (~10 min.) Exercise 4: Reading In A Data Frame  Create an object named \u0026ldquo;data_address\u0026rdquo; that stores the web address for the dataset.\n  Hint (click here)  \nUse the assignment operator and make sure to put the address in quotes to define it as a character string.    Solution (click here)  data_address \u0026lt;- \"https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/data_frame/example_df.tsv\"    Now use the read.table() function to read the dataset in as a data frame. Assign it as an object named \u0026lsquo;exp_data\u0026rsquo; and view it in R.\n  Hint (click here)  \nUse the data_address object as the first argument in the read.table() function.    Solution (click here)  exp_data \u0026lt;- read.table(data_address) exp_data #\u0026gt; V1 V2 V3 V4 #\u0026gt; 1 Age Height_cm Eye_Color Graduated #\u0026gt; 2 22 175.26 Blue TRUE #\u0026gt; 3 67 170.18 Green TRUE #\u0026gt; 4 53 165.1 Blue FALSE #\u0026gt; 5 13 134.62 Brown FALSE #\u0026gt; 6 19 147.32 Green TRUE #\u0026gt; 7 27 185.42 Gray TRUE #\u0026gt; 8 30 190.5 Blue TRUE #\u0026gt; 9 11 144.78 Brown FALSE      Exercise 5: Getting Info About Functions  The column names (header) were read in as the first observation, and default column names (i.e. V1, V2, etc) were added. Take a look at the help page for read.table() by typing ?read.table in your R console, or by searching for \u0026ldquo;read.table\u0026rdquo; in the search box in the Help tab of the lower right RStudio panel. Look through some of the options/arguments and make an adjustment to fix the column names/header, then view the data frame again.\n  Hint (click here)  \nRerun the command, setting \u0026ldquo;header\u0026rdquo; to TRUE, instead of the default FALSE.    Solution (click here)  exp_data \u0026lt;- read.table(data_address, header = TRUE) exp_data #\u0026gt; Age Height_cm Eye_Color Graduated #\u0026gt; 1 22 175.26 Blue TRUE #\u0026gt; 2 67 170.18 Green TRUE #\u0026gt; 3 53 165.10 Blue FALSE #\u0026gt; 4 13 134.62 Brown FALSE #\u0026gt; 5 19 147.32 Green TRUE #\u0026gt; 6 27 185.42 Gray TRUE #\u0026gt; 7 30 190.50 Blue TRUE #\u0026gt; 8 11 144.78 Brown FALSE      Exercise 6: Practicing With Some Functions  Spend a few minutes playing around with some of the following functions and try to figure out what they do by applying them to the exp_data object. If it\u0026rsquo;s not clear, use the help\u0026hellip;\n head() dim() nrow() ncol() names() str() summary()    Solution (click here)  head(exp_data) #\u0026gt; Age Height_cm Eye_Color Graduated #\u0026gt; 1 22 175.26 Blue TRUE #\u0026gt; 2 67 170.18 Green TRUE #\u0026gt; 3 53 165.10 Blue FALSE #\u0026gt; 4 13 134.62 Brown FALSE #\u0026gt; 5 19 147.32 Green TRUE #\u0026gt; 6 27 185.42 Gray TRUE #gives preview of object dim(exp_data) #\u0026gt; [1] 8 4 #returns dimensions (number of row, number of columns) of the object nrow(exp_data) #\u0026gt; [1] 8 #returns number of rows in data frame ncol(exp_data) #\u0026gt; [1] 4 #returns number of columns in data frame names(exp_data) #\u0026gt; [1] \"Age\" \"Height_cm\" \"Eye_Color\" \"Graduated\" #returns vector of column names str(exp_data) #\u0026gt; 'data.frame': 8 obs. of 4 variables: #\u0026gt; $ Age : int 22 67 53 13 19 27 30 11 #\u0026gt; $ Height_cm: num 175 170 165 135 147 ... #\u0026gt; $ Eye_Color: Factor w/ 4 levels \"Blue\",\"Brown\",..: 1 4 1 2 4 3 1 2 #\u0026gt; $ Graduated: logi TRUE TRUE FALSE FALSE TRUE TRUE ... #summarizes the structure of an object summary(exp_data) #\u0026gt; Age Height_cm Eye_Color Graduated  #\u0026gt; Min. :11.00 Min. :134.6 Blue :3 Mode :logical  #\u0026gt; 1st Qu.:17.50 1st Qu.:146.7 Brown:2 FALSE:3  #\u0026gt; Median :24.50 Median :167.6 Gray :1 TRUE :5  #\u0026gt; Mean :30.25 Mean :164.1 Green:2  #\u0026gt; 3rd Qu.:35.75 3rd Qu.:177.8  #\u0026gt; Max. :67.00 Max. :190.5 #provides a summary/summary statistics for individual variables/columns       7 \u0026ndash; R Packages I mentioned above when talking about functions that many have already been written for you, and some are available as soon as you open up R - those that are considered part of \u0026ldquo;base R\u0026rdquo;. All the functions we\u0026rsquo;ve used up to this point are included in that set. But there are lots of other functions available as part of additional packages you can install and load. The two most common places to get packages are the CRAN and Bioconductor repositories - I did a couple short videos on these as part of this Intro To R Playlist.\nAs one example, we used the function read.table() above to read in the example dataset. A similar function, read_tsv() is available as part of the readr package, which is available from CRAN, and so can be installed with the install.packages() function\u0026hellip;\ninstall.packages(\"readr\")   The installation should only have to be done once. Then we use the library() function to load the library in each R session where we want to use it\u0026hellip;\nlibrary(readr) #\u0026gt; Warning: package 'readr' was built under R version 3.6.2   Now we should have access to the readr package and all of the functions contained in it.\nexp_data2 \u0026lt;- read_tsv(data_address) #\u0026gt;  #\u0026gt; ── Column specification ──────────────────────────────────────────────────────── #\u0026gt; cols( #\u0026gt; Age = col_double(), #\u0026gt; Height_cm = col_double(), #\u0026gt; Eye_Color = col_character(), #\u0026gt; Graduated = col_logical() #\u0026gt; ) exp_data2 #\u0026gt; # A tibble: 8 x 4 #\u0026gt; Age Height_cm Eye_Color Graduated #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;lgl\u0026gt;  #\u0026gt; 1 22 175. Blue TRUE  #\u0026gt; 2 67 170. Green TRUE  #\u0026gt; 3 53 165. Blue FALSE  #\u0026gt; 4 13 135. Brown FALSE  #\u0026gt; 5 19 147. Green TRUE  #\u0026gt; 6 27 185. Gray TRUE  #\u0026gt; 7 30 190. Blue TRUE  #\u0026gt; 8 11 145. Brown FALSE   You might notice that exp_data2 is a tibble, while exp_data is a data frame (try the class() function on each). This small difference in the types of objects that are returned is one of the differences in the functions read.table() and read_tsv(). While the class of the objects is different, the contents of the objects are the same.\nIn addition to functions like install.packages() and library() that help you manage packages in R, RStudio also provides some point-and-click ways to do these same things. Check out the packages tab in the bottom-right RStudio panel.\n Bonus: Breakout Rooms III (~10 min.) Exercise 7: Reading In Compressed Data  Let\u0026rsquo;s look at one more example for a bit more practice with packages and reading data in to R. This time, we\u0026rsquo;ll try reading in a compressed (gzipped) version of the same example dataset. This one\u0026rsquo;s available from\u0026hellip;\nhttps://github.com/biodash/biodash.github.io/raw/master/assets/data/data_frame/example_df.tsv.gz\nLet\u0026rsquo;s read this dataset in as an object named zip_data. First try using the read.table() function just like before.\n  Hint (click here)  Try replacing the previous address with the updated address for the compressed file. Remember to set the header argument to TRUE.\n   Solution (click here)  #create an object storing the web address zip_address \u0026lt;- \"https://github.com/biodash/biodash.github.io/raw/master/assets/data/data_frame/example_df.tsv.gz\"   zip_data \u0026lt;- read.table(zip_address, header = TRUE)    read.table() isn\u0026rsquo;t able to uncompress a file directly from online, so you probably got an error message. However, it can automatically uncompress a file when reading it in locally (from your computer). So, see if you can use the download.file() function to get the compressed file and then read it in in a second step.\n  Hint (click here)  download.file() requires that two arguments are defined: url and destfile. Check ?download.file for details.\n   Solution (click here)  download.file(zip_address, destfile = \"example_zip_file.tsv.gz\") zip_data \u0026lt;- read.table(\"example_zip_file.tsv.gz\", header = TRUE)    Alternatively, you could install the data.table package and try its fread() function, which is able to download and automatically uncompress a file from online all in one step (though doing so requires another package, R.utils, so you\u0026rsquo;ll also have to get that one first if you don\u0026rsquo;t already have it)\u0026hellip;\ninstall.packages(\"R.utils\") install.packages(\"data.table\")   library(R.utils) library(data.table) data.table::fread(zip_address) #\u0026gt; Age Height_cm Eye_Color Graduated #\u0026gt; 1: 22 175.26 Blue TRUE #\u0026gt; 2: 67 170.18 Green TRUE #\u0026gt; 3: 53 165.10 Blue FALSE #\u0026gt; 4: 13 134.62 Brown FALSE #\u0026gt; 5: 19 147.32 Green TRUE #\u0026gt; 6: 27 185.42 Gray TRUE #\u0026gt; 7: 30 190.50 Blue TRUE #\u0026gt; 8: 11 144.78 Brown FALSE     Not only does this offer a little more practice with objects, functions, and reading in data, but it also provides one small example of the value in having multiple functions available that do similar things. In this specific case, when reading in data directly from online, you might find read.table() to be a little easier to work with if the data are uncompressed, but fread() might make things a bit easier (one less step) if the file is compressed. And we actually saw a third function, read_tsv() earlier (from the readr package), which offers yet another option for reading in data-frame-like data. This kind of thing is common in R - there are typically multiple ways of doing things, and as you work in R, you\u0026rsquo;ll continue to pick up more and more efficient ways of doing what you want to do.\n\n","date":1630281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630419925,"objectID":"05140758ca36d0c2bef7cd0d6b392018","permalink":"https://biodash.github.io/codeclub/s02e02_r-intro_part2/","publishdate":"2021-08-30T00:00:00Z","relpermalink":"/codeclub/s02e02_r-intro_part2/","section":"codeclub","summary":"Part 2 of hitting some of the important basics for working in R. We'll take a look at functions, packages, and pick up from last week with a bit more on R objects.","tags":null,"title":"Code Club S02E02: An introduction to R (Part 2)","type":"codeclub"},{"authors":["Jelmer Poelstra"],"categories":null,"content":"\nLearning objectives   Learn what Code Club is all about Get some basic familiarity with R and RStudio Understand a bit about R objects and how to use them    To do beforehand Before the Code Club Zoom session, please follow the Code Club Computer Setup instructions.\nIn brief, you should have R and RStudio installed on your computer or you should be set up to run RStudio Server at the Ohio Supercomputer Center (OSC). (As a bonus, you can try to install and load the tidyverse package as the setup page suggests, but no sweat if you can\u0026rsquo;t get that to work yet.)\nIn case you run into issues, contact Jelmer or for last-minute troubleshooting, you can join the Zoom call 15-30 minutes early.\n (Re)Introducing Code Club OSU Code Club is a regularly occurring online gathering to improve coding skills, now in its second year.\nThis Code Club was inspired by a paper in PLoS Computational Biology (\u0026ldquo;Ten simple rules to increase computational skills among biologists with Code Clubs\u0026rdquo;), and here are some of the underlying ideas:\n  Coding is best learned by doing, so Code Club is interactive and hands-on.\n  Ongoing exposure and practice also helps when learning.\n  We aim to keep it informal and maybe even fun.\n  We have a core group of 5 organizers that do most of the presenting, but we also encourage participants to present, and will have a couple of participant-led sessions at the end of this semester (see the schedule).\n  Organizers  Jelmer Poelstra (Molecular and Cellular Imaging Center (MCIC), Wooster Campus) Jessica Cooperstone (Dept. of Horticulture and Crop Science \u0026amp; Dept. of Food Science and Technology) Michael Broe (Dept. of Evolution, Ecology and Organismal Biology) Mike Sovic (Center for Applied Plant Sciences) Stephen Opiyo (MCIC, Columbus Campus)  Session structure Each session consists of an instructional part where you can code along or listen, some exercises in breakout rooms with 3-4 people, and exercise recaps with the entire group.\nZoom guidelines   We very much welcome questions at any time, so please either unmute yourself and speak, or post in the chat whenever you have a question!\n  Having your camera on helps, especially in breakout rooms. We will record the whole-group part of each session, so we understand if some of you prefer to have their cameras off during that part. (But note that we will only share the recordings with other Code Clubbers.)\n  You can use the icons under the \u0026ldquo;Participants\u0026rdquo; menu in Zoom when we ask for a \u0026ldquo;show of hands\u0026rdquo; or if you are having problems.\n  In breakout rooms:\n Briefly introduce yourselves. Have someone share their screen, preferably one of the least experienced people. Be friendly and patient, keep everyone aboard. The Zoom Ask for help button will alert us, and one of the organizers will come into the breakout room. (Raise hand is not seen by us outside of the room.)    Otherwise   We need your feedback! Always feel free to email one of the organizers, and for suggestions for a topic to cover in a future Code Club, you can fill out this form!\n  I will quickly show the Code Club menu and BioDASH website during the session.\n  Zoom polling question: are you working at OSC or locally?\n   1 \u0026ndash; Why R? R is a programming language that is most well-known for being excellent for statistical analysis and data visualization.\nWhile the learning curve is steeper than for most programs with graphical user interfaces (GUIs), it pays off to invest in learning R:\n  R gives you greater flexibility to do anything you want.\n  Writing computer instructions as code, like you have to do in R, is more reproducible than clicking around in a GUI. It also makes it much easier to redo analyses with slight modifications!\n  R is highly interdisciplinary and can be used with many different kinds of data. To just name two examples, R has a very strong ecosystem for bioinformatics analysis (\u0026ldquo;Bioconductor\u0026rdquo; project), and can be used to create maps and perform GIS analyses.\n  R is more than a platform to perform analysis and create figures. R Markdown combines R with a simple text markup language to produce analysis reports that integrate code, results, and text, and to create slide decks, data dashboards, websites, and even books! In the third session of Code Club, Michael Broe will talk more about R Markdown.\n  While not as versatile outside of data-focused topics as a language like Python, R can be used as a general programming language, for instance to automate tasks such as large-scale file renaming.\n  Finally, R:\n  Is open-source and freely available for all platforms (Windows, Mac, Linux).\n  Has a large and welcoming user community.\n   2 \u0026ndash; Exploring RStudio R simply provides a \u0026ldquo;console\u0026rdquo; (command-line interface) where you can type your commands.\nHowever, because you want to save your commands in scripts and see the graphics that you produce, it is more effective to work in an environment that provides all of this side-by-side. We will use RStudio, an excellent graphical environment (\u0026ldquo;Integrated Development Environment\u0026rdquo;, IDE) for R.\nI will now demonstrate how to start an RStudio Server session from the Ohio Supercomputer Center\u0026rsquo;s website following the steps from our Code Club Computer Setup page. If you have RStudio installed on your own computer, start it now, and otherwise, follow along with me to run RStudio in your browser.\nOnce you have a running instance of RStudio, create a new R script by clicking File \u0026gt; New File \u0026gt; R Script.\nNow, you should see all 4 \u0026ldquo;panes\u0026rdquo; that the RStudio window is divided into:\n Top-left: The Editor for your scripts and other documents (hidden when no file is open). Bottom-left: The R Console to interactively run your code (+ a tab with a Terminal). Top-right: Your Environment with R objects you have created (+ several other tabs). Bottom-left: Tabs for Files, Plots, Help, and others.  So, in RStudio, we have a single interface to write code in text files or directly in the console, visualize plots, navigate the files found on our computer, and inspect the data we are working with.\nRStudio has a lot of useful features and during the next few sessions of Code Club, we will introduce some tips and tricks for working with it.\n Breakout rooms I (~5 min.)  Introduce yourselves! We\u0026rsquo;ll return to the same breakout room configuration later in this session to do a few exercises, so please take a moment to introduce yourself to your breakout roommates. Make sure to also mention:\n  Your level of experience with R and other coding languages.\n  What you are aiming to use or are already using R for.\n  Check that everyone has RStudio working   Take a moment to explore the RStudio interface.\n  If you run into issues, click the Ask for help button in Zoom and one of us will come by.\n     3 \u0026ndash; Interacting with R R as a calculator The lower-left RStudio pane, i.e. the R console, is where you can interact with R directly.\nThe \u0026gt; sign is the R \u0026ldquo;prompt\u0026rdquo;. It indicates that R is ready for you to type something.\nLet\u0026rsquo;s start by performing a division:\n203 / 2.54 #\u0026gt; [1] 79.92126  R does the calculation and prints the result in the console as well. Afterwards, you get your \u0026gt; prompt back. (The [1] may look a bit weird when there is only one output element; this is how you can keep count of output elements when there are many.)\nWith the expected set of symbols, you can use R as a general calculator:\n203 * 2.54 # Multiplication #\u0026gt; [1] 515.62 203 + 2.54 # Addition #\u0026gt; [1] 205.54  Note that pressing the up arrow key will put your previous command back on the prompt, and you can press the up arrow again to go further back (as well as the down arrow to go in the other direction).\nExperimenting a bit\u0026hellip; What if we add spaces around our values?\n203 - 2.54 #\u0026gt; [1] 200.46  This works: as it turns out, R simply ignores any extra spaces.\nSimilarly, we could omit the single spaces around the mathematical operators that we used earlier (though we will keep using them for clarity):\n203/2.54 #\u0026gt; [1] 79.92126  How about:\n203 /  Now the prompt turned into a + instead of the usual \u0026gt;.\n  What is going on here? (Click for the answer)  R is waiting for you to finish the command, since you typed an incomplete command: something has to follow the division sign /.\nWhile it was obvious here that our command was incomplete, you will often type incomplete commands without realizing you did so. Just remember that when you see the + prompt, something has to be missing in your command: most commonly, you\u0026rsquo;ll have forgotten a closing parenthesis ) or you accidentally opened up an unwanted opening parenthesis (.\nIf you want to abort completing the incomplete command, you can press Esc.\n And if we just type a number:\n203 #\u0026gt; [1] 203  R will print the number back to us! It turns out that the default, implicit action that R will perform on anything you type is to print it back to us (under the hood, it is calling a function called print()).\nInstead of a number, what if we try to have R print some text (a character string) back to us?\nFantastic #\u0026gt; Error in eval(expr, envir, enclos): object 'Fantastic' not found  Code Club #\u0026gt; Error: \u0026lt;text\u0026gt;:1:6: unexpected symbol #\u0026gt; 1: Code Club #\u0026gt; ^    What seems to be going wrong here? (Click for the answer)  Whenever you type a character string, R expects to find an object with that name (we will get to what exactly objects are in a little bit!). When no object exists with that name, R will throw an error. We will learn some of the basics of objects in section 5 of today\u0026rsquo;s session.\n We can get R to print character strings back to us, and work with strings in other ways, as long as we quote them:\n\"Fantastic\" #\u0026gt; [1] \"Fantastic\"   4 \u0026ndash; Working with a script Need for scripts We can go along like this, typing commands directly into the R console. But to keep better track of what we\u0026rsquo;re doing, it\u0026rsquo;s a good idea to write code in plain text files, i.e. to write \u0026ldquo;scripts\u0026rdquo;.\n  You should have already created a script above (otherwise, click File \u0026gt; New File \u0026gt; R Script).\n  Click File \u0026gt; Save As to save the script; give it a descriptive name like intro-to-R.R.\n(You may want to put the script in a new subfolder for this Code Club session.)\n  Interacting with the R console from your script We recommend that you generally type your commands into a script and execute the commands from there, instead of typing directly into the console.\nWe want to make sure to save our division command, so start by typing the following into the R script in the top-left pane:\n203 / 2.54  With the cursor still on this line, press Ctrl + Enter. The command will be copied to the R console and executed, and then the cursor will move to the next line.\nNote that it doesn\u0026rsquo;t matter where on the line your cursor is: Ctrl + Enter will execute the entire line unless you have selected only part of it.\n(And when you have selected multiple lines of code, Ctrl + Enter will execute them all.)\nCommenting You can use # signs to annotate (comment) your code. Anything to the right of a # is ignored by R, meaning it won\u0026rsquo;t be executed. You can use # both at the start of a line or anywhere in a line following code.\nComments are a great way to describe what your code does within the code itself, so comment liberally in your R scripts! This is useful not only for others that you may share your code with, but perhaps especially for yourself when you look back at your code a day, a month, or a year later.\n# Divide by 2.54 to get the wingspan in inches: 203 / 2.54 # Original measurement was in cm   5 \u0026ndash; R Objects Assigning stuff to R objects We can assign any value, character, or set of values or characters to an object with the assignment operator, \u0026lt;-. (This is a smaller-than sign \u0026lt; followed by a dash -.)1\nFor example:\nwingspan_cm \u0026lt;- 203 conversion \u0026lt;- 2.54  Type that into your script, and use Ctrl + Enter to send it to the console.\nThe objects you create get added to your \u0026ldquo;workspace\u0026rdquo; or \u0026ldquo;environment.\u0026rdquo; RStudio shows this in the Environment tab in the topright panel \u0026ndash; check to see if wingspan_cm and conversion are indeed there.\nAfter you\u0026rsquo;ve assigned a number to an object, you can use it in other calculations:\nwingspan_inch \u0026lt;- wingspan_cm / conversion wingspan_inch #\u0026gt; [1] 79.92126  More generally speaking, the object name that you provide is substituted with its contents by R, so the object name is just a reference to the underlying value.\nOur objects so far contained just a single number and we may have also called them variables. Object is the more general name that encompasses R items of any size or complexity. As we see will see next week, R distinguishes between different types of objects.\nObject names Objects can be given any name such as x, current_temperature, or subject_id.\nSome pointers on object names:\n  Because R is case sensitive, wingspan_inch is different from Wingspan_inch.\n  An object name cannot contain a space, so for readability, separate words using:\n _ \u0026ndash; e.g. wingspan_inch (this is called \u0026ldquo;snake case\u0026rdquo;, which we will tend to use in Code Club instructional materials) . \u0026ndash; e.g. wingspan.inch capitalization \u0026ndash; e.g. wingspanInch or WingspanInch (\u0026ldquo;camel case\u0026rdquo;)    Object names can contain but cannot start with a number (2x is not valid, but x2 is)2.\n  Make object names descriptive yet not too long.\n  You will make things easier for yourself by naming objects in a consistent way, for instance by always sticking to your favorite case like \u0026ldquo;snake case.\u0026quot;3\n Objects, your workspace, and closing R When you close R, it will probably ask you whether you want to save your workspace (\u0026ldquo;Save workspace image to ~/.RData\u0026rdquo;). When you do so, then the next time you start R, you can reload everything the way it was, such as your previously created objects.\nWhile this may seem convenient, we recommend that you don\u0026rsquo;t do this.\n  Can you think of a reason why saving and reloading your workspace may not be a good idea? (Click for the answer)  The main reason why this is generally not considered good practice relates to the idea that you should be able to reproduce your workspace (and more broadly speaking, your analysis) from the code in your script.\nRemember that you can modify your workspace either by entering commands in the console directly, or by running them from a script \u0026ndash; or even from multiple different scripts. Also, in practice, you often run lines in the script out of order, or write lines in the script that you don\u0026rsquo;t execute.\nTherefore, if you \u0026ldquo;carry around\u0026rdquo; the same workspace across multiple different sessions, you run a greater risk of not having a reproducible set of steps in your script.\nTo make RStudio stop asking you about saving your workspace, click Tools \u0026gt; Global Options \u0026gt; General and set the options as follows:\nTaking these ideas a step further, it can be a good idea to occasionally restart R so you can check whether the code in your script is correct and complete, that you are not relying on code that is not in the script, and so on. To do so, you don\u0026rsquo;t need to close and reopen RStudio itself: under Session in the top menu bar, you can click Restart R (and you should also see the keyboard shortcut for it in the menu bar, which is Ctrl + Shift + F10 for Windows/Linux, and Cmd + Shift + F10 for Mac).\n    Breakout rooms II (5-10 min.) Note that in both of these exercises, the answers are not contained in what we just discussed. I would like you to think about your intuition for R\u0026rsquo;s behavior, and then see if R indeed works that way or not.\n Exercise 1: Object \u0026ldquo;linkage\u0026rdquo; What do you think the value of y will be after executing the following lines in R? 100 or 160, and why?\nx \u0026lt;- 50 # x is now 50 y \u0026lt;- x * 2 # y is now 100 x \u0026lt;- 80 # x is now 80, but what is y?    Solution (click here)  Objects don\u0026rsquo;t get linked to each other, so if you change one object, it won\u0026rsquo;t affect the values of other objects that were defined earlier.\nTherefore, y will continue to be 100.\n    Exercise 2: Errors\u0026hellip; (Bonus) In section 3, you might have noticed that we got a different error when typing one versus multiple unquoted words. Here are those examples again:\nFantastic #\u0026gt; Error in eval(expr, envir, enclos): object 'Fantastic' not found  Code Club #\u0026gt; Error: \u0026lt;text\u0026gt;:1:6: unexpected symbol #\u0026gt; 1: Code Club #\u0026gt; ^  Reproduce these errors for yourself: in Rstudio\u0026rsquo;s editor pane, type these or equivalent error-generating examples in a script saved with a .R extension, and send them to the console.\nWhy is the error in the second case different, and what does it mean?\n  Hints (click here)    Can you see how RStudio can \u0026ldquo;notice\u0026rdquo; errors already in the editor \u0026ndash; but only for the second of these two examples? The editor checks for syntax (\u0026ldquo;R grammar\u0026rdquo;) errors but not whether objects already exist.\n  If you hover over the red cross in the margin, you can see what RStudio is upset about.\n    What if we put a + or another operator between the two words?\nCode + Club #\u0026gt; Error in eval(expr, envir, enclos): object 'Code' not found       Solution (click here)  When typing a single unquoted word which is not an existing object, R will look for an object and then complain that it can\u0026rsquo;t find that object.\nWhen typing multiple unquoted words with a space between them, regardless of whether those are existing objects, R will notice a syntax (\u0026ldquo;R grammar\u0026rdquo;) error before it even gets around to checking objects.\nThe problem is that you are referring to two objects sequentially and without any mathematical operator in between them, or some other syntax to \u0026ldquo;join\u0026rdquo; them. In R, that\u0026rsquo;s not valid syntax. (You may think it would perhaps simply try to print both objects, but this is not the case.)\n A general lesson here is that you should always pay attention to the details of the error messages that you get. While the language may seem terse and odd at first, it usually holds important clues as to what is going wrong exactly.\n   In closing Where to go from here For a list of recommended resources for learning R, see our R Resources and Tips page page.\nAttribution This was modified after material from The Carpentries, especially from this Data Carpentry workshop and this \u0026ldquo;R for Ecology\u0026rdquo; workshop.\n\n  In RStudio, typing Alt + - will write \u0026lt;- in a single keystroke. You can also use = as assignment, but that symbol can have other meanings, so we recommend sticking with the \u0026lt;- combination. \u0026#x21a9;\u0026#xfe0e;\n There are some names that cannot be used because they are the names of fundamental keywords in R (e.g., if, else, for, see here for a complete list). In general, it\u0026rsquo;s best not to use other function names even if it\u0026rsquo;s \u0026ldquo;allowed\u0026rdquo; (e.g., c, T, mean, data, df, weights). If in doubt, check the Help to see if the name is already in use. \u0026#x21a9;\u0026#xfe0e;\n It is also recommended to use nouns for variable names, and verbs for function names. For more, two popular R style guides are Hadley Wickham\u0026rsquo;s and Google\u0026rsquo;s. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1629158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630001482,"objectID":"5342f37781dccc93340fc0b810b8f329","permalink":"https://biodash.github.io/codeclub/s02e01_r-intro-part1/","publishdate":"2021-08-17T00:00:00Z","relpermalink":"/codeclub/s02e01_r-intro-part1/","section":"codeclub","summary":"This first installment of Code Club in the Fall '21 semester is the first of two sessions where we will go through the basics of R.","tags":null,"title":"Code Club S02E01:\nAn introduction to R (Part 1)\n","type":"codeclub"},{"authors":null,"categories":null,"content":" R Resources   RStudio cheatsheets\n  Our own Mike Sovic\u0026rsquo;s Youtube playlist of short videos on R:\n      Also for getting started with R, a useful and fun written tutorial is R for cats.\n  For a more systematic and lengthy introduction to R, see A Tutorial Introduction to R.\n  The Carpentries have a number of great lessons on R, such as:\n  Data Analysis and Visualization in R for Ecologists, which includes data wrangling with tidyverse packages and plotting with ggplot2.\n  R for Reproducible Scientific Analysis\n    If you prefer material structured as a course, excellent free ones include the R Basics and Visualization courses by Rafael Irizarry (you do have to create an EdX account for access).\n  If you prefer a book, we would recommend Wickham \u0026amp; Grolemund\u0026rsquo;s \u0026ldquo;R for Data Science\u0026rdquo;, which is freely available on the web in a really nice format here.\n   Miscellaneous R tips Useful settings By default, R will try to save your \u0026ldquo;environment\u0026rdquo; (e.g., your loaded data, variables, etc) when you exit, and then reload everything the way it was upon restarting R. However, doing so is not good practice! You should always be able to reproduce your environment given a set of commands saved in an R script or R Markdown document, whereas saving and reloading your entire environment encourages you to be sloppy about this.\nTo disable this behavior in RStudio, click Tools \u0026gt; Global Options \u0026gt; General and set the options as follows:\n  Recommended R/RStudio settings  To start R in the same way from the command line:\nR --no-save --no-restore-data \n Installing R packages CRAN packages To install an R package that is available at CRAN, the default R package repository, from within R (e.g. in the R console in RStudio), use the install.packages() function.\nThe install.packages() function will handle dependencies within R \u0026ndash; i.e., it will install other R packages that your package depends on. Occasionally, when the install function needs to compile a package from source, errors arise that relate to missing system dependencies (i.e. software outside of R).\nOn Mac and Linux, these system dependencies are best installed outside of R, such as with homebrew on Mac or apt on Ubuntu. The errror message you got when trying to install an R package should tell you which system dependencies are needed.\nOn Windows, you can use the installr package to install such dependencies or other software from within R \u0026ndash; for example:\ninstall.packages(\u0026#34;installr\u0026#34;) # Install the installr package first installlr::install.RStudio() # Install RStudio installr::install.python() # Install Python \nSystem setup to installing packages \u0026ldquo;from source\u0026rdquo; Sometimes you need to install a package from source, that is, you need to compile the package rather than simply installing a pre-existing binary. (On Linux, where installing from source is often needed, this should work without additional steps.) On Windows and Mac, installing from source is generally only needed when you install a package from outside of CRAN (such as from Github, see below), but you will need to make sure you have the following non-R software:\nOn Windows, you will need Rtools (Rtools installation instructions).\nOn a Mac, you will need Xcode (which can be installed from the Mac App store).\nYou can test whether or not you are able to install packages from source using the devtools package:\ninstall.packages(\u0026#34;devtools\u0026#34;) # Install the devtools package devtools::has_devel() # Check whether you can install packages from source For a bit more info, see this page.\nInstalling packages from Github To install a package from Github, use either the devtools or the remotes package \u0026ndash; for example:\ninstall.packages(\u0026#34;devtools\u0026#34;) # Install the devtools package devtools::install_github(\u0026#34;kbroman/broman\u0026#34;) # Install from a repository using \u0026#34;\u0026lt;username\u0026gt;/\u0026lt;repo-name\u0026gt;\u0026#34; This will install the package from source, so you will need to make sure you are able to do so by following the instructions in the section right above this one.\nInstalling packages from Bioconductor If you\u0026rsquo;re doing bioinformatic analyses in R, you will probably run into packages that are not on CRAN but on Bioconductor. To install a package from Bioconductor, use the BiocManager package \u0026ndash; for example:\ninstall.packages(\u0026#34;BiocManager\u0026#34;) # Install the BiocManager package BiocManager::install(\u0026#34;edgeR\u0026#34;) # Install the edgeR package from Bioconductor \n Updating R Consider updating R if you have an older version of R installed. Specifically, in the first session of Code Club, we\u0026rsquo;ve seen problems when installing the tidyverse with R versions below R 3.6.\nYou can check which version of R you have by looking at the first lines of output when running the following command inside R:\nsessionInfo() To update:   Windows: You can update R from within R. The updateR() function will also take care of updating your packages:\ninstall.packages(\u0026#34;installr\u0026#34;) installr::updateR()   Mac: Download and install the latest .pkg file as if you were installing it for the first time.\n  Linux: In Ubuntu, if you installed R with apt or apt-get, you can use apt-get upgrade in a terminal. Otherwise, download and install the latest version after removing the old one. Rtask has some instructions for upgrading to R 4.0 in Ubuntu (along with upgrading to Ubuntu 20.04).\n  Re-installing your packages after updating (Mac and Linux) While the installr::updateR() function for Windows users takes care of reinstalling your packages along with updating R, Mac and Linux users will have to manually re-install their packages. Some people prefer to re-install these packages on the fly, which can end up being a way to get rid of packages you no longer use.\nBut if you want immediately reinstall all your packages, run this before you upgrade:\nmy_packages \u0026lt;- installed.packages() saveRDS(my_packages, \u0026#34;my_packages.rds\u0026#34;) Then, after you\u0026rsquo;ve installed the latest R version:\nmy_packages \u0026lt;- readRDS(\u0026#34;CurrentPackages.rds\u0026#34;) install.packages(my_packages[1, ]) This will only work for packages available on CRAN. Of course, you can check your list for Github-only and Bioconductor packages and then install those with their respective commands (see below). Yes, this can be a bit of a hassle!\n  \n ","date":1629158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629760303,"objectID":"1b8835e02d17d12c605c4ae1b9cc35e8","permalink":"https://biodash.github.io/tutorials/r-resources-tips/","publishdate":"2021-08-17T00:00:00Z","relpermalink":"/tutorials/r-resources-tips/","section":"tutorials","summary":"R Resources   RStudio cheatsheets\n  Our own Mike Sovic\u0026rsquo;s Youtube playlist of short videos on R:\n      Also for getting started with R, a useful and fun written tutorial is R for cats.","tags":null,"title":"R Resources and Tips","type":"tutorials"},{"authors":["Jessica Cooperstone"],"categories":null,"content":"\n Prep homework Basic computer setup   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n  You can use R locally, or at OSC. You can find instructions if you are having trouble here.\n   Getting Started RMarkdown for today\u0026rsquo;s session # directory for Code Club Session 20: dir.create(\"S20\") # directory for our RMarkdown # (\"recursive\" to create two levels at once.) dir.create(\"S20/Rmd/\") # save the url location for today's script todays_Rmd \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/20_cleaning-up/CleaningUp.Rmd' # indicate the name of the new script file Session20_Rmd \u0026lt;- \"S20/Rmd/CleaningUp.Rmd\" # go get that file!  download.file(url = todays_Rmd, destfile = Session20_Rmd)   1 - Using regexs for wrangling Artwork by Allison Horst\nNow that we have gone through a mini-series on regular expressions, with the basics, some next level helpers, and using tidytext to make word clouds, I thought I\u0026rsquo;d talk today about some applications of this information to cleaning up your data.\nTo do this, we are going to practice with the palmerpenguins dataset, and get back to the bakeoff for our practice exercises.\n 2 - Accessing our data First load your libraries. We will be using stringr and tidyr but those are both part of core tidyverse. We are also using a new package today called janitor which helps you \u0026ldquo;clean up\u0026rdquo; your data.\nIf you don\u0026rsquo;t have the package janitor, please install it.\ninstall.packages(\"janitor\")  library(tidyverse) library(janitor) # for cleaning up column names library(palmerpenguins) # for penguins data library(bakeoff) # for bakeoff data  Then we will use the package palmerpenguins and the dataset penguins_raw, which has a bit more info than penguins, which we have used previously.\nArtwork by Allison Horst\n 3 - Variable names There are many instances where you may have variables names and/or sample names that are messy. For example, variable names that include characters like white spaces, special characters like symbols, or begin with a number are going to give you problems with some R coding. I\u0026rsquo;ll say that you can have these non-standard variable names, but occasionally they will give you a big headache and so I\u0026rsquo;d recommend to just avoid them.\nR variable \u0026ldquo;rules\u0026rdquo;:\n can contain letters, numbers, underscores (_) and periods (.) cannot start with a number or underscore shouldn\u0026rsquo;t be a \u0026ldquo;reserved\u0026rdquo; word, like if, else, function, TRUE, FALSE etc. (if you want to see them all, execute ?reserved in your console)  You can read about the tidyverse style guide if you want to learn more.\nLets look at the variable names in penguins_raw.\nglimpse(penguins_raw) #\u0026gt; Rows: 344 #\u0026gt; Columns: 17 #\u0026gt; $ studyName \u0026lt;chr\u0026gt; \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL… #\u0026gt; $ `Sample Number` \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… #\u0026gt; $ Species \u0026lt;chr\u0026gt; \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie P… #\u0026gt; $ Region \u0026lt;chr\u0026gt; \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\"… #\u0026gt; $ Island \u0026lt;chr\u0026gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse… #\u0026gt; $ Stage \u0026lt;chr\u0026gt; \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stage\", \"Adu… #\u0026gt; $ `Individual ID` \u0026lt;chr\u0026gt; \"N1A1\", \"N1A2\", \"N2A1\", \"N2A2\", \"N3A1\", \"N3A2\", … #\u0026gt; $ `Clutch Completion` \u0026lt;chr\u0026gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", … #\u0026gt; $ `Date Egg` \u0026lt;date\u0026gt; 2007-11-11, 2007-11-11, 2007-11-16, 2007-11-16,… #\u0026gt; $ `Culmen Length (mm)` \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34… #\u0026gt; $ `Culmen Depth (mm)` \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18… #\u0026gt; $ `Flipper Length (mm)` \u0026lt;dbl\u0026gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,… #\u0026gt; $ `Body Mass (g)` \u0026lt;dbl\u0026gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34… #\u0026gt; $ Sex \u0026lt;chr\u0026gt; \"MALE\", \"FEMALE\", \"FEMALE\", NA, \"FEMALE\", \"MALE\"… #\u0026gt; $ `Delta 15 N (o/oo)` \u0026lt;dbl\u0026gt; NA, 8.94956, 8.36821, NA, 8.76651, 8.66496, 9.18… #\u0026gt; $ `Delta 13 C (o/oo)` \u0026lt;dbl\u0026gt; NA, -24.69454, -25.33302, NA, -25.32426, -25.298… #\u0026gt; $ Comments \u0026lt;chr\u0026gt; \"Not enough blood for isotopes.\", NA, NA, \"Adult…  What you can see is that there are variable names here that don\u0026rsquo;t comply with the \u0026ldquo;rules\u0026rdquo; I just indicated. How can that be?! You can see for the variable Sample Number that it is surrounded by backticks. This is how R know that this is a variable name.\nOkay, so who cares? If you want to call that particular variable, you will have to put it in backticks. For example:\n# this doesn't work penguins_raw %% select(Sample Number)  # this works but is clunky penguins_raw %\u0026gt;% select(`Sample Number`) #\u0026gt; # A tibble: 344 × 1 #\u0026gt; `Sample Number` #\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 1 #\u0026gt; 2 2 #\u0026gt; 3 3 #\u0026gt; 4 4 #\u0026gt; 5 5 #\u0026gt; 6 6 #\u0026gt; 7 7 #\u0026gt; 8 8 #\u0026gt; 9 9 #\u0026gt; 10 10 #\u0026gt; # … with 334 more rows  And, this is using tidyverse functions - there will be other situations where you will get non-solvable errors because of your variable names.\ntl;dr just make your variable names R compliant, there are lots of other harder things you\u0026rsquo;re going to be doing with coding, so just make this easier for yourself.\nUsing clean_names() Artwork by Allison Horst\nYou may be thinking now, okay but what happens if someone else gives me data that has unclean variable names?\nDon\u0026rsquo;t worry too much, you can easily fix it. My favorite, and the simplest way to do this is using the package janitor, and the function clean_names(). Certainly you could clean your variable names manually, but why? This is really easy.\npenguins_clean \u0026lt;- clean_names(penguins_raw) glimpse(penguins_clean) #\u0026gt; Rows: 344 #\u0026gt; Columns: 17 #\u0026gt; $ study_name \u0026lt;chr\u0026gt; \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL0708… #\u0026gt; $ sample_number \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1… #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie Pengu… #\u0026gt; $ region \u0026lt;chr\u0026gt; \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\", \"A… #\u0026gt; $ island \u0026lt;chr\u0026gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen\", … #\u0026gt; $ stage \u0026lt;chr\u0026gt; \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stage\", \"Adult, … #\u0026gt; $ individual_id \u0026lt;chr\u0026gt; \"N1A1\", \"N1A2\", \"N2A1\", \"N2A2\", \"N3A1\", \"N3A2\", \"N4A… #\u0026gt; $ clutch_completion \u0026lt;chr\u0026gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\"… #\u0026gt; $ date_egg \u0026lt;date\u0026gt; 2007-11-11, 2007-11-11, 2007-11-16, 2007-11-16, 200… #\u0026gt; $ culmen_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, … #\u0026gt; $ culmen_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, … #\u0026gt; $ flipper_length_mm \u0026lt;dbl\u0026gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186… #\u0026gt; $ body_mass_g \u0026lt;dbl\u0026gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, … #\u0026gt; $ sex \u0026lt;chr\u0026gt; \"MALE\", \"FEMALE\", \"FEMALE\", NA, \"FEMALE\", \"MALE\", \"F… #\u0026gt; $ delta_15_n_o_oo \u0026lt;dbl\u0026gt; NA, 8.94956, 8.36821, NA, 8.76651, 8.66496, 9.18718,… #\u0026gt; $ delta_13_c_o_oo \u0026lt;dbl\u0026gt; NA, -24.69454, -25.33302, NA, -25.32426, -25.29805, … #\u0026gt; $ comments \u0026lt;chr\u0026gt; \"Not enough blood for isotopes.\", NA, NA, \"Adult not…  You can see that Sample Number became sample_number, Culmen Length (mm) became culmen_length_mm.\nThe default is to parse with \u0026ldquo;snake\u0026rdquo; case, which would look like snake_case. You could also set the argument case to:\n \u0026quot;lower_camel\u0026quot; or \u0026quot;small_camel\u0026quot; to get lowerCamel \u0026quot;upper_camel\u0026quot; or \u0026quot;big_camel\u0026quot; to get UpperCamel \u0026quot;screaming_snake\u0026quot; or \u0026quot;all_caps\u0026quot; to get SCREAMING_SNAKE (stop yelling please) \u0026quot;lower_upper\u0026quot; to get lowerUPPER (I don\u0026rsquo;t know why you\u0026rsquo;d want this) \u0026quot;upper_lower\u0026quot; to get UPPERlower (I also don\u0026rsquo;t know why you\u0026rsquo;d want this)  Artwork by Allison Horst\n 4 - Unite character columns There will be times when you\u0026rsquo;d like to take a variable, and combine it with another variable. For example, you might want a column called region_island which contains a combination of the region and island that each penguin is from. We can do this with the function unite(). The function unite() allows you to paste together multiple columns to become one column.\nThe arguments to unite work like this:\nunite(data, col, ..., sep = \u0026quot;_\u0026quot;, remove = TRUE, na.rm = FALSE)\npenguins_clean_unite \u0026lt;- penguins_clean %\u0026gt;% unite(col = \"region_island\", region:island, # indicate the columns to unite remove = FALSE) # don't remove region and island  Did it work?\nhead(penguins_clean_unite) #\u0026gt; # A tibble: 6 × 18 #\u0026gt; study_name sample_number species region_island region island stage  #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 PAL0708 1 Adelie Penguin… Anvers_Torger… Anvers Torge… Adult, … #\u0026gt; 2 PAL0708 2 Adelie Penguin… Anvers_Torger… Anvers Torge… Adult, … #\u0026gt; 3 PAL0708 3 Adelie Penguin… Anvers_Torger… Anvers Torge… Adult, … #\u0026gt; 4 PAL0708 4 Adelie Penguin… Anvers_Torger… Anvers Torge… Adult, … #\u0026gt; 5 PAL0708 5 Adelie Penguin… Anvers_Torger… Anvers Torge… Adult, … #\u0026gt; 6 PAL0708 6 Adelie Penguin… Anvers_Torger… Anvers Torge… Adult, … #\u0026gt; # … with 11 more variables: individual_id \u0026lt;chr\u0026gt;, clutch_completion \u0026lt;chr\u0026gt;, #\u0026gt; # date_egg \u0026lt;date\u0026gt;, culmen_length_mm \u0026lt;dbl\u0026gt;, culmen_depth_mm \u0026lt;dbl\u0026gt;, #\u0026gt; # flipper_length_mm \u0026lt;dbl\u0026gt;, body_mass_g \u0026lt;dbl\u0026gt;, sex \u0026lt;chr\u0026gt;, #\u0026gt; # delta_15_n_o_oo \u0026lt;dbl\u0026gt;, delta_13_c_o_oo \u0026lt;dbl\u0026gt;, comments \u0026lt;chr\u0026gt;  This is a silly example since there is only one region, but I think you can see how this function is used.\n 5 - Separate character columns There will be times that you have a column that has two variables embedded within it, and you will want to separate or parse the column to become two separate columns. You can do this with the function separate().\nThe arguments to separate look like this:\nseparate(data, col, into, sep = \u0026quot;yourregex\u0026quot;, remove = TRUE, extra = \u0026quot;warn\u0026quot;, fill = \u0026quot;warn\u0026quot;)\nLet\u0026rsquo;s look at the column stage.\npenguins_clean$stage[1:5] #\u0026gt; [1] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\" #\u0026gt; [4] \"Adult, 1 Egg Stage\" \"Adult, 1 Egg Stage\"  We might want to separate the column stage into age and egg_stage. We can do this with separate().\npenguins_clean_stage \u0026lt;- penguins_clean %\u0026gt;% separate(col = stage, into = c(\"age\", \"egg_stage\"), sep = \",\", # the comma is the separator remove = FALSE)   Did it work?\npenguins_clean_stage %\u0026gt;% select(stage, age, egg_stage) %\u0026gt;% head() #\u0026gt; # A tibble: 6 × 3 #\u0026gt; stage age egg_stage  #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Adult, 1 Egg Stage Adult \" 1 Egg Stage\" #\u0026gt; 2 Adult, 1 Egg Stage Adult \" 1 Egg Stage\" #\u0026gt; 3 Adult, 1 Egg Stage Adult \" 1 Egg Stage\" #\u0026gt; 4 Adult, 1 Egg Stage Adult \" 1 Egg Stage\" #\u0026gt; 5 Adult, 1 Egg Stage Adult \" 1 Egg Stage\" #\u0026gt; 6 Adult, 1 Egg Stage Adult \" 1 Egg Stage\"   6 - Extract character columns We can use extract() to set up regular expressions to allow the separation of our variable species into a column with the common name, and a column with the genus species.\nWe will use str_view to figure out a regex that will work for us.\n# indicate our string string \u0026lt;- \"Adelie Penguin (Pygoscelis adeliae)\"  # to get Adelie Penguin str_view(string, \"\\\\w+\\\\s\\\\w+\")    \\\\w gives you anything that\u0026rsquo;s a word character the + indicates to match alphanumeric at least 1 time \\\\s indicates a space  # to get Pygoscelis adeliae str_view(string, \"(?\u0026lt;=\\\\()\\\\w+\\\\s\\\\w+\")    (?\u0026lt;=) is called the positive lookbehind, and has this general structure (?\u0026lt;=B)A which can be read like \u0026ldquo;find exprssion A which is preceeded by expression B.\u0026rdquo; In our example, expression B is a parentheses (. But there is some additional complexity here because parentheses have their own meanings in regex so you need to use the \\\\ to escape them. The whole expression for this part of our regex is (?\u0026lt;=\\\\(). \\\\w gives you anything that\u0026rsquo;s a word character the + indicates to match alphanumeric at least 1 time \\\\s indicates a space  Ok our regexs work as desired! Now we can incorporate them into extract(). Here I am using .*? to match the characters between our two targeted regex which here is (.\npenguins_clean_extract \u0026lt;- penguins_clean %\u0026gt;% extract(col = species, into = c(\"common_name\", \"genus_species\"), regex = \"(\\\\w+\\\\s\\\\w+).*?((?\u0026lt;=\\\\()\\\\w+\\\\s\\\\w+)\", remove = FALSE)   penguins_clean_extract %\u0026gt;% select(species, common_name, genus_species) %\u0026gt;% head() #\u0026gt; # A tibble: 6 × 3 #\u0026gt; species common_name genus_species  #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Adelie Penguin (Pygoscelis adeliae) Adelie Penguin Pygoscelis adeliae #\u0026gt; 2 Adelie Penguin (Pygoscelis adeliae) Adelie Penguin Pygoscelis adeliae #\u0026gt; 3 Adelie Penguin (Pygoscelis adeliae) Adelie Penguin Pygoscelis adeliae #\u0026gt; 4 Adelie Penguin (Pygoscelis adeliae) Adelie Penguin Pygoscelis adeliae #\u0026gt; 5 Adelie Penguin (Pygoscelis adeliae) Adelie Penguin Pygoscelis adeliae #\u0026gt; 6 Adelie Penguin (Pygoscelis adeliae) Adelie Penguin Pygoscelis adeliae  Voila!\n 7 - Replacing with str_replace() The column individual_id has two parts: the letter N and then a number, and the letter A and then a number. Let\u0026rsquo;s split this column into two columns, one called id_n that contains the number after the N, and a second called id_a that contains the number after the A.\npenguins_clean_fixID \u0026lt;- penguins_clean %\u0026gt;% separate(col = individual_id, into = c(\"id_n\", \"id_a\"), sep = \"A\", # can also use regex \"[A]\" remove = FALSE)   Did it work?\npenguins_clean_fixID %\u0026gt;% select(individual_id, id_n, id_a) %\u0026gt;% head() #\u0026gt; # A tibble: 6 × 3 #\u0026gt; individual_id id_n id_a  #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 N1A1 N1 1  #\u0026gt; 2 N1A2 N1 2  #\u0026gt; 3 N2A1 N2 1  #\u0026gt; 4 N2A2 N2 2  #\u0026gt; 5 N3A1 N3 1  #\u0026gt; 6 N3A2 N3 2  This worked to separate out the A, but the N is still linked with id_n. We can use a combination of mutate() and str_replace_all() to remove the N. You can learn more about str_replace() here.\npenguins_clean_fixID \u0026lt;- penguins_clean_fixID %\u0026gt;% mutate(id_n = str_replace_all(id_n, \"N\", \"\"))  penguins_clean_fixID %\u0026gt;% select(individual_id, id_n, id_a) %\u0026gt;% head() #\u0026gt; # A tibble: 6 × 3 #\u0026gt; individual_id id_n id_a  #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 N1A1 1 1  #\u0026gt; 2 N1A2 1 2  #\u0026gt; 3 N2A1 2 1  #\u0026gt; 4 N2A2 2 2  #\u0026gt; 5 N3A1 3 1  #\u0026gt; 6 N3A2 3 2   Exercises We will be doing our exercises today with a couple of datasets from the bakeoff package.\n Exercise 1  Using the dataset bakers, combine bakers_last with bakers_first to create a new column bakers_last_first which is indicated like this: Lastname, Firstname.\n  Hints (click here)  Use [`head()`](https://rdrr.io/r/utils/head.html) or `glimpse()` to see the structure of this data. Use `unite()` to combine columns. Don't forget to indicate the correct `sep`    Solutions (click here)  head(bakers) #\u0026gt; # A tibble: 6 × 8 #\u0026gt; series baker_full baker age occupation hometown baker_last baker_first #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 1 \"Annetha Mi… Annet… 30 Midwife Essex Mills Annetha  #\u0026gt; 2 1 \"David Cham… David 31 Entrepreneur Milton K… Chambers David  #\u0026gt; 3 1 \"Edward \\\"E… Edd 24 Debt collec… Bradford Kimber Edward  #\u0026gt; 4 1 \"Jasminder … Jasmi… 45 Assistant C… Birmingh… Randhawa Jasminder  #\u0026gt; 5 1 \"Jonathan S… Jonat… 25 Research An… St Albans Shepherd Jonathan  #\u0026gt; 6 1 \"Lea Harris\" Lea 51 Retired Midlothi… Harris Lea bakers_2 \u0026lt;- bakers %\u0026gt;% unite(col = \"bakers_last_first\", c(baker_last, baker_first), sep = \", \") # did it work? head(bakers_2) #\u0026gt; # A tibble: 6 × 7 #\u0026gt; series baker_full baker age occupation hometown bakers_last_fir… #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 1 \"Annetha Mills\" Annetha 30 Midwife Essex Mills, Annetha  #\u0026gt; 2 1 \"David Chambers\" David 31 Entrepren… Milton … Chambers, David  #\u0026gt; 3 1 \"Edward \\\"Edd\\\" Kimber\" Edd 24 Debt coll… Bradford Kimber, Edward  #\u0026gt; 4 1 \"Jasminder Randhawa\" Jasminder 45 Assistant… Birming… Randhawa, Jasmi… #\u0026gt; 5 1 \"Jonathan Shepherd\" Jonathan 25 Research … St Alba… Shepherd, Jonat… #\u0026gt; 6 1 \"Lea Harris\" Lea 51 Retired Midloth… Harris, Lea      Exercise 2  Using the dataset bakers, convert the column hometown to two columns, where whatever comes before the comma is in a column called city and whatever comes after is in a column called locale.\n  Hints (click here)  Try using `separate()`.    Solutions (click here)  head(bakers) #\u0026gt; # A tibble: 6 × 8 #\u0026gt; series baker_full baker age occupation hometown baker_last baker_first #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 1 \"Annetha Mi… Annet… 30 Midwife Essex Mills Annetha  #\u0026gt; 2 1 \"David Cham… David 31 Entrepreneur Milton K… Chambers David  #\u0026gt; 3 1 \"Edward \\\"E… Edd 24 Debt collec… Bradford Kimber Edward  #\u0026gt; 4 1 \"Jasminder … Jasmi… 45 Assistant C… Birmingh… Randhawa Jasminder  #\u0026gt; 5 1 \"Jonathan S… Jonat… 25 Research An… St Albans Shepherd Jonathan  #\u0026gt; 6 1 \"Lea Harris\" Lea 51 Retired Midlothi… Harris Lea bakers_hometown \u0026lt;- bakers %\u0026gt;% separate(col = hometown, into = c(\"city\", \"locale\"), sep = \", \") #\u0026gt; Warning: Expected 2 pieces. Additional pieces discarded in 1 rows [71]. #\u0026gt; Warning: Expected 2 pieces. Missing pieces filled with `NA` in 65 rows [1, 2, 3, 4, 5, 7, 8, 11, 12, 15, 19, 20, 23, 25, 27, 28, 31, 34, 38, 41, ...]. # did it work? head(bakers_hometown) #\u0026gt; # A tibble: 6 × 9 #\u0026gt; series baker_full baker age occupation city locale baker_last baker_first #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 1 \"Annetha M… Annet… 30 Midwife Essex NA Mills Annetha  #\u0026gt; 2 1 \"David Cha… David 31 Entrepren… Milt… NA Chambers David  #\u0026gt; 3 1 \"Edward \\\"… Edd 24 Debt coll… Brad… NA Kimber Edward  #\u0026gt; 4 1 \"Jasminder… Jasmi… 45 Assistant… Birm… NA Randhawa Jasminder  #\u0026gt; 5 1 \"Jonathan … Jonat… 25 Research … St A… NA Shepherd Jonathan  #\u0026gt; 6 1 \"Lea Harri… Lea 51 Retired Midl… Scotl… Harris Lea      Exercise 3  Using the dataset bakers add a column nickname which indicates the bakers nickname, if they have one.\n  Hints (click here)  Think about how to make a regex that would pull out the nickname. Try using `str_view_all()` to get your regex working before you apply it to `bakers`. Try using the lookahead syntax.    Solutions (click here)  baker_full \u0026lt;- bakers$baker_full  # note I used single quotes because there were double quotes in the regex str_view_all(baker_full, '(?\u0026lt;=\\\\\").*(?=\\\\\")')    bakers_nickname \u0026lt;- bakers %\u0026gt;% extract(col = baker_full, into = \"nickname\", regex = '((?\u0026lt;=\\\\\")\\\\w+(?=\\\\\"))') bakers_nickname %\u0026gt;% arrange(nickname) %\u0026gt;% head() #\u0026gt; # A tibble: 6 × 8 #\u0026gt; series nickname baker age occupation hometown baker_last baker_first #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 1 Edd Edd 24 Debt collector… Bradford Kimber Edward  #\u0026gt; 2 2 Jo Joanne 41 Housewife Ongar, E… Wheatley Joanne  #\u0026gt; 3 7 Val Val 66 Semi-retired, … Yeovil Stones Valerie  #\u0026gt; 4 8 Yan Yan 46 Laboratory res… North Lo… Tsou Chuen-Yan  #\u0026gt; 5 1 NA Annetha 30 Midwife Essex Mills Annetha  #\u0026gt; 6 1 NA David 31 Entrepreneur Milton K… Chambers David      Exercise 4  Using the dataset challenge_results, write a regex to find any signature that contains chocolate. Remove all observations that contain NA for the signature. How many of the signature bakes contain chocolate? What percentage of the total signature bakes (for which we have bake names) does this represent?\n  Hints (click here)  You can get rid of NAs with `drop_na()`. Try using `str_count()` to see how many occurances you have of chocolate in the signatures.    Solutions (click here)  # select only signatures, drop NAs signatures \u0026lt;- challenge_results %\u0026gt;% select(signature) %\u0026gt;% drop_na() # check dimensions  dim(signatures) #\u0026gt; [1] 703 1 # regex for chocolate (or Chocolate, or Chocolatey) str_count(signatures, \"[Cc]hocolat[ey]\") #\u0026gt; Warning in stri_count_regex(string, pattern, opts_regex = opts(pattern)): argument is not an atomic vector; coercing #\u0026gt; [1] 75 # what percent of signatures contain chocolate (str_count(signatures, \"[Cc]hocolat[ey]\")/count(signatures))*100 #\u0026gt; Warning in stri_count_regex(string, pattern, opts_regex = opts(pattern)): argument is not an atomic vector; coercing #\u0026gt; n #\u0026gt; 1 10.66856      ","date":1619740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628697543,"objectID":"15be695bc3bed9ca7458afe8a992c490","permalink":"https://biodash.github.io/codeclub/20_cleaning-up/","publishdate":"2021-04-30T00:00:00Z","relpermalink":"/codeclub/20_cleaning-up/","section":"codeclub","summary":"During this  session of Code Club, we will be learning to clean up variable names, combine and separate columns, and extract data with regular expressions.","tags":null,"title":"Session 20: Cleaning up variables names, and other wrangling","type":"codeclub"},{"authors":["Michael Broe"],"categories":null,"content":"\n New To Code Club?   First, check out the Code Club Computer Setup instructions, which also has some pointers that might be helpful if you\u0026rsquo;re new to R or RStudio.\n  Please open RStudio before Code Club to test things out \u0026ndash; if you run into issues, join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n   Session Goals  Learn the fundamentals of text mining. Learn how to do text mining in a tidyverse setting. Reuse some of our dplyr and ggplot skills on text. Learn how to very simply create word cloud visualizations.   Setup This is another in our current series on text processing. We\u0026rsquo;ll be using the following previously used packages which you should load first (install them if you haven\u0026rsquo;t already):\nlibrary(tidyverse) library(bakeoff)   We\u0026rsquo;ll also be using the following packages, which you should install and load:\n# Uncomment the following line to install: # install.packages(c(\"tidytext\", \"gutenbergr\", \"wordcloud\")) library(tidytext) library(gutenbergr) library(wordcloud)   Introduction In this CodeClub session we\u0026rsquo;ll see how to create word clouds (also known as tag clouds) from text, using the tidytext and wordcloud packages. A word cloud is a visualization of word frequencies, graphically highlighting the most common words.\nWe need to get some text from somewhere, so first let\u0026rsquo;s do it in the simplest possible way. Here we manually enter a quote, line by line, as a vector of five character strings. This is the first stanza from Robert Lowell\u0026rsquo;s Skunk Hour:\nlowell \u0026lt;- c(\"Nautilus Island's hermit\", \"heiress still lives through winter in her Spartan cottage;\", \"her sheep still graze above the sea.\", \"Her son's a bishop. Her farmer is first selectman in our village;\", \"she's in her dotage.\")   In textual analysis we distinguish between word types, and word tokens (multiple instances of those words in text). For example there are two tokens of the word-type \u0026ldquo;still\u0026rdquo; in this stanza:\n heiress still lives through winter\nher sheep still graze above the sea\n And slightly more abstractly there are four tokens of \u0026ldquo;her\u0026rdquo;, modulo capitalization:\n her Spartan cottage\nher sheep still graze\nHer son\u0026rsquo;s a bishop.\nHer farmer\n Formally, it\u0026rsquo;s the token frequency of the word types we are ultimately interested in capturing. So: two tasks, extract the word tokens, and count them! Done!\nThe reason this is tricky is that natural language text is messy: the task of extracting a clean set of tokens to count is termed text mining or tokenization. We would also like to get the output into a tidyverse compliant data frame, so we can use familiar dplyr and ggplot functions to analyze it.\nWe could imagine attacking this using stingr functions:\nlowell_tokens \u0026lt;- lowell %\u0026gt;% # convert upper to lower case; returns a character vector. str_to_lower() %\u0026gt;% # remove punctuation with a character class; returns a list. str_extract_all(\"[a-z]+\") %\u0026gt;% # flatten that list unlist() %\u0026gt;% # stick it in a data frame as_tibble() print(lowell_tokens, n = 38) #\u0026gt; # A tibble: 38 x 1 #\u0026gt; value  #\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 nautilus  #\u0026gt; 2 island  #\u0026gt; 3 s  #\u0026gt; 4 hermit  #\u0026gt; 5 heiress  #\u0026gt; 6 still  #\u0026gt; 7 lives  #\u0026gt; 8 through  #\u0026gt; 9 winter  #\u0026gt; 10 in  #\u0026gt; 11 her  #\u0026gt; 12 spartan  #\u0026gt; 13 cottage  #\u0026gt; 14 her  #\u0026gt; 15 sheep  #\u0026gt; 16 still  #\u0026gt; 17 graze  #\u0026gt; 18 above  #\u0026gt; 19 the  #\u0026gt; 20 sea  #\u0026gt; 21 her  #\u0026gt; 22 son  #\u0026gt; 23 s  #\u0026gt; 24 a  #\u0026gt; 25 bishop  #\u0026gt; 26 her  #\u0026gt; 27 farmer  #\u0026gt; 28 is  #\u0026gt; 29 first  #\u0026gt; 30 selectman #\u0026gt; 31 in  #\u0026gt; 32 our  #\u0026gt; 33 village  #\u0026gt; 34 she  #\u0026gt; 35 s  #\u0026gt; 36 in  #\u0026gt; 37 her  #\u0026gt; 38 dotage   This is a good start: it gets rid of the capitalization issue, and also gets rid of the punctuation. But there\u0026rsquo;s a problem. The regular expression pattern [a-z]+ doesn\u0026rsquo;t recognize possessives or contractions: it just strips anything that\u0026rsquo;s not a letter, so it messes up with Island's, son's, and she's: welcome to the subtleties of processing natural language text algorithmically! Exceptions, exceptions!!\nWe could fiddle about with our regex, but\u0026hellip; there\u0026rsquo;s a package for that! This kind of text mining is exactly what the tidytext package was built for. It will simultaneously strip punctuation intelligently and \u0026lsquo;unnest\u0026rsquo; lines into word tokens.\nTidytext functions need a dataframe to operate on. So first we need to get the poem into a data frame; here we\u0026rsquo;ll use the column name text.\nlowell_df \u0026lt;- tibble(text = lowell) lowell_df #\u0026gt; # A tibble: 5 x 1 #\u0026gt; text  #\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Nautilus Island's hermit  #\u0026gt; 2 heiress still lives through winter in her Spartan cottage;  #\u0026gt; 3 her sheep still graze above the sea.  #\u0026gt; 4 Her son's a bishop. Her farmer is first selectman in our village; #\u0026gt; 5 she's in her dotage.   Each string in the character vector becomes a single row in the data frame.\nAgain we want one word-token per row, to \u0026lsquo;tidy\u0026rsquo; our data. This is what tidytext::unnest_tokens() does. We\u0026rsquo;re going to unnest words in this case (we can unnest other things, like characters, sentences, regexes, even tweets) and we need to specify the variable in the dataframe we are unnesting (in this case just text). This will create a new word-token data frame, and we\u0026rsquo;ll name the variable in the data frame word. This is important (see later on stop words).\nlowell_tidy \u0026lt;- lowell_df %\u0026gt;% unnest_tokens(word, text) print(lowell_tidy, n = 35) #\u0026gt; # A tibble: 35 x 1 #\u0026gt; word  #\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 nautilus  #\u0026gt; 2 island's  #\u0026gt; 3 hermit  #\u0026gt; 4 heiress  #\u0026gt; 5 still  #\u0026gt; 6 lives  #\u0026gt; 7 through  #\u0026gt; 8 winter  #\u0026gt; 9 in  #\u0026gt; 10 her  #\u0026gt; 11 spartan  #\u0026gt; 12 cottage  #\u0026gt; 13 her  #\u0026gt; 14 sheep  #\u0026gt; 15 still  #\u0026gt; 16 graze  #\u0026gt; 17 above  #\u0026gt; 18 the  #\u0026gt; 19 sea  #\u0026gt; 20 her  #\u0026gt; 21 son's  #\u0026gt; 22 a  #\u0026gt; 23 bishop  #\u0026gt; 24 her  #\u0026gt; 25 farmer  #\u0026gt; 26 is  #\u0026gt; 27 first  #\u0026gt; 28 selectman #\u0026gt; 29 in  #\u0026gt; 30 our  #\u0026gt; 31 village  #\u0026gt; 32 she's  #\u0026gt; 33 in  #\u0026gt; 34 her  #\u0026gt; 35 dotage   Punctuation has been stripped and all words are lower case, but possessives and contractions are preserved (fancy usage of str_ regular expression functions under the hood\u0026hellip;).\nBakeoff! Now that we have the basic idea, let\u0026rsquo;s look at a more interesting data set, from the bakeoff package.\nFirst we\u0026rsquo;ll create a data frame with just the signature column from the bakes data set:\nsignature_df \u0026lt;- select(bakes, signature) signature_df #\u0026gt; # A tibble: 548 x 1 #\u0026gt; signature  #\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 \"Light Jamaican Black Cakewith Strawberries and Cream\"  #\u0026gt; 2 \"Chocolate Orange Cake\"  #\u0026gt; 3 \"Caramel Cinnamon and Banana Cake\"  #\u0026gt; 4 \"Fresh Mango and Passion Fruit Hummingbird Cake\"  #\u0026gt; 5 \"Carrot Cake with Lime and Cream Cheese Icing\"  #\u0026gt; 6 \"Cranberry and Pistachio Cakewith Orange Flower Water Icing\"  #\u0026gt; 7 \"Carrot and Orange Cake\"  #\u0026gt; 8 \"Sticky Marmalade Tea Loaf\"  #\u0026gt; 9 \"Triple Layered Brownie Meringue Cake\\nwith Raspberry Cream\"  #\u0026gt; 10 \"Three Tiered Lemon Drizzle Cakewith Fresh Cream and freshly made Lemon Curd\" #\u0026gt; # … with 538 more rows   Next we tokenize by word on the signature column:\nsignature_tidy \u0026lt;- signature_df %\u0026gt;% unnest_tokens(word, signature) signature_tidy #\u0026gt; # A tibble: 2,762 x 1 #\u0026gt; word  #\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 light  #\u0026gt; 2 jamaican  #\u0026gt; 3 black  #\u0026gt; 4 cakewith  #\u0026gt; 5 strawberries #\u0026gt; 6 and  #\u0026gt; 7 cream  #\u0026gt; 8 chocolate  #\u0026gt; 9 orange  #\u0026gt; 10 cake  #\u0026gt; # … with 2,752 more rows   Now we want to count those tokens: i.e. we want to collapse all duplicate word tokens into a single word type, with the corresponding frequency. Since we now have tidy data, dplyr to the rescue!\n dplyr count() lets you quickly count the unique values of one or more variables. The option sort, if TRUE, will show the largest groups at the top.\n signature_count \u0026lt;- signature_tidy %\u0026gt;% count(word, sort = TRUE) signature_count #\u0026gt; # A tibble: 806 x 2 #\u0026gt; word n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 and 321 #\u0026gt; 2 cake 66 #\u0026gt; 3 chocolate 61 #\u0026gt; 4 orange 42 #\u0026gt; 5 with 42 #\u0026gt; 6 pie 37 #\u0026gt; 7 apple 34 #\u0026gt; 8 ginger 30 #\u0026gt; 9 lemon 29 #\u0026gt; 10 biscuits 26 #\u0026gt; # … with 796 more rows   We\u0026rsquo;re way more interested in cake than and: this is an example of a stop word:\n In computing, stop words are words which are filtered out before or after processing of natural language data (text). \u0026ldquo;stop words\u0026rdquo; usually refers to the most common words in a language.\n  One of our major performance (search) optimizations\u0026hellip; is removing the top 10,000 most common English dictionary words (as determined by Google search). It\u0026rsquo;s shocking how little is left of most posts once you remove the top 10k English dictionary words\u0026hellip;\n The tidytext package has a database of just over a thousand of these words, including \u0026lsquo;and\u0026rsquo;:\nprint(stop_words, n = 30) #\u0026gt; # A tibble: 1,149 x 2 #\u0026gt; word lexicon #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 a SMART  #\u0026gt; 2 a's SMART  #\u0026gt; 3 able SMART  #\u0026gt; 4 about SMART  #\u0026gt; 5 above SMART  #\u0026gt; 6 according SMART  #\u0026gt; 7 accordingly SMART  #\u0026gt; 8 across SMART  #\u0026gt; 9 actually SMART  #\u0026gt; 10 after SMART  #\u0026gt; 11 afterwards SMART  #\u0026gt; 12 again SMART  #\u0026gt; 13 against SMART  #\u0026gt; 14 ain't SMART  #\u0026gt; 15 all SMART  #\u0026gt; 16 allow SMART  #\u0026gt; 17 allows SMART  #\u0026gt; 18 almost SMART  #\u0026gt; 19 alone SMART  #\u0026gt; 20 along SMART  #\u0026gt; 21 already SMART  #\u0026gt; 22 also SMART  #\u0026gt; 23 although SMART  #\u0026gt; 24 always SMART  #\u0026gt; 25 am SMART  #\u0026gt; 26 among SMART  #\u0026gt; 27 amongst SMART  #\u0026gt; 28 an SMART  #\u0026gt; 29 and SMART  #\u0026gt; 30 another SMART  #\u0026gt; # … with 1,119 more rows   Note that the name of the stop word column is word, and the name we used in our tokenized column is word (now you will see why we used that name) so we can use dplyr\u0026rsquo;s anti_join() to filter the word tokens!\n anti_join() returns all rows from x without a match in y (where x are the word tokens, and y are the stop words)\n signature_count \u0026lt;- signature_tidy %\u0026gt;% count(word, sort = TRUE) %\u0026gt;% anti_join(stop_words) #\u0026gt; Joining, by = \"word\" signature_count #\u0026gt; # A tibble: 762 x 2 #\u0026gt; word n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 cake 66 #\u0026gt; 2 chocolate 61 #\u0026gt; 3 orange 42 #\u0026gt; 4 pie 37 #\u0026gt; 5 apple 34 #\u0026gt; 6 ginger 30 #\u0026gt; 7 lemon 29 #\u0026gt; 8 biscuits 26 #\u0026gt; 9 loaf 22 #\u0026gt; 10 walnut 22 #\u0026gt; # … with 752 more rows   Since we are in the tidyverse, we can pipe our results into ggplot. First we filter on counts above a certain threshold (here 12, just for visualization purposes):\nsignature_count %\u0026gt;% filter(n \u0026gt; 12) %\u0026gt;% ggplot(aes(n, word)) + geom_col() + theme_minimal() + labs(y = NULL)   This is ordered alphabetically by default, bottom to top; but we can reorder by count (n) using dplyr mutate():\nsignature_count %\u0026gt;% filter(n \u0026gt; 12) %\u0026gt;% mutate(word = reorder(word, n)) %\u0026gt;% ggplot(aes(n, word)) + geom_col() + theme_minimal() + labs(y = NULL)   We now have everything we need for a word cloud: word types and their token frequencies:\nThe only obligatory arguments to wordcloud() are the first two: the rest just let you tweak the graphic:\nwordcloud(words = signature_count$word, freq = signature_count$n, min.freq = 12, random.order=FALSE, rot.per=0.3, colors=brewer.pal(8, \"Dark2\"))   min.freq lets you filter on a frequency threshold. random.order=FALSE plots words in decreasing frequency (highest most central); rot.per is the proportion of words with 90 degree rotation; colors=brewer.pal(8, \u0026quot;Dark2\u0026quot;) lets you choose an RColorBrewer color palette of your choice.\n Lemmatization\nIf you create a count data frame of signature_tidy without the sort = TRUE option, the words are sorted alphabetically. And if you look through that table you will see many instances such as apple, apples; apricot, apricots; cake, cakes etc. Arguably, these are the same word type (think \u0026ldquo;dictionary word\u0026rdquo;) just grammatical variations. Properly collapsing these into a single type is called lemmatization: a very difficult problem which would take us far afield into the morphology of words. Again in general there are many exceptions, only partly due to English borrowing so many words from other languages: besides apple, apples there is mouse, mice; self, selves; bacillus, bacilli; basis, bases. etc. These are known as irregular plurals.\nVerbs are worse! Perhaps you would also consider the inflectional forms run, runs, ran, running as the same type, just as a dictionary does. How do you reduce those algorithmically? And if you consider inflectional forms as the same dictionary word, how would you tackle Ancient Greek, which has hundreds of inflected forms for the same verb? Here are just a few, there are pages and pages of them\u0026hellip;\nCurrently machine learning has been unleashed on this problem, with limited success. The traditional computational linguists' algorithms are still winning\u0026hellip;\n  The gutenbergr package Say we wanted to do a word cloud for a more substantive text like Darwin\u0026rsquo;s Origin of Species.\nProject Gutenberg is a volunteer effort to digitize and archive cultural works and is the oldest digital library. It has over 60,000 books in the public domain (including Darwin\u0026rsquo;s works).\nThe gutenbergr package allows you to download any of these works directly into a data frame using just the Project Gutenberg ID. This is then perfect input for tidytext. The package provides all the metadata to search for author and work IDs inside R (you can also just find the ID by searching on the Project Gutenberg website):\ndarwins_works \u0026lt;- gutenberg_metadata %\u0026gt;% filter(author == \"Darwin, Charles\") darwins_works #\u0026gt; # A tibble: 40 x 8 #\u0026gt; gutenberg_id title author gutenberg_autho… language gutenberg_books… rights #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 944 \"The… Darwi… 485 en Travel/Harvard … Publi… #\u0026gt; 2 1227 \"The… Darwi… 485 en NA Publi… #\u0026gt; 3 1228 \"On … Darwi… 485 en Harvard Classic… Publi… #\u0026gt; 4 2009 \"The… Darwi… 485 en Harvard Classic… Publi… #\u0026gt; 5 2010 \"The… Darwi… 485 en NA Publi… #\u0026gt; 6 2087 \"Lif… Darwi… 485 en NA Publi… #\u0026gt; 7 2088 \"Lif… Darwi… 485 en NA Publi… #\u0026gt; 8 2300 \"The… Darwi… 485 en NA Publi… #\u0026gt; 9 2355 \"The… Darwi… 485 en NA Publi… #\u0026gt; 10 2485 \"The… Darwi… 485 en Botany Publi… #\u0026gt; # … with 30 more rows, and 1 more variable: has_text \u0026lt;lgl\u0026gt;   An inspection of the results of Origin of Species on the website reveals that the latest edition is ID 2009. Let\u0026rsquo;s grab it:\nOoS \u0026lt;- gutenberg_download(2009) #\u0026gt; Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest #\u0026gt; Using mirror http://aleph.gutenberg.org   In the breakout rooms, we\u0026rsquo;ll work through inspecting the frequencies and creating a word cloud for this text.\nThe gutenbergr package is extremely useful, but as long as you can read a document into R, you can then convert it to a data frame as we did in the very first example above, and then the tidytext pipeline will work. The readtext package can import a variety of formats, including PDFs and Microsoft Word documents.\nBreakout rooms Exercise 1 Run the command:\nOoS \u0026lt;- gutenberg_download(2009) and inspect the data frame. Identify the name of the column you want to tokenize.\nThen use the unnest_tokens() command to create a data frame of word tokens.\n  Hints (click here)  It's the text column you want. gutenbergr includes the gutenberg_ID in case you download multiple texts into the same data frame. Remember to name the column in the new data frame word so we can filter any stop words later on.    Solution (click here)  OoS \u0026lt;- gutenberg_download(2009) OoS #\u0026gt; # A tibble: 21,556 x 2 #\u0026gt; gutenberg_id text  #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 2009 \"1228 1859, First Edition\"  #\u0026gt; 2 2009 \"22764 1860, Second Edition\"  #\u0026gt; 3 2009 \"2009 1872, Sixth Edition, considered the definitive edition… #\u0026gt; 4 2009 \"\"  #\u0026gt; 5 2009 \"\"  #\u0026gt; 6 2009 \"\"  #\u0026gt; 7 2009 \"\"  #\u0026gt; 8 2009 \"On the Origin of Species\"  #\u0026gt; 9 2009 \"\"  #\u0026gt; 10 2009 \"BY MEANS OF NATURAL SELECTION,\"  #\u0026gt; # … with 21,546 more rows   OoS_tidy \u0026lt;- OoS %\u0026gt;% unnest_tokens(word, text) OoS_tidy #\u0026gt; # A tibble: 209,048 x 2 #\u0026gt; gutenberg_id word  #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 2009 1228  #\u0026gt; 2 2009 1859  #\u0026gt; 3 2009 first  #\u0026gt; 4 2009 edition #\u0026gt; 5 2009 22764  #\u0026gt; 6 2009 1860  #\u0026gt; 7 2009 second  #\u0026gt; 8 2009 edition #\u0026gt; 9 2009 2009  #\u0026gt; 10 2009 1872  #\u0026gt; # … with 209,038 more rows      Exercise 2 Count and sort the tokens into a new data frame. Inspect the output. Are there any stop words?\n  Hints (click here)  Pipe the word column of the data frame into the dplyr count() function with the sort = TRUE option.    Solution (click here)  OoS_count \u0026lt;- OoS_tidy %\u0026gt;% count(word, sort = TRUE) OoS_count #\u0026gt; # A tibble: 9,233 x 2 #\u0026gt; word n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 the 14570 #\u0026gt; 2 of 10438 #\u0026gt; 3 and 5853 #\u0026gt; 4 in 5414 #\u0026gt; 5 to 4753 #\u0026gt; 6 a 3368 #\u0026gt; 7 that 2749 #\u0026gt; 8 as 2230 #\u0026gt; 9 have 2114 #\u0026gt; 10 be 2099 #\u0026gt; # … with 9,223 more rows      Exercise 3 Remove the stop words from the output and inspect the results.\n  Hints (click here)  Use antijoin() with the tidytext stop_words data frame:    Solution (click here)  OoS_count \u0026lt;- OoS_tidy %\u0026gt;% count(word, sort = TRUE) %\u0026gt;% anti_join(stop_words) #\u0026gt; Joining, by = \"word\" OoS_count #\u0026gt; # A tibble: 8,678 x 2 #\u0026gt; word n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 species 1921 #\u0026gt; 2 forms 565 #\u0026gt; 3 selection 561 #\u0026gt; 4 natural 535 #\u0026gt; 5 varieties 486 #\u0026gt; 6 plants 471 #\u0026gt; 7 animals 436 #\u0026gt; 8 distinct 357 #\u0026gt; 9 life 350 #\u0026gt; 10 nature 325 #\u0026gt; # … with 8,668 more rows      Exercise 4 Visualize the counts using ggplot(), from highest frequency to lowest, using a frequency cutoff of 200. Does any one word stand out in any way?\nDoes the tidytext package perform lemmatization? Are there any irregular plurals in this result?\n  Hints (click here)  Use a dplyr filter() command on the n column, and, well just look at the examples in the presentation for the details of piping it into ggplot()!    Solution (click here)  OoS_count %\u0026gt;% filter(n \u0026gt; 200) %\u0026gt;% mutate(word = reorder(word, n)) %\u0026gt;% ggplot(aes(n, word)) + geom_col() + theme_minimal() + labs(y = NULL)   tidytext does not lemmatize. There are many plurals in this list, so undoubtedly there are corresponding singulars of lower frequency. Indeed we see both forms and form. And of course the irregular genera is the plural of genus.\n   Exercise 5 Create a word cloud of this data frame, with the same frequency cut off as the ggplot() (200). Otherwise use the same settings as in the presentation. Tweak those settings, especially the frequency threshold and rotation proportion. See what happens when you set random.order=TRUE.\n  Hints (click here)  The option for the the frequency threshold is min.freq = 200.    Solution (click here)  wordcloud(words = OoS_count$word, freq = OoS_count$n, min.freq = 200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, \"Dark2\"))      ","date":1618963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626742536,"objectID":"3d438db44d6a4c848a548ed0236c3266","permalink":"https://biodash.github.io/codeclub/19_wordclouds/","publishdate":"2021-04-21T00:00:00Z","relpermalink":"/codeclub/19_wordclouds/","section":"codeclub","summary":"Visualizing text frequency distributions","tags":null,"title":"Session 19: Word Clouds via Tidytext","type":"codeclub"},{"authors":["Mike Sovic"],"categories":null,"content":"\n New to Code Club?   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts. If you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n   Getting Set Up Like last week, we\u0026rsquo;re going to be working with functions from the stringr package, which is one of the core tidyverse packages, so let\u0026rsquo;s get that loaded first\u0026hellip;\n## If needed, install the tidyverse: # install.packages(\"tidyverse\") ## Load the tidyverse -- this will include loading \"stringr\".  library(tidyverse)   stringr has lots of useful functions for working with strings. Our focus here is on regular expressions, though, which represent just one component of working with strings. So, we\u0026rsquo;ll limit the number of stringr functions we work with to try to focus more on the regular expressions themselves. In the previous session, we worked primarily with the str_view_all() function. We\u0026rsquo;ll see a lot of that one again this week, and maybe a couple more as needed. Maybe we\u0026rsquo;ll do a stringr-focused session down the road to see more of what it offers, but in the meantime, you can check out the stringr cheatsheet here, which also includes some useful info on regular expressions, if you\u0026rsquo;re interested.\nIntro In case you missed last week, or could use a refresher, here\u0026rsquo;s a quick summary\u0026hellip;\n Regular expressions allow you to match specific patterns in text. These can be simple patterns, like matching \u0026lsquo;choco\u0026rsquo; in \u0026lsquo;chocolate\u0026rsquo;, or more complicated patterns, like matching only lines that end with any three or four digits. More complicated matches are possible because there are characters, or in some cases, combinations of characters, that have special meaning. These include the metacharacters, anchors, and quantifiers we saw last week, and they help us define more complicated patterns in text. Sometimes you want to turn the \u0026ldquo;special meaning\u0026rdquo; of things like metacharacters, anchors, and quantifiers off to instead interpret the characters literally. The backslash helps us in those cases, and in R, you typically need two of them.  Session Goals If regular expressions were new to you last week, it might have felt like a lot to digest. And this week we\u0026rsquo;re just going to add more. But don\u0026rsquo;t worry \u0026ndash; the idea really isn\u0026rsquo;t that you remember all of the special characters (metacharacters) and rules for matching patterns. Personally, I use regular expressions fairly often, and still don\u0026rsquo;t remember all of them all the time \u0026ndash; it\u0026rsquo;s easy enough to grab a cheat sheet and look up what you need to know. The more important thing for now is to just get a sense of the types of things regular expressions allow you to do. With that in mind, this week we\u0026rsquo;ll consider the following additional features/uses of regular expressions\u0026hellip;\n Character classes/Bracket expressions Alternation Grouping Backreferences Greediness/Non-Greediness  As we go through these, we\u0026rsquo;ll use the following string that contains made-up counts of 100 peoples' favorite ice cream flavor to see some examples of how they work\u0026hellip;\nour_string \u0026lt;- \"Chocolate-48,Vanilla-27,Strawberry-25\"   Character Classes/Bracket Expressions Regular expressions allow you to match certain classes of characters \u0026ndash; uppercase, lowercase, digits, alphanumeric, punctuation, etc. We actually saw some examples of character classes last week \u0026ndash; we just didn\u0026rsquo;t call them that. For example, the \u0026lsquo;\\d\u0026rsquo; metacharacter that matched any digit, and the \u0026lsquo;\\w\u0026rsquo; that matched any word character each represented character classes. Another way of defining character classes/sets is with bracket expressions. These can work in several ways. Basically, any characters defined inside square brackets are matched. So, if you wanted to match any digit, you could use\u0026hellip;\nstr_view_all(our_string, \"[01234556789]\", match = TRUE)    Ranges can also be defined inside the square brackets with a dash, so this would be equivalent to the expression above\u0026hellip;\nstr_view_all(our_string, \"[0-9]\", match = TRUE)    And if you want to match the dash, put it at the beginning\u0026hellip;\nstr_view_all(our_string, \"[-0-9]\", match = TRUE)    Many character classes have a descriptive term that can also be used if it\u0026rsquo;s bracketed by a colon on each side inside the brackets\u0026hellip;\nstr_view_all(our_string, \"[:digit:]\", match = TRUE)    Finally, the \u0026lsquo;^\u0026rsquo; can be used inside the brackets to negate the match. Notice the difference in how this character is interpreted here as compared to when we previously used it as an anchor (outside of the square brackets) \u0026ndash; CONTEXT MATTERS!\u0026hellip;\nstr_view_all(our_string, \"[^0-9]\", match = TRUE)    Alternation Alternation allows you to search for any of two or more patterns. This is achieved with the pipe symbol/vertical bar |, which is usually just above the Return key. Within regular expressions, it can be read as \u0026ldquo;or\u0026rdquo;. So, the expression \u0026ldquo;Chocolate|Vanilla\u0026rdquo; finds matches to either of these flavors\u0026hellip;\nstr_view_all(our_string, \"Chocolate|Vanilla\", match = TRUE)    And you can chain more than two of these together, as in \u0026ldquo;Chocolate|Vanilla|Strawberry\u0026rdquo;\u0026hellip;\nstr_view_all(our_string, \"Chocolate|Vanilla|Strawberry\", match = TRUE)    Grouping Grouping serves a couple main purposes in regular expressions. We\u0026rsquo;ll consider one here, and then a second in the context of backreferences in the next section. The quantifiers Jelmer introduced last week define the number of times the preceding character must occur. But what if you want to match a set of characters a specific number of times? They can be grouped by wrapping them in parentheses, so the quantifier applies to the entire set. We\u0026rsquo;ll use a new example string for this one - one from the DNA world. Sometimes strings of DNA contain short sequences of repeats, like the \u0026lsquo;ATC\u0026rsquo; repeat in the middle of this string\u0026hellip; GTACGGGATCATCATCATCATCGGATCCCAGT\ndna_string \u0026lt;- \"GTACGGGATCATCATCATCATCGGATCCCAGT\"   What if we wanted to find places where \u0026ldquo;ATC\u0026rdquo; was repeated at least 3 times in sequence?\nThis doesn\u0026rsquo;t give us what we want, since the quantifier is only being applied to the \u0026lsquo;C\u0026rsquo;\u0026hellip;\nstr_view_all(dna_string, \"ATC\u0026#123;3,\u0026#125;\", match = TRUE)    Instead, we can group the \u0026lsquo;ATC\u0026rsquo; with a set of parentheses to get the result we want\u0026hellip;\nstr_view_all(dna_string, \"(ATC)\u0026#123;3,\u0026#125;\", match = TRUE)    Backreferences Another place grouping comes in handy is with backreferences. But before we get to those, let\u0026rsquo;s get comfortable with a new function from stringr. So far, we\u0026rsquo;ve focused on using regular expressions just to search for patterns. But sometimes we want to not only find a pattern, but then replace it with something else. The str_replace() function can be thought of as an extension of str_view() that takes a third argument - the string that will be used to replace any match identified. So, say we had a mistake in the data, and \u0026ldquo;Strawberry\u0026rdquo; was actually supposed to be \u0026ldquo;Caramel\u0026rdquo;\u0026hellip;\nour_string #\u0026gt; [1] \"Chocolate-48,Vanilla-27,Strawberry-25\" str_replace(our_string, \"Strawberry\", \"Caramel\") #\u0026gt; [1] \"Chocolate-48,Vanilla-27,Caramel-25\"   Backreferences allow us to use the matches to (grouped) regex patterns as replacements. The characters matching each grouped regex pattern are temporarily assigned to variables (sequential numbers - i.e. the first matched group is assigned as 1, the second as 2, and so on), and can then be recalled with those numbers. Let\u0026rsquo;s go back to our ice cream string and use backreferences to reverse the order of the flavors in the string\u0026hellip;\n#view the current string our_string #\u0026gt; [1] \"Chocolate-48,Vanilla-27,Strawberry-25\" str_replace(our_string, \"(Chocolate-48),(Vanilla-27),(Strawberry-25)\", \"\\\\3,\\\\2,\\\\1\") #\u0026gt; [1] \"Strawberry-25,Vanilla-27,Chocolate-48\"   The first grouped match (Chocolate-48) got assigned to the variable \u0026lsquo;1\u0026rsquo;, the second (Vanilla-27) to \u0026lsquo;2\u0026rsquo;, and the third (Strawberry-25) to \u0026lsquo;3\u0026rsquo;. For the replacement, we just called these variables in reverse order. The notation to call these variables (backreferences) is often the combination of a single backslash and the number, but as Jelmer pointed out last week, in R, we need two backslashes.\nWe could also use metacharacters to do it like this (or many other ways for that matter)\u0026hellip;\nstr_replace(our_string, \"(C.*),(V.*),(S.*)\", \"\\\\3,\\\\1,\\\\2\") #\u0026gt; [1] \"Strawberry-25,Chocolate-48,Vanilla-27\"   Greediness By default, regular expression matches will be greedy, as in this example\u0026hellip;\nstr_view_all(our_string, \"C.+\\\\d\\\\d\")    Notice there are three possible valid matches to the search pattern here \u0026ndash; \u0026ldquo;Chocolate-48\u0026rdquo;, \u0026ldquo;Chocolate-48,Vanilla-27\u0026rdquo;, and the full string which is actually what gets matched. This is called greedy behavior - the longest valid match will be identified by default. You can add the \u0026lsquo;?\u0026rsquo; after a quantifier to make the match non-greedy\u0026hellip;\nstr_view_all(our_string, \"C.+?\\\\d\\\\d\")    So, in summary for today,\n Bracket expressions (square brackets) allow you to match anything inside them. Ranges can be defined with a dash. Notation is also available to define and match character classes \u0026ndash; things like digits, lowercase letters, punctuation, etc. The | means \u0026ldquo;or\u0026rdquo; \u0026ndash; use it to match one of two or more patterns. Parentheses can be used to group a set of characters/metacharacters into a single regex pattern. When grouped patterns match, they are assigned to a temporary numeric variable that can be used to recall the match, usually to use it in a replacement. If there is more than one valid match to a regex search pattern, the longest one will be returned by default. This \u0026ldquo;greedy\u0026rdquo; behavior can be reversed by adding a \u0026lsquo;?\u0026rsquo; after the relevant quantifier.  Like last week, we\u0026rsquo;ll use data from the Great British Bakeoff to practice with some of these things. If you didn\u0026rsquo;t install that dataset last week, you can get it with the following code\u0026hellip;\n## If needed, first install the \"remotes\" package: # install.packages(\"remotes\") remotes::install_github(\"apreshill/bakeoff\")   Then (everybody), load it\u0026hellip;\nlibrary(bakeoff)    Breakout rooms  Exercise 1 For the first few exercises, we\u0026rsquo;re going to work with the signature bakes found in the \u0026ldquo;signature\u0026rdquo; column of the \u0026ldquo;bakes\u0026rdquo; data frame. Assign the data from this column to an object names \u0026ldquo;sigs\u0026rdquo;. Preview it by viewing its first 3 items and getting its length.\n  Hints  Use the \u0026lsquo;$\u0026rsquo; notation to pull out the single column from the data frame, or alternatively a combination of dplyr\u0026rsquo;s select() followed by unlist(). Use square brackets to index the vector, and the length() function to get its length.\n   Solution  sigs \u0026lt;- bakes$signature sigs[1:3] #\u0026gt; [1] \"Light Jamaican Black Cakewith Strawberries and Cream\" #\u0026gt; [2] \"Chocolate Orange Cake\"  #\u0026gt; [3] \"Caramel Cinnamon and Banana Cake\" length(sigs) #\u0026gt; [1] 548       Exercise 2 Find all signature bakes that contain either raspberries or blueberries. Make sure to try to cover all the ways those ingredients might be reflected in the names.\n  Hints    Use the pipe symbol for alternation (OR)\n  Include possible variants such as raspberry, raspberries, Raspberry, etc.\n     Solution  str_view_all(sigs, \"[Rr]aspberr.+|[Bb]lueberr.+\", match = TRUE)        Exercise 3 Even if you\u0026rsquo;re not a millionaire, you\u0026rsquo;d like to try to eat like one. First, find all signature bakes that have \u0026ldquo;Millionaire\u0026rdquo; in the name. Then do a second search and limit the results to just those that start with \u0026ldquo;Millionaire\u0026rdquo;.\n  Hints   Use the appropriate anchor to limit results to those with \u0026ldquo;Millionaire\u0026rdquo; at the beginning of the name.     Solution  str_view_all(sigs, \"Millionaire\", match=TRUE)    str_view_all(sigs, \"^Millionaire\", match=TRUE)        Exercise 4 You tried each of the three signature bakes that start with \u0026ldquo;Millionaire\u0026rdquo;, and weren\u0026rsquo;t that impressed. Save these three bakes' names in the object \u0026lsquo;not_good\u0026rsquo; and then change the names of each of the three by replacing \u0026ldquo;Millionaire\u0026rdquo; with \u0026ldquo;Poor Man\u0026rdquo;. Assign the three new names to the object \u0026lsquo;renamed\u0026rsquo;. Note you\u0026rsquo;ll need a new stringr function for this exercise.\n  Hints  Use the str_subset() function to pull out the matching strings. Then use the str_replace() function we used in the examples for the replacement.\n   Solution  not_good \u0026lt;- str_subset(sigs, \"^Millionaire\") not_good #\u0026gt; [1] \"Millionaires' Shortbread\" \"Millionaire Banoffee Bonus\" #\u0026gt; [3] \"Millionaire's Roulade\" renamed \u0026lt;- str_replace_all(not_good, \"Millionaire\", \"Poor Man\") renamed #\u0026gt; [1] \"Poor Mans' Shortbread\" \"Poor Man Banoffee Bonus\" #\u0026gt; [3] \"Poor Man's Roulade\"       Bonus 1 For the bonus, let\u0026rsquo;s work with a different part of the dataset. The \u0026lsquo;bakers\u0026rsquo; data frame includes a column named \u0026lsquo;baker_full\u0026rsquo; that has the full name of each baker. First, extract that column and save it as the object \u0026lsquo;baker_names\u0026rsquo;. Then preview the first 5 names in this vector.\n  Hints  Use the \u0026lsquo;$\u0026rsquo; and [ ] notations.\n   Solution  baker_names \u0026lt;- bakers$baker_full baker_names[1:5] #\u0026gt; [1] \"Annetha Mills\" \"David Chambers\" \"Edward \\\"Edd\\\" Kimber\" #\u0026gt; [4] \"Jasminder Randhawa\" \"Jonathan Shepherd\"       Bonus 2 Notice from the first 5 entries of \u0026lsquo;baker_names\u0026rsquo; that the names are ordered as first name then last name, with potentially a middle name, or nickname, in between. Try reordering the names so they read last name, comma, first (and middle, if applicable). Assign the new names to \u0026lsquo;baker_names_rev\u0026rsquo;.\n  Hints  Use grouping and backreferences.\n   Solution  baker_names_rev \u0026lt;- str_replace(baker_names, \"(.+)(\\\\s[:alpha:]+)\", \"\\\\2, \\\\1\") baker_names_rev[1:5] #\u0026gt; [1] \" Mills, Annetha\" \" Chambers, David\"  #\u0026gt; [3] \" Kimber, Edward \\\"Edd\\\"\" \" Randhawa, Jasminder\"  #\u0026gt; [5] \" Shepherd, Jonathan\"      ","date":1618185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618512594,"objectID":"a85a2a284ea62b5cc185c9c5e88d0488","permalink":"https://biodash.github.io/codeclub/18_regex2/","publishdate":"2021-04-12T00:00:00Z","relpermalink":"/codeclub/18_regex2/","section":"codeclub","summary":"Building on last week, we'll take regular expressions to a second level.","tags":null,"title":"Session 18: Regular Expressions: Part II","type":"codeclub"},{"authors":["Jelmer Poelstra"],"categories":null,"content":"\n New to Code Club?   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n   1. Getting set up While base R also has functions to work with regular expressions (such as grep() and regexp()), we will work with the stringr package, one of the core tidyverse packages.\n## If needed, install the tidyverse: # install.packages(\"tidyverse\") ## Load the tidyverse -- this will include loading \"stringr\".  library(tidyverse)   To get access to some strings that we can match with regular expressions, we will use the bakeoff data package:\n## If needed, first install the \"remotes\" package: # install.packages(\"remotes\") remotes::install_github(\"apreshill/bakeoff\")   library(bakeoff)    2. Regular expressions: what and why? You would probably have no trouble recognizing internet and email addresses, most phone numbers, or a DNA sequence embedded in a piece of text. And you would do so even if these were presented without context, and even though you may have never seen that specific email address, DNA sequence, and so on.\nWe can recognize these things because they adhere to certain patterns: a DNA sequence, for instance, typically consists of a sequence of capital As, Cs, Gs, and Ts.\nRegular expressions provide a way to describe and match text that contains specific patterns to computers, with expressions that convey things like \u0026ldquo;any digit\u0026rdquo; and \u0026ldquo;one or more or the previous character or character type\u0026rdquo;. For example, \\d{5} is a regular expression that matches at least five consecutive digits and would be a good start to finding all US ZIP codes contained in some text.\nRegular expressions are extremely useful for a couple of related purposes:\n  Finding and extracting information that adheres to patterns\n  Finding addresses, citations, or identifiers such as accession numbers.\n  Finding degenerate primers (or the DNA sequence between them) or transcription factor binding sites, in which certain positions may vary.\n  Finding DNA repeats: you know that something is repeated, but not what is.\n  While we often generalize and constrain matches at the same time, we could also merely constrain them:\n  Only find instances of \u0026ldquo;chocolate\u0026rdquo; if it is the first or last word of a line/sentence/string.\n  Only find instances of \u0026ldquo;chocolate\u0026rdquo; which are followed by \u0026ldquo;cake\u0026rdquo;, \u0026ldquo;tart\u0026rdquo;, or \u0026ldquo;croissant\u0026rdquo;.\n        Sophisticated find-and-replace\n  Replace multiple variations of the same thing at once:\ne.g. change all DNA repeats to lowercase letters or Ns.\n  Change a date format from M/DD/YY to YYYY-MM-DD, or GPS coordinates in degrees/minutes/seconds format to decimal degrees (note that this needs a bit of conversion too).\n  Rename files: switch sample ID and treatment ID separated by underscores,\nor pad numbers (1-100 =\u0026gt; 001-100 for proper ordering).\n    Finally, regular expressions can be used to parse and convert file formats, though you generally don\u0026rsquo;t have to do this yourself unless you are dealing with highly custom file types.\nRegular expressions are used in nearly all programming languages. They are also widely used in text editors and therefore provide a first taste of programming for many people.\n 3. str_view() and strings Today, to get to know regular expressions, we will just use the str_view() function from the stringr package. Next week, we\u0026rsquo;ll get introduced to other stringr functions to search and also to replace strings.\nThe basic syntax is str_view(\u0026lt;target-string(s)\u0026gt;, \u0026lt;search-pattern\u0026gt;), for example:\nstr_view(\"chocolate\", \"cola\")    str_view() shows us which part of the target string was matched in the Viewer pane of RStudio. This particular match is rather obvious because we searched for a \u0026ldquo;literal string\u0026rdquo; without any special meaning. However, the visual representation will become useful when we start using special characters in our regular expressions: then, we know what pattern we should be matching, but not what exact string we actually matched.\nIf we want to see all matches, and not just the first one, we have to use str_view_all:\nstr_view(\"chocolate\", \"o\")    str_view_all(\"chocolate\", \"o\")    stringr functions are vectorized, so we can use them not just to match a single string but also to match a vector of strings:\nbakes \u0026lt;- c(\"plum pudding\", \"chocolate cake\", \"sticky toffee pudding\") str_view(bakes, \"pudding\")    Note that the non-matching string \u0026ldquo;chocolate cake\u0026rdquo; was displayed despite the lack of a match. If we only want to see strings that matched, we can set the match argument to TRUE:\n str_view(bakes, \"pudding\", match = TRUE)     Strings in R\nA \u0026ldquo;string\u0026rdquo; or \u0026ldquo;character string\u0026rdquo; is a contiguous sequence of characters. To indicate that something is a string in R, we put quotes around it: \u0026quot;Hello\u0026quot; and \u0026quot;9\u0026quot;. If you forget the quotes, R would interpret \u0026quot;Hello\u0026quot; as an object (because it starts with a letter) and \u0026quot;9\u0026quot; as a number (because it starts with a digit).\nThere is no difference between single quotes ('Hello') and double quotes (\u0026quot;Hello\u0026quot;), but double quotes are generally recommended.\nIf your string is itself supposed to contain a quote symbol of some kind, it is convenient to use the other type of quote to define the string:\n# The string contains a single quote, so we use double quotes to define it: \"This cake's 7th layer is particularly good.\" #\u0026gt; [1] \u0026ldquo;This cake\u0026rsquo;s 7th layer is particularly good.\u0026quot; \n Alternatively, a quote can be escaped using a backslash \\ to indicate that it does not end the string but represents a literal quote inside the string, which may be necessary if a string contains both single and double quotes:\n\"This cake is only 2'4\\\" tall - do better!\" #\u0026gt; [1] \u0026ldquo;This cake is only 2'4\u0026quot; tall - do better!\u0026quot; \n    4. Special characters Special characters and escaping them In regular expressions (regex), we need a way to succinctly convey descriptions such as \u0026ldquo;any character\u0026rdquo; or \u0026ldquo;any digit\u0026rdquo;. However, there are no characters exclusive to regular expressions: instead, we re-use normal characters. For instance:\n \u0026ldquo;Any digit\u0026rdquo; is represented by \\d, with the \\ basically preventing the d from being interpreted literally. \u0026ldquo;Any character\u0026rdquo; is represented by a period, .  How, then, do we indicate a literal period . in a regular expression? The solution is to escape it with a backslash: the regular expression \\. matches a period ..\n TLDR for the rest of this section When writing regular expressions as strings in R, we always need to add an extra backslash:\n The regex \\d matches a digit \u0026mdash; and we write it as \u0026quot;\\\\d\u0026quot; in R. The regex \\. matches a period \u0026mdash; and we write it as \u0026quot;\\\\.\u0026quot; in R.    The \u0026ldquo;escaping\u0026rdquo; described above also applies to backslashes, such that the regex \\\\ matches a \\.\nEscape sequences in regular strings Outside of regular expressions, R also uses backslashes \\ to form so-called \u0026ldquo;escape sequences\u0026rdquo;. This works similarly to how the regular expression \\d means \u0026ldquo;any digit\u0026rdquo; \u0026ndash; for example, when we use \\n in any string, it will be interpreted as a newline:\ncat(\"cho\\nco\") #\u0026gt; cho #\u0026gt; co   In fact, a single backslash \\ is never taken literally in any regular R string:\ncat(\"cho\\dco\") #\u0026gt; Error: '\\d' is an unrecognized escape in character string starting \"\"cho\\d\"   Because this is not a regular expression, and \\d does not happen to be an escape sequence like \\n was earlier, \\d doesn\u0026rsquo;t mean anything to R. But instead of assuming that the backslash is therefore a literal backslash, R throws an error, demonstrating that a backslash is always interpreted as the first character in an escape sequence.\nHow can we include a backslash in a string, then? Same as before: we \u0026ldquo;escape\u0026rdquo; it with another backslash:\ncat(\"bla\\\\dbla\") #\u0026gt; bla\\dbla   The backslash plague We saw that the regular expression \\d matches a digit, but also that using string \u0026quot;\\d\u0026quot; will merely throw an error!\nTherefore, to actually define a regular expression that contains \\d, we need to use the string \u0026quot;\\\\d\u0026quot;:\nstr_view(\"The cake has 8 layers\", \"\\d\") #\u0026gt; Error: '\\d' is an unrecognized escape in character string starting \"\"\\d\"   str_view(\"The cake has 8 layers\", \"\\\\d\")    So, to define any regular expression symbol that contains a backslash, we need to always use two backslashes!\nThis also applies when we want to match a literal character. For example, to match a literal period, we need the regex \\., which we have to write as \\\\. in an R string:\nstr_view(\"The cake has 8.5 layers\", \"\\\\.\")    Now to the worst case: what if we want to match a backslash? We need the regular expression \\\\, but to define that regex as a string, we have to escape each of the two backslashes \u0026ndash; only to end up with four backslashes!\nstr_view(\"C:\\\\Windows\", \"\\\\\") #\u0026gt; Error in stri_locate_first_regex(string, pattern, opts_regex = opts(pattern)): Unrecognized backslash escape sequence in pattern. (U_REGEX_BAD_ESCAPE_SEQUENCE, context=`\\`)   str_view(\"C:\\\\Windows\", \"\\\\\\\\\")    Welcome to the backslash plague! 1\n 5. The Great British Bake Off Let\u0026rsquo;s take a look at some of the data in the bakeoff package, which is about \u0026ldquo;The Great British Bake Off\u0026rdquo; (GBBO) television show.\nThe bakers dataframe contains some information about each participant (baker) in the show, and we will be matching names from the baker_full column:\nhead(bakers) #\u0026gt; # A tibble: 6 x 8 #\u0026gt; series baker_full baker age occupation hometown baker_last baker_first #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 1 \"Annetha Mi… Annet… 30 Midwife Essex Mills Annetha  #\u0026gt; 2 1 \"David Cham… David 31 Entrepreneur Milton K… Chambers David  #\u0026gt; 3 1 \"Edward \\\"E… Edd 24 Debt collec… Bradford Kimber Edward  #\u0026gt; 4 1 \"Jasminder … Jasmi… 45 Assistant C… Birmingh… Randhawa Jasminder  #\u0026gt; 5 1 \"Jonathan S… Jonat… 25 Research An… St Albans Shepherd Jonathan  #\u0026gt; 6 1 \"Lea Harris\" Lea 51 Retired Midlothi… Harris Lea   The challenge_results dataframe contains \u0026ldquo;signature\u0026rdquo; and \u0026ldquo;showstopper\u0026rdquo; bakes made by each participant in each episode:\nhead(challenge_results) #\u0026gt; # A tibble: 6 x 7 #\u0026gt; series episode baker result signature technical showstopper  #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 1 1 Annet… IN Light Jamaican … 2 Red, White \u0026amp; Blue Cho… #\u0026gt; 2 1 1 David IN Chocolate Orang… 3 Black Forest Floor Ga… #\u0026gt; 3 1 1 Edd IN Caramel Cinnamo… 1 NA  #\u0026gt; 4 1 1 Jasmi… IN Fresh Mango and… NA NA  #\u0026gt; 5 1 1 Jonat… IN Carrot Cake wit… 9 Three Tiered White an… #\u0026gt; 6 1 1 Louise IN Carrot and Oran… NA Never Fail Chocolate …   The \u0026ldquo;signature\u0026rdquo; bakes are the first bakes presented in each GBBO episode, so we\u0026rsquo;ll start trying to match these bakes with regular expressions. Let\u0026rsquo;s save them in a vector for easy access later on:\nsignatures \u0026lt;- challenge_results$signature # Assign the column to a vector signatures \u0026lt;- signatures[!is.na(signatures)] # Remove NAs signatures[1:20] # Look at the first 20 items #\u0026gt; [1] \"Light Jamaican Black Cakewith Strawberries and Cream\"  #\u0026gt; [2] \"Chocolate Orange Cake\"  #\u0026gt; [3] \"Caramel Cinnamon and Banana Cake\"  #\u0026gt; [4] \"Fresh Mango and Passion Fruit Hummingbird Cake\"  #\u0026gt; [5] \"Carrot Cake with Lime and Cream Cheese Icing\"  #\u0026gt; [6] \"Carrot and Orange Cake\"  #\u0026gt; [7] \"Triple Layered Brownie Meringue Cake\\nwith Raspberry Cream\"  #\u0026gt; [8] \"Three Tiered Lemon Drizzle Cakewith Fresh Cream and freshly made Lemon Curd\" #\u0026gt; [9] \"Cranberry and Pistachio Cakewith Orange Flower Water Icing\"  #\u0026gt; [10] \"Sticky Marmalade Tea Loaf\"  #\u0026gt; [11] \"Cheddar Cheese and Fresh Rosemary Biscuits\"  #\u0026gt; [12] \"Oatmeal Raisin Cookie\"  #\u0026gt; [13] \"Millionaires' Shortbread\"  #\u0026gt; [14] \"Honey and Candied Ginger Cookies\"  #\u0026gt; [15] \"Fresh Vanilla Biscuits with Royal Icing\"  #\u0026gt; [16] \"Peanut Shortbread withSalted Peanut Caramel\"  #\u0026gt; [17] \"Rose Petal Shortbread\"  #\u0026gt; [18] \"Stained Glass Window Shortbread\"  #\u0026gt; [19] \"Chilli Bread\"  #\u0026gt; [20] \"Olive Bread\"    6. Components of regular expressions Literal characters Literal characters can be a part of regular expressions. In fact, as we saw in the first example, our entire search pattern for str_view() can perfectly well consist of only literal characters.\nBut the power of regular expressions comes with special characters, and below, we\u0026rsquo;ll go through several different categories of these.\nMetacharacters Metacharacters often represent a single instance of a character type: above, we already learned that . matches any single character.\nOther metacharacters are actually character combinations starting with a \\:\n   Symbol Matches Negation (\u0026ldquo;anything but\u0026rdquo;)     . Any single character.    \\d Any digit. \\D   \\s Any white space: space, tab, newline, carriage return. \\S   \\w Any word character: alphanumeric and underscore. \\W   \\n A newline.    \\t A tab.     Negated metacharacters match anything except that character type: \\D matches anything except a digit.\nSome examples:\n  Are there any digits (\\d) in the bake names?\nstr_view_all(signatures, \"\\\\d\", match = TRUE)        Let\u0026rsquo;s match 5-character strings that start with \u0026ldquo;Ma\u0026quot;:\nstr_view_all(signatures, \"Ma...\", match = TRUE)    Note that the only constraint we are setting with ... is that at least three characters should follow Ma \u0026ndash; we are not restricting matches to five-character words.\n    Let\u0026rsquo;s find the bakers whose (first or last) names contain at least 11 word characters \\w:\nstr_view_all(bakers$baker_full, \"\\\\w\\\\w\\\\w\\\\w\\\\w\\\\w\\\\w\\\\w\\\\w\\\\w\\\\w\", match = TRUE)    It\u0026rsquo;s not very convenient to have to repeat \\\\w so many times!\n  Or let\u0026rsquo;s say we wanted to get all three-part names: names that contain three sets of one or more word characters separated by non-word characters. How could we describe such a pattern? \u0026ldquo;Quantifiers\u0026rdquo; to the rescue!\nQuantifiers Quantifiers describe how many consecutive instances of the preceding character should be matched:\n   Quantifier Matches     * Preceding character any number of times (0 or more).   + Preceding character at least once (1 or more).   ? Preceding character at most once (0 or 1).   {n} Preceding character exactly n times.   {n,} Preceding character at least n times.   {n,m} Preceding character at least n and at most m times.    Some examples:\n  Names with at least 11 ({11,}) characters \u0026ndash; note that this matches the entire word:\nstr_view(bakers$baker_full, \"\\\\w\u0026#123;11,\u0026#125;\", match=TRUE)        Match names with 2 to 3 ({2,3}) consecutive \u0026ldquo;e\u0026rdquo; characters. Note that this match encompasses the full string (name), because we flank the pattern with .*.\nstr_view(bakers$baker_full, \".*e\u0026#123;2,3\u0026#125;.*\", match=TRUE)        Account for different spelling options with ? \u0026ndash; match \u0026ldquo;flavor\u0026rdquo; or \u0026ldquo;flavour\u0026quot;:\nstr_view_all(signatures, \"flavou?r\", match=TRUE)        Match all three-part names \u0026ndash; one or more word characters (\\w+) separated by a non-word character (\\W) at least two consecutive times:\nstr_view(bakers$baker_full, \"\\\\w+\\\\W\\\\w+\\\\W\\\\w+\", match=TRUE)        Match all three-letter names by looking for non-word characters (\\W) surrounding three word characters (\\w{3})?\nstr_view_all(bakers$baker_full, \"\\\\W\\\\w\u0026#123;3\u0026#125;\\\\W\", match = TRUE)      That last attempt didn\u0026rsquo;t really work \u0026ndash; note that we only got three-letter middle names, since we required our three-letter names to be flanked by non-word characters.\nTo get all three-letter names, we need to be able to \u0026ldquo;anchor\u0026rdquo; our regular expressions, e.g. demand that a pattern starts at the beginning of the string.\nAnchors    Anchor Matches     ^ Beginning of the string/line   $ End of the string/line   \\b A word boundary (beginning or end)    Some examples:\n  Match all three-letter first names, by anchoring the three word characters (\\w{3}) to the beginning of the string with ^, and including a space at the end:\nstr_view(bakers$baker_full, \"^\\\\w\u0026#123;3\u0026#125; \", match = TRUE)      Match all three-letter names \u0026ndash;whether first, middle, or last\u0026ndash; using three word-characters (\\w) surrounded by word-boundaries (\\b):\nstr_view_all(bakers$baker_full, \"\\\\b\\\\w\u0026#123;3\u0026#125;\\\\b\", match = TRUE)      Regex components for next week Next week, we\u0026rsquo;ll talk about:\n Character classes Alternation Grouping Backreferences Making quantifiers non-greedy   Regular expressions vs globbing\nDo not confuse regular expressions with globbing!\nIf you have worked in a terminal before, you may know that you can match file names using shell wildcards, which is known as \u0026ldquo;globbing\u0026rdquo;.\nThere are only a few characters used in shell wildcards, but their meanings differ from regular expressions in two instances!\n   Shell wildcard Equivalent regex Meaning     ? . Any single character   * .* Any number of any character   [] and [^] same! Match/negate match of character class     Note also that . is interpreted as a literal period in globbing. We will talk about \u0026ldquo;character classes\u0026rdquo; next week.     7. Breakout rooms  Exercise 1 Find all participant names in bakers$baker_full that contain at least 4 lowercase \u0026ldquo;e\u0026rdquo; characters. (That, the \u0026ldquo;e\u0026ldquo;s don\u0026rsquo;t need to be consecutive, but you should not disallow consecutive \u0026ldquo;e\u0026ldquo;s either.)\n  Hints  Use .* to allow for optional characters in between the \u0026ldquo;e\u0026quot;s.\n   Solution  str_view(bakers$baker_full, \"e.*e.*e.*e\", match = TRUE)        Exercise 2 In the signatures vector, match words of exactly five characters that start with \u0026ldquo;Ta\u0026rdquo;.\n  Hints    To describe the five-letter word you should include three word characters after \u0026ldquo;Ta\u0026rdquo;.\n  To exclusively match five-letter words, you should use the \u0026ldquo;word boundary\u0026rdquo; anchor before and after the part that should match the word.\n     Solution  str_view_all(signatures, \"\\\\bTa\\\\w\u0026#123;3\u0026#125;\\\\b\", match = TRUE)        Exercise 3 Match \u0026ldquo;Donut\u0026rdquo; as well as \u0026ldquo;Doughnut\u0026rdquo; in the signatures vector.\nUnfortunately, signatures only contains the spelling \u0026ldquo;Doughnut\u0026rdquo;. Therefore, you should separately test whether your regex would actually match \u0026ldquo;Donut\u0026rdquo;.\n  Hints  Since \u0026ldquo;donut\u0026rdquo; is contained within \u0026ldquo;doughnut\u0026rdquo;, you can build a single regex and use ? to indicate optional characters.\n   Solution  str_view_all(signatures, \"Dou?g?h?nut\", match=TRUE)    str_view_all(c(signatures, \"Donut\"), \"Dou?g?h?nut\", match=TRUE)        Exercise 4 Match both dates in the string: \u0026ldquo;The best cakes were baked between 2016-03-10 and 2017-08-31.\u0026rdquo;.\n  Hints  Make sure you use str_view_all() and not str_view()!\n   Solution  mystring \u0026lt;- \"The best cakes were baked between 2016-03-10 and 2017-08-31.\" str_view_all(mystring, \"\\\\d\u0026#123;4\u0026#125;-\\\\d\u0026#123;2\u0026#125;-\\\\d\u0026#123;2\u0026#125;\")        Bonus exercise You can use the list.files() function in R to list files on your computer. list.files() takes an argument pattern to which you can specify a regular expression in order to narrow down the results.\nFor example, the code below would find all files with \u0026ldquo;codeclub\u0026rdquo; in the name, from your current working directory (the default for the path argument) and downwards (due to recursive = TRUE):\nlist.files(pattern = \"codeclub\", recursive = TRUE)   You can also specify a path \u0026ndash; for instance, the code below would search your home or (on Windows) Documents directory and nothing below it:\nlist.files(path = \"~\", pattern = \"codeclub\") # \"~\" is your home dir list.files(path = \"C:/Users/myname/Documents\", pattern = \"codeclub\")   Use this function to list only R scripts, i.e. files ending in .R, in a directory of your choice.\n  Hints  Make sure to use the \u0026ldquo;end of string\u0026rdquo; anchor.\n   Solution  Here we are searching the the home dir and everything below it \u0026ndash; could take a while, but then you know how many R scripts you actually have!\nlist.files(path = \"~\", pattern = \"\\\\.R$\", recursive = TRUE)       8. Further resources   The chapter on strings in Hadley Wickham\u0026rsquo;s R for Data Science (freely abailable online!).\n  RStudio regex cheatsheet.\n  A course video by Roger Peng introducing regular expressions.\n  RegExplain, an RStudio add-in to visualize regex matches and help build regular expressions.\n    Since R 4.0, which was released last year, there is also a \u0026ldquo;raw string\u0026rdquo; or \u0026ldquo;raw character constant\u0026rdquo; construct, which circumvents some of these problems \u0026ndash; see this blogpost that summarizes this new syntax. Because many are not yet using R 4.x, and most current examples, vignettes, and tutorials on the internet don\u0026rsquo;t use this, we will stick to being stuck with all the backslashes for now. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1617667200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617993294,"objectID":"7360016f393c20d38ce9f0d2a030289c","permalink":"https://biodash.github.io/codeclub/17_regex/","publishdate":"2021-04-06T00:00:00Z","relpermalink":"/codeclub/17_regex/","section":"codeclub","summary":"In the first in a mini-series on working with strings in R, we will learn some basics of regular expressions.","tags":null,"title":"Session 17: Introduction to regular expressions","type":"codeclub"},{"authors":["Stephen Opiyo"],"categories":null,"content":"\n New to Code Club?   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n   1. Getting set up R has a range of functions that allow you to work with dates and times. However, today we will discuss how to work with dates and times in R using the package \u0026ldquo;lubridate\u0026rdquo;.\nWhile lubridate is tidyverse-style, it is not part of the core tidyverse, so we need to install it.\nWe are also going to use the bird data that was first discussed in Code Club session 1, and we will need to download that.\n# If needed, install the lubridate package: # install.packages(\"lubridate\") # Load the tidyverse and lubridate: library(tidyverse) library(lubridate)   # Create a dir for our bird data (\"recursive\" to create two levels at once): dir.create(\"data/birds/\", recursive = TRUE) # The URL to our file: birds_file_url \u0026lt;- \"https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv\" # The path to the file that we want to download the data to: birds_file \u0026lt;- \"data/birds/backyard-birds_Ohio.tsv\" # Download: download.file(url = birds_file_url, destfile = birds_file) # Read the data: birds \u0026lt;- read_tsv(file = birds_file)     2. What is lubridate? lubridate provides tools that make it easier to parse and manipulate dates.\nWe will discuss the common use of lubridate under the following themes:\n  Parsing dates\n  Manipulating dates\na) Instants: Rounding dates, time zones\nb) Time spans: Durations, periods, intervals\n   3. Parsing dates lubridate\u0026rsquo;s parsing functions read strings into R as \u0026ldquo;date-time\u0026rdquo; objects. Year is represented by y, month by m, and day by d.\nStrings can be parsed using the following functions: dmy(), myd(), ymd(), ydm(), dym(), mdy(), ymd_hms().\nLet us look at some examples\n# parsing by year, month, day ymd(20170131) #\u0026gt; [1] \"2017-01-31\" # parsing by month, day, year mdy(\"December 1st, 2020\") #\u0026gt; [1] \"2020-12-01\" # parsing by day, month, year dmy(\"01-Dec-2020\") #\u0026gt; [1] \"2020-12-01\" dmy(\"01/Dec/2020\") #\u0026gt; [1] \"2020-12-01\" dmy(\"01Dec2020\") #\u0026gt; [1] \"2020-12-01\" # parsing by year, month, day, hour, minutes, and seconds ymd_hms(\"2020-01-31 20:11:59\") #\u0026gt; [1] \"2020-01-31 20:11:59 UTC\"    4. Manipulating dates: Instants lubridate distinguishes between moments in time (instants) and spans of time (time spans).\nInstants are specific moments of time. They are a combination of measurements on different units (i.e, years, months, days, etc.).\n now() returns the current system time. today() returns the current system date.  The individual values for now() and today() units can be extracted from an instant and set with the accessor functions second(), minute(), hour(), day(), yday(), mday(), wday(), week(), month(), and year().\nLet us look at some examples\n# Find the current system date using function today () today() #\u0026gt; [1] \"2021-07-19\" # Find the current system time using function now () Now \u0026lt;- now() Now #\u0026gt; [1] \"2021-07-19 20:54:27 EDT\" # Extract the day of the month from an object Now using function mday () mday(Now) #\u0026gt; [1] 19 # Extract the day of the week from an object Now using function wday() wday(Now) #\u0026gt; [1] 2 # Extract the week of the year from an object Now using function week () week(Now) #\u0026gt; [1] 29 # Extract the month from an object Now using function month () month(Now) #\u0026gt; [1] 7 # Extract the year from an object Now using function year () year(Now) #\u0026gt; [1] 2021   Rounding instants Instants can be rounded to a convenient unit using the functions ceiling_date(), floor_date(), and round_date().\n  ceiling_date() takes a date-time object and rounds it up to the nearest boundary of the specified time unit.\n  round_date() takes a date-time object and time unit, and rounds it to the nearest value of the specified time unit.\n  floor_date() takes a date-time object and rounds it down to the nearest boundary of the specified time unit.\n  Let us look at some examples\nceiling_date(Now, unit = \"minute\") #\u0026gt; [1] \"2021-07-19 20:55:00 EDT\" round_date(Now, unit = \"minute\") #\u0026gt; [1] \"2021-07-19 20:54:00 EDT\" floor_date(Now, unit = \"minute\") #\u0026gt; [1] \"2021-07-19 20:54:00 EDT\"   Time zones Naming time zones is challenging because everyday names of time zones tend to be ambiguous. For example, USA has EST, or Eastern Standard Time. However, both Australia and Canada also have EST!\nTo avoid confusion, R uses the international standard IANA time zones. These use a consistent naming scheme \u0026ldquo;/\u0026rdquo;, typically in the form \u0026lt;continent\u0026gt;/\u0026lt;city\u0026gt; (there are a few exceptions because not every country lies on a continent). Examples include America/New_York, Europe/Paris, and Pacific/Auckland.\nUnless otherwise specified, lubridate always uses UTC. UTC (Coordinated Universal Time) is the standard time zone used by the scientific community and roughly equivalent to its predecessor GMT (Greenwich Mean Time).\nExample: ymd_hms(\u0026quot;2021-03-27 11:54:54 EDT\u0026quot;, tz=\u0026quot;America/New_York\u0026quot;)\nTo find your current time zone, use the Sys.timezone() function:\nSys.timezone() #\u0026gt; [1] \"America/New_York\"   To see the complete list of all time zone names, use OlsonNames():\n# See the first four time zones in the list of the time zone head(OlsonNames(), 4) #\u0026gt; [1] \"Africa/Abidjan\" \"Africa/Accra\" \"Africa/Addis_Ababa\" #\u0026gt; [4] \"Africa/Algiers\"   lubridate has two functions for working with time zones:\n  with_tz(): Changes the time zone in which an instant is displayed. The clock time displayed for the instant changes, but the moment of time described remains the same.\n  force_tz(): Changes only the time zone element of an instant. The clock time displayed remains the same, but the resulting instant describes a new moment of time.\n  x1 \u0026lt;- now() # An example using with_tz() x1a \u0026lt;- with_tz(x1, tzone = \"Australia/Lord_Howe\") x1 - x1a #\u0026gt; Time difference of 0 secs # Now use force_tz() x1b \u0026lt;- force_tz(x1, tzone = \"Australia/Lord_Howe\") x1 - x1b #\u0026gt; Time difference of 14.5 hours    4. Manipulating dates: Time spans A timespan is a length of time that may or may not be connected to a particular instant. For example, two months is a timespan. lubridate has three timespan classes: Durations, Periods and Intervals.\nDurations Durations measure the exact amount of time that occurs between two instants.\nFunctions for working with durations include is.duration(), as.duration() and duration(). For specific lengths, dseconds(), dminutes(), dhours(), ddays(), dweeks() and dyears() convenient lengths.\nPeriods Periods measure the change in clock time that occurs between two instants.\nFunctions for working with periods include is.period(), as.period() and period(). seconds(), minutes(), hours(), days(), weeks(), months() and years() quickly create periods of convenient lengths.\nIntervals Intervals are timespans that begin at a specific instant and end at a specific instant. Intervals retain complete information about a timespan. They provide the only reliable way to convert between periods and durations.\nFunctions for working with intervals include is.interval(), as.interval(), interval(), int_shift(), int_flip(), int_aligns(), int_overlaps().\nLet us look at an example\n# John was born on 19841014. How old is John h_age \u0026lt;- today() - ymd(19841014) h_age #\u0026gt; Time difference of 13427 days # Time difference in years as.duration(h_age) #\u0026gt; [1] \"1160092800s (~36.76 years)\"    5. Plotting the bird data We will plot the bird data using ggplot2.\nFirst, we plot a bar graph of days of the week:\nbirds %\u0026gt;% mutate(Wday = wday(eventDate, label = TRUE)) %\u0026gt;% ggplot(aes(x = Wday)) + geom_bar()   Second, we\u0026rsquo;ll plot the relative abundance of different bird orders by day of the week:\nbirds %\u0026gt;% mutate(Wday = wday(eventDate, label = TRUE)) %\u0026gt;% ggplot(aes(x = Wday, fill = order)) + geom_bar()    6. Breakout rooms!  Exercise 1 Jane was born on January 31st, 1992. How old is Jane today?\n  Hints (click here)  \nUse the functions today(), mdy(), and as.duration().\n   Solution (click here)  Jane_age \u0026lt;- today() - mdy(\"January 31st, 1992\") as.duration(Jane_age) #\u0026gt; [1] \"929836800s (~29.46 years)\"       Exercise 2 Calculate the time differences between the last four time zones with the current time.\n  Hints (click here)    You can get the last four time zones using the tail() function in combination with the OlsonNames() functions.\n  Then, you can compare the current time (now()) with times in different time zones using the force_tz() function.\n     Solution (click here)  # Current time  C_time \u0026lt;- now() # Last four time zones tail(OlsonNames(), 4) #\u0026gt; [1] \"UTC\" \"W-SU\" \"WET\" \"Zulu\" # Calculate time for UTC time zone  UTC_time \u0026lt;- force_tz(C_time, tzone = \"UTC\") # Calculate time difference C_time - UTC_time #\u0026gt; Time difference of 4 hours # Calculate time for W-SU time zone  WSU_time \u0026lt;- force_tz(C_time, tzone = \"W-SU\") WSU_time #\u0026gt; [1] \"2021-07-19 20:54:29 MSK\" # Calculate time difference C_time - WSU_time #\u0026gt; Time difference of 7 hours C_time #\u0026gt; [1] \"2021-07-19 20:54:29 EDT\" # Calculate time for WET time zone  WET_time \u0026lt;- force_tz(C_time, tzone = \"WET\") # Calculate time difference C_time - WET_time #\u0026gt; Time difference of 5 hours # Calculate time for Zulu time zone  Zulu_time \u0026lt;- force_tz(C_time, tzone = \"Zulu\") # Calculate time difference C_time - Zulu_time #\u0026gt; Time difference of 4 hours       Bonus exercise Remove the order \u0026ldquo;Passeriformes\u0026rdquo; from the bird data, and plot relative abundance of order based on days of the week.\n  Hints (click here)  \nUse the functions filter() and mutate().\n   Solution (click here)  # Remove Passeriformes: birds_a \u0026lt;- filter(birds, order != \"Passeriformes\") # Create the plot: birds_a %\u0026gt;% mutate(Wday = wday(eventDate, label = TRUE)) %\u0026gt;% ggplot(aes(x = Wday, fill = order)) + geom_bar()      ","date":1617148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626742536,"objectID":"87c18c604b69c5ed531b30df969f498e","permalink":"https://biodash.github.io/codeclub/16_lubridate/","publishdate":"2021-03-31T00:00:00Z","relpermalink":"/codeclub/16_lubridate/","section":"codeclub","summary":"Today, we will learn how to work effectively with dates and times in R using the lubridate package.","tags":null,"title":"Session 16: lubridate","type":"codeclub"},{"authors":["Jessica Cooperstone"],"categories":null,"content":" Prep homework Basic computer setup   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n  New to ggplot? Check out the three Code Club pages for Session 4, Session 5 and Session 10 which are all about ggplot2.\nIf you\u0026rsquo;ve never used ggplot2 before (or even if you have), you may find this cheat sheet useful.\nGetting Started RMarkdown for today\u0026rsquo;s session # directory for Code Club Session 15: dir.create(\"S15\") # directory for our RMarkdown # (\"recursive\" to create two levels at once.) dir.create(\"S15/Rmd/\") # save the url location for today's script todays_Rmd \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/15_plotly/Plotly-withOUT-answers.Rmd' # indicate the name of the new Rmd Session15_Rmd \u0026lt;- \"S15/Rmd/Session15_plotly.Rmd\" # go get that file!  download.file(url = todays_Rmd, destfile = Session15_Rmd)    1 - What is plotly? Today we are going to talk about making interactive plots using Plotly. Plotly exists in a variety of programming languages, but today we will be just talking about using it in R. All of the plotly documentation can be found here.\nIf you have never used plotly before, install it with the code below.\ninstall.packages(\"plotly\")   Here are some useful links to find info about using ggplotly.\n Basic ggplot2 charts Plotly R library fundamentals Intro to ggplotly() Using layout() ggplotly() tooltips  Before we start, there are two basic ways to use plot in R using plotly:\n Using ggplotly() - this is what we will go over today because it has the same syntax as ggplot() which we have already learned Using plot_ly() - there is slightly more functionality in this function, but the syntax is all new, so I\u0026rsquo;d suggest if you can do what you want with ggplotly(), do that. The syntax is not particularly hard so don\u0026rsquo;t be scared to use it if interactive plots are something you\u0026rsquo;re very interested in.  When you are googling about using plotly, you will find a combination of ggplotly() and plot_ly() approaches, and some parts of the code are interchangable. The easiesy way to see which parts are, is to try.\nAlso note, Google gets a bit confused when googling \u0026ldquo;ggplotly\u0026rdquo; and often returns information about just ggplot, so read extra carefully when problem solving.\nThis is an example of work from my group where we have found plotly to be particularly useful.\n   (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./apples.json\", function(chart) { Plotly.plot('chart-478513296', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  Data from Bilbrey et al., bioRxiv 2021\n 2 - Load libraries, get data Lets load the libraries we are using for today.\nlibrary(tidyverse) library(plotly) # for making interactive plots library(htmlwidgets) # for saving html files library(palmerpenguins) # for our penguins data   Let\u0026rsquo;s look at penguins_raw this time, a df that has a bit more data than the penguins df.\nhead(penguins_raw) #\u0026gt; # A tibble: 6 x 17 #\u0026gt; studyName `Sample Number` Species Region Island Stage `Individual ID` #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 PAL0708 1 Adelie… Anvers Torge… Adul… N1A1  #\u0026gt; 2 PAL0708 2 Adelie… Anvers Torge… Adul… N1A2  #\u0026gt; 3 PAL0708 3 Adelie… Anvers Torge… Adul… N2A1  #\u0026gt; 4 PAL0708 4 Adelie… Anvers Torge… Adul… N2A2  #\u0026gt; 5 PAL0708 5 Adelie… Anvers Torge… Adul… N3A1  #\u0026gt; 6 PAL0708 6 Adelie… Anvers Torge… Adul… N3A2  #\u0026gt; # … with 10 more variables: `Clutch Completion` \u0026lt;chr\u0026gt;, `Date Egg` \u0026lt;date\u0026gt;, #\u0026gt; # `Culmen Length (mm)` \u0026lt;dbl\u0026gt;, `Culmen Depth (mm)` \u0026lt;dbl\u0026gt;, `Flipper Length #\u0026gt; # (mm)` \u0026lt;dbl\u0026gt;, `Body Mass (g)` \u0026lt;dbl\u0026gt;, Sex \u0026lt;chr\u0026gt;, `Delta 15 N (o/oo)` \u0026lt;dbl\u0026gt;, #\u0026gt; # `Delta 13 C (o/oo)` \u0026lt;dbl\u0026gt;, Comments \u0026lt;chr\u0026gt; head(penguins) #\u0026gt; # A tibble: 6 x 8 #\u0026gt; species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex  #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; #\u0026gt; 1 Adelie Torge… 39.1 18.7 181 3750 male  #\u0026gt; 2 Adelie Torge… 39.5 17.4 186 3800 fema… #\u0026gt; 3 Adelie Torge… 40.3 18 195 3250 fema… #\u0026gt; 4 Adelie Torge… NA NA NA NA NA  #\u0026gt; 5 Adelie Torge… 36.7 19.3 193 3450 fema… #\u0026gt; 6 Adelie Torge… 39.3 20.6 190 3650 male  #\u0026gt; # … with 1 more variable: year \u0026lt;int\u0026gt;    3 - Create base ggplot object Using the penguins_raw dataset and make a scatter plot with Culmen Length on the y, and Culmen Depth on the x.\nbill_depth_length \u0026lt;- penguins_raw %\u0026gt;% ggplot(aes(x = `Culmen Length (mm)`, y = `Culmen Depth (mm)`)) + geom_point() bill_depth_length #\u0026gt; Warning: Removed 2 rows containing missing values (geom_point).    4 - Make it interactive with ggplotly() You can learn more about the ggplotly() function, including its arguments here.\nggplotly(bill_depth_length)       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins1.json\", function(chart) { Plotly.plot('chart-641397852', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \nWow that was easy!\nLet\u0026rsquo;s add a title and change the theme to make our plot a little prettier before we progress.\nbill_depth_length \u0026lt;- penguins_raw %\u0026gt;% ggplot(aes(x = `Culmen Length (mm)`, y = `Culmen Depth (mm)`)) + geom_point() + theme_minimal() + labs(title = \"Understanding Penguin Bill Dimensions\") ggplotly(bill_depth_length)       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins2.json\", function(chart) { Plotly.plot('chart-812739456', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \n 5 - Using tooltip Using tooltip helps you to indicate what appears when you hover over different parts of your plot. You can learn more about controlling tooltip here.\nWhat if we want to hover over each point and be able to tell which Island the penguin was found on?\nTo do this, we indicate what we want to hover with using text = in our aesthetic mappings. Then, we indicate tooltip = \u0026quot;text\u0026quot; to tell ggplotly() what we want to hover.\nbill_depth_length \u0026lt;- penguins_raw %\u0026gt;% ggplot(aes(x = `Culmen Length (mm)`, y = `Culmen Depth (mm)`, text = Island)) + geom_point() + theme_minimal() + labs(title = \"Understanding Penguin Bill Dimensions\") ggplotly(bill_depth_length, tooltip = \"text\")       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins3.json\", function(chart) { Plotly.plot('chart-851936724', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \nYou can play around a lot with tooltip to get it to be exactly how you want, and you can include multiple things in your hover text.\nYou can also indicate to hover with data that is not inherently in your plot by mapping it to a group aesthetic.\nbill_depth_length \u0026lt;- penguins_raw %\u0026gt;% ggplot(aes(x = `Culmen Length (mm)`, y = `Culmen Depth (mm)`, text = Island, group = `Individual ID`)) + geom_point() + theme_minimal() + labs(title = \"Understanding Penguin Bill Dimensions\") ggplotly(bill_depth_length, tooltip = c(\"text\", \"Individual ID\")) # hover test will be in this order   #\u0026gt; Warning: `group_by_()` was deprecated in dplyr 0.7.0. #\u0026gt; Please use `group_by()` instead. #\u0026gt; See vignette('programming') for more help      (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins4.json\", function(chart) { Plotly.plot('chart-145267398', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \nYou may also want to paste in some text to your hover info to provide additional clarity on what you are showing.\nYou can use paste to add some information you\u0026rsquo;d like to see in each of the hover texts, here, we are indicating Island: Island. You can also add multiple variables within text, and it will populate in the hover text in the way you indicate. There is an example of how to do this in Bonus 1.\nbill_depth_length \u0026lt;- penguins_raw %\u0026gt;% ggplot(aes(x = `Culmen Length (mm)`, y = `Culmen Depth (mm)`, text = paste(\"Island:\", Island))) + geom_point() + theme_minimal() + labs(title = \"Understanding Penguin Bill Dimensions\") ggplotly(bill_depth_length, tooltip = \"text\")       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins5.json\", function(chart) { Plotly.plot('chart-729854361', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \n 6 - Hover label aesthetics You might not like the default hover text aesthetics, and can change them! You can do this using style and layout and adding these functions using the pipe %\u0026gt;%.\n# setting fonts for the plot font \u0026lt;- list( family = \"Roboto Condensed\", size = 15, color = \"white\") # setting hover label specs label \u0026lt;- list( bgcolor = \"#FF0000\", bordercolor = \"transparent\", font = font) # we can do this bc we already set font # plotting like normal bill_depth_length \u0026lt;- penguins_raw %\u0026gt;% ggplot(aes(x = `Culmen Length (mm)`, y = `Culmen Depth (mm)`, text = paste(\"Island:\", Island))) + geom_point() + theme_minimal() + labs(title = \"A Deep Dive (ha) Into \\nUnderstanding Penguin Bill Dimensions\") # use\\n to bring your text to another line # amending our ggplotly call to include new fonts and hover label specs ggplotly(bill_depth_length, tooltip = \"text\") %\u0026gt;% style(hoverlabel = label) %\u0026gt;% layout(font = font)       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins6.json\", function(chart) { Plotly.plot('chart-571684923', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \n 7 - Dynamic ticks Keep your axis labels so when you zoom, you can see where you are on your plot. Remember, you can zoom and pan around your plot!\nggplotly(bill_depth_length, tooltip = \"text\", dynamicTicks = TRUE)       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins7.json\", function(chart) { Plotly.plot('chart-142796835', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \n 8 - Animating Add frame in your aesthetics mapping to tell plotly what column to animate over. You can then play your animation, or toggle from one view to another.\n# add frame bill_depth_length \u0026lt;- penguins_raw %\u0026gt;% ggplot(aes(x = `Culmen Length (mm)`, y = `Culmen Depth (mm)`, frame = Island, text = `Individual ID`)) + geom_point() + theme_minimal() + labs(title = \"Understanding Penguin Bill Dimensions\") ggplotly(bill_depth_length, tooltip = \"text\")       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins8.json\", function(chart) { Plotly.plot('chart-672548391', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \nNote: I know this plot isn\u0026rsquo;t animating \u0026ndash; for an animated version, see this page. Also, if you do this in R yourself, you will find the code works.\n 9 - Everything you know about ggplot still applies! Don\u0026rsquo;t forget you can use things like faceting, that we have gone over previously in Session 10.\nbill_depth_length \u0026lt;- penguins %\u0026gt;% ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species, text = paste(\"Island:\", island))) + geom_point() + theme_minimal() + theme(legend.position = \"none\") + labs(title = \"Understanding Penguin Bill Dimensions\", x = \"Culmen Bill Length (mm)\", y = \"Culmen Bill Depth (mm)\") + facet_wrap(~species) ggplotly(bill_depth_length, tooltip = \"text\")       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./penguins9.json\", function(chart) { Plotly.plot('chart-674318952', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \n 10 - Saving your plots Now that you\u0026rsquo;ve made a beautiful interactive plot, you probably want to save it.\nAssign the plot you want to save to an object, and use the function saveWidget() to save it. You can find the documentation here.\n# assign ggplotly plot to an object ggplotly_to_save \u0026lt;- ggplotly(bill_depth_length, tooltip = \"text\") # save saveWidget(widget = ggplotly_to_save, file = \"ggplotlying.html\")    Breakout rooms We are going to use the birds dataset from previous weeks, and gapminder data for the bonus.\nLet\u0026rsquo;s grab the birds data.\n# create directory for data to go dir.create('data/birds/', recursive = TRUE) # preparing to download # denote bird file url birds_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv' # denote file name birds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' # get file download.file(url = birds_url, destfile = birds_file)   Read in data.\n# read in birds data birds \u0026lt;- read_tsv(file = 'data/birds/backyard-birds_Ohio.tsv') #\u0026gt;  #\u0026gt; ── Column specification ──────────────────────────────────────────────────────── #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; decimalLatitude = col_double(), #\u0026gt; decimalLongitude = col_double(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; range = col_character() #\u0026gt; )   Look at your new df.\nhead(birds) #\u0026gt; # A tibble: 6 x 12 #\u0026gt; class order family genus species locality stateProvince decimalLatitude #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Aves Pass… Corvi… Cyan… Cyanoc… 44805 A… Ohio 40.9 #\u0026gt; 2 Aves Pass… Corvi… Cyan… Cyanoc… 45244 C… Ohio 39.1 #\u0026gt; 3 Aves Pass… Corvi… Cyan… Cyanoc… 44132 E… Ohio 41.6 #\u0026gt; 4 Aves Pass… Corvi… Cyan… Cyanoc… 45242 C… Ohio 39.2 #\u0026gt; 5 Aves Pass… Corvi… Cyan… Cyanoc… 45246 C… Ohio 39.3 #\u0026gt; 6 Aves Pass… Corvi… Cyan… Cyanoc… 44484 W… Ohio 41.2 #\u0026gt; # … with 4 more variables: decimalLongitude \u0026lt;dbl\u0026gt;, eventDate \u0026lt;dttm\u0026gt;, #\u0026gt; # species_en \u0026lt;chr\u0026gt;, range \u0026lt;chr\u0026gt;   For a knitted HTML with answers, you can also see this page.\nExercise 1  Filter your new birds df to only include bald eagles. Check to see how many bald eagle sightings there were in Ohio.\n  Hints (click here)  Try using a [`filter()`](https://dplyr.tidyverse.org/reference/filter.html), and consider filtering based on `species_en`    Solutions (click here)  bald_eagle \u0026lt;- birds %\u0026gt;% filter(species_en == \"Bald Eagle\") # what do we have? head(bald_eagle) #\u0026gt; # A tibble: 6 x 12 #\u0026gt; class order family genus species locality stateProvince decimalLatitude #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Aves Acci… Accip… Hali… Haliae… Mentor Ohio 41.7 #\u0026gt; 2 Aves Acci… Accip… Hali… Haliae… 45742 L… Ohio 39.3 #\u0026gt; 3 Aves Acci… Accip… Hali… Haliae… Morelan… Ohio 41.4 #\u0026gt; 4 Aves Acci… Accip… Hali… Haliae… Eastlake Ohio 41.7 #\u0026gt; 5 Aves Acci… Accip… Hali… Haliae… 44060 M… Ohio 41.7 #\u0026gt; 6 Aves Acci… Accip… Hali… Haliae… 44839 H… Ohio 41.4 #\u0026gt; # … with 4 more variables: decimalLongitude \u0026lt;dbl\u0026gt;, eventDate \u0026lt;dttm\u0026gt;, #\u0026gt; # species_en \u0026lt;chr\u0026gt;, range \u0026lt;chr\u0026gt; # check our df dimensions dim(bald_eagle) #\u0026gt; [1] 381 12       Exercise 2  Create a map that plots all the bald eagles found around Ohio. Color the points blue. Make sure the aspect ratio of Ohio looks reasonable to you.\n  Hints (click here)  Go back to Sessions [11](https://biodash.github.io/codeclub/11_ggplot-maps/) and [12](https://biodash.github.io/codeclub/12_loops/) to re-remember how maps work. Don't forget to call [`library(maps)`](https://rdrr.io/r/base/library.html).    Solutions (click here)  library(maps) #\u0026gt;  #\u0026gt; Attaching package: 'maps' #\u0026gt; The following object is masked from 'package:purrr': #\u0026gt;  #\u0026gt; map # get map of the states states \u0026lt;- map_data(\"state\") # filter states to only include ohio ohio \u0026lt;- states %\u0026gt;% filter(region == \"ohio\") # plot ggplot(data = ohio, aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = bald_eagle, aes(x = decimalLongitude, y = decimalLatitude, group = NULL), color = \"blue\", alpha = 0.2) + coord_fixed(1.2) + labs(title = 'Bald Eagles Around Ohio')       Exercise 3  Make your plot interactive so you can hover and and see the locality of each bald eagle observation.\n  Hints (click here)  You may want to call `text` within `geom_point()`.    Solutions (click here)  bald_eagles_ohio \u0026lt;- ggplot(data = ohio, aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = bald_eagle, aes(x = decimalLongitude, y = decimalLatitude, group = NULL, text = locality), color = \"blue\", alpha = 0.2) + coord_fixed(1.2) + labs(title = 'Bald Eagles Around Ohio') ggplotly(bald_eagles_ohio, tooltip = \"text\")       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./ohio1.json\", function(chart) { Plotly.plot('chart-518967423', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \n    Exercise 4  Change the hover text so that the background color is red, clean up your axis labels, and make all the fonts for the plot Arial.\n  Hints (click here)  You can set fonts either within your `ggplot()` call, or setting `font` within [`layout()`](https://docs.ropensci.org/plotly/reference/layout.html). You can customize the hover label with [`style()`](https://docs.ropensci.org/plotly/reference/style.html).    Solutions (click here)  # setting fonts for the plot eagle_font \u0026lt;- list( family = \"Arial\", size = 15, color = \"white\") # setting hover label specs eagle_label \u0026lt;- list( bgcolor = \"red\", bordercolor = \"transparent\", font = eagle_font) # we can do this bc we already set font bald_eagles_ohio \u0026lt;- ggplot(data = ohio, aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = bald_eagle, aes(x = decimalLongitude, y = decimalLatitude, group = NULL, text = locality), color = \"blue\", alpha = 0.2) + coord_fixed(1.2) + labs(title = 'Bald Eagles Around Ohio', x = \"Latitude\", y = \"Longitude\") # amending our ggplotly call to include new fonts and hover label specs ggplotly(bald_eagles_ohio, tooltip = \"text\") %\u0026gt;% style(hoverlabel = eagle_label) %\u0026gt;% layout(font = eagle_font)       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./ohio2.json\", function(chart) { Plotly.plot('chart-615843729', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \n    Bonus Bonus 1  Let\u0026rsquo;s go back to the Gapminder data we looked at in the instructional part of Session 10 on faceting, animating, and multi-plotting.\nMake a bubble-style plot that shows the life expectancy vs. GDP per capita over 1952 to 2007 for all countries. Color by continent, and indicate population by size. Use your knowledge of making plots to alter it such that you think it is descriptive and aesthetic.\n  Hints (click here)  Set text to what you want to hover (try adding multiple variables in there!), play around with theme and scaling, change fonts and aesthetics until you are pleased. You can download the gapminder data like this:\n# install.packages(\"gapminder\") # if you weren't at Session 10 library(gapminder) head(gapminder) #\u0026gt; # A tibble: 6 x 6 #\u0026gt; country continent year lifeExp pop gdpPercap #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #\u0026gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #\u0026gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #\u0026gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #\u0026gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #\u0026gt; 6 Afghanistan Asia 1977 38.4 14880372 786.      Solutions (click here)  gapminder_font \u0026lt;- list( family = \"Roboto Condensed\") gapminder_bubble \u0026lt;- gapminder %\u0026gt;% ggplot(aes(x = gdpPercap, y = lifeExp, fill = continent, size = pop, text = paste( \"Country:\", country, \"\\nLife expectancy:\", round(lifeExp,1), \"\\nGDP per capita:\", round(gdpPercap,0)))) + geom_point(aes(frame = year), color = \"black\", shape = 21, stroke = 0.2) + scale_x_log10() + theme_minimal() + theme(plot.title = element_text(size = 18)) + labs(title = \"Changing Life Expectancy and GDP Per Capita Worldwide \\nFrom 1952 to 2007\", x = \"GDP per capita (in International Dollars)\", y = \"Life Expectancy (years)\", fill = \"\", size = \"\") ggplotly(gapminder_bubble, tooltip = c(\"text\")) %\u0026gt;% layout(font = gapminder_font)       (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./gapminder.json\", function(chart) { Plotly.plot('chart-649532718', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })(); \nNote: I know this plot isn\u0026rsquo;t animating \u0026ndash; for an animated version, see this page. Also, if you do this in R yourself, you will find the code works.\n    ","date":1616544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616780375,"objectID":"ce6d61c1afe64ebae9067e14090c8573","permalink":"https://biodash.github.io/codeclub/15_plotly/","publishdate":"2021-03-24T00:00:00Z","relpermalink":"/codeclub/15_plotly/","section":"codeclub","summary":"During this fifteenth session of Code Club, we will learn to make interactive plots using ggplotly.","tags":null,"title":"Session 15: Plotly","type":"codeclub"},{"authors":["Michael Broe"],"categories":null,"content":"\n New To Code Club?   First, check out the Code Club Computer Setup instructions, which also has some pointers that might be helpful if you\u0026rsquo;re new to R or RStudio.\n  Please open RStudio before Code Club to test things out \u0026ndash; if you run into issues, join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n   Session Goals  Learn another way to avoid repetition in your code by creating your own functions. Learn the basic template of a function in R. Learn to incorporate your own functions into for loops and functionals like lapply() and map(). Learn all the advantages of using functions instead of copied code blocks.   We\u0026rsquo;ll be using tibble() and map() from the tidyverse packages, so we need to load that first.\nlibrary(tidyverse) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.2 ✔ purrr  0.3.4 #\u0026gt; ✔ tibble  3.0.4 ✔ dplyr  0.8.5 #\u0026gt; ✔ tidyr  1.0.3 ✔ stringr 1.4.0 #\u0026gt; ✔ readr  1.3.1 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag()   Why write functions? Copying your code is not good The first motivation for writing a function is when you find yourself cut-and-pasting code blocks with slight alterations each time.\nSay we have the following toy tidyverse data frame, where each column is a vector of 10 random numbers from a normal distribution, with mean = 0 and sd = 1 (the defaults for rnorm):\ndf \u0026lt;- tibble( a = rnorm(10), b = rnorm(10), c = rnorm(10), d = rnorm(10) ) df #\u0026gt; # A tibble: 10 x 4 #\u0026gt; a b c d #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 0.388 0.736 2.26 -0.302  #\u0026gt; 2 1.19 -0.131 -2.17 -0.0537 #\u0026gt; 3 0.971 0.919 0.0329 -0.227  #\u0026gt; 4 -0.147 -1.43 1.15 -2.09  #\u0026gt; 5 1.87 0.566 -0.935 0.601  #\u0026gt; 6 -1.07 0.941 1.56 -0.413  #\u0026gt; 7 1.22 0.637 1.62 0.976  #\u0026gt; 8 -0.142 1.02 1.98 1.22  #\u0026gt; 9 -2.02 0.499 -1.93 -0.0917 #\u0026gt; 10 0.177 0.347 1.79 1.55   In previous Code Clubs we\u0026rsquo;ve seen how you can apply a built-in function like median to each column using a for loop or lapply. But say we wanted to do something a bit fancier that is not part of core R. For example, we can normalize the values in a column so they range from 0 to 1 using the following code block:\n(df$a - min(df$a)) / (max(df$a) - min(df$a)) #\u0026gt; [1] 0.6193844 0.8252053 0.7693140 0.4817556 1.0000000 0.2453463 0.8345409 #\u0026gt; [8] 0.4828838 0.0000000 0.5650749   This code is a literal translation of the mathematical formula for normalization:\n$$z_{i} = \\frac{x_{i} - min(x)}{max(x)-min(x)}$$ OK, so how can we do this for each column? Here is a first attempt:\ndf$a \u0026lt;- (df$a - min(df$a)) / (max(df$a) - min(df$a)) df$b \u0026lt;- (df$b - min(df$a)) / (max(df$b) - min(df$b)) df$c \u0026lt;- (df$c - min(df$c)) / (max(df$c) - min(df$c)) df$d \u0026lt;- (df$d - min(df$d)) / (max(df$d) - min(df$d)) df #\u0026gt; # A tibble: 10 x 4 #\u0026gt; a b c d #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 0.619 0.301 1 0.491 #\u0026gt; 2 0.825 -0.0535 0 0.559 #\u0026gt; 3 0.769 0.376 0.497 0.512 #\u0026gt; 4 0.482 -0.582 0.749 0  #\u0026gt; 5 1 0.231 0.278 0.739 #\u0026gt; 6 0.245 0.384 0.843 0.461 #\u0026gt; 7 0.835 0.260 0.855 0.842 #\u0026gt; 8 0.483 0.418 0.938 0.910 #\u0026gt; 9 0 0.204 0.0532 0.549 #\u0026gt; 10 0.565 0.142 0.895 1   This works, but it caused me mental anguish to type it out. Even with cut and paste! All those manual textual substitutions!! And manual data entry is prone to mistakes, especially repetitive tasks like this. And say you had 1,000 columns\u0026hellip;\nAnd it didn\u0026rsquo;t work!! Honestly, I swear that mistake was totally real: I didn\u0026rsquo;t notice it until I looked at the output. Can you spot the mistake?\nIt turns out R has a range function that returns the minimum and maximum of a vector, which somewhat simplifies the coding:\nrange(df$a)   The result is a vector something like c(-1.2129504, 2.1011248) (it varies run to run, since the columns values are random) which we can index, and so we only do the min/max computation once for each column, instead of three times, so we get the following block of code for each column:\nrng \u0026lt;- range(df$a) (df$a - rng[1]) / (rng[2] - rng[1])   Does this help?\nrng \u0026lt;- range(df$a) df$a \u0026lt;- (df$a - rng[1]) / (rng[2] - rng[1]) rng \u0026lt;- range(df$b) df$b \u0026lt;- (df$b - rng[1]) / (rng[2] - rng[1]) rng \u0026lt;- range(df$c) df$c \u0026lt;- (df$c - rng[1]) / (rng[2] - rng[1]) rng \u0026lt;- range(df$d) df$d \u0026lt;- (df$d - rng[1]) / (rng[2] - rng[1])   Still pretty horrible, and arguably worse since we add a line for each column.\nHow can we distill this into a function to avoid all that repetition?\nEncapsulation of code in a function The secret to function writing is abstracting the constant from the variable. (Using the range function does throw into sharper relief what is constant and what is varying at least.) The constant part is the body of the function: the template or boiler-plate you use over and over again. The variable parts are the arguments of the function. We also need to give the function a name, so we can call it and reuse it. The template for a function is then:\nname \u0026lt;- function(arg1, arg2...) { \u0026lt;body\u0026gt; # do something with arg1, arg2 } The arguments go inside (...). The body is the block of code you want to reuse, and it\u0026rsquo;s contained in curly brackets {...}.\nHere\u0026rsquo;s what it looks like in this case:\nnormalize \u0026lt;- function(x) \u0026#123; rng \u0026lt;- range(x) (x - rng[1]) / (rng[2] - rng[1]) \u0026#125;   Pretty cool, right? Here normalize is the descriptive name we give the function.\nWe assign the function to the name using \u0026lt;- just like any other value. This means that now normalize is a function object, just like you create vector objects, or list or data frame objects, when you assigned them to names. Notice too that in RStudio they appear in the Global Environment in a special section, and clicking on them shows the code. This means that if you have a large file of code with many functions defined, you don\u0026rsquo;t have to go back searching for the function definition in the code itself.\nx is the argument of the function. In the current case this is a data frame column vector, but we can potentially use this function on any vector, so let\u0026rsquo;s not be too specific. The more generally you can write your function, the more useful it will be.\ntest_vec \u0026lt;- c(3, 7, pi, 8.657, 80) normalize(test_vec) #\u0026gt; [1] 0.000000000 0.051948052 0.001838866 0.073467532 1.000000000   When we call the function, the value we use in the function call is assigned to x and is passed in to the body of the function. So if we call the function on the first column, it gets passed in to the body, and returns the result:\ndf \u0026lt;- tibble(a = rnorm(10)) normalize(df$a) #\u0026gt; [1] 0.8726863 1.0000000 0.8764474 0.5618469 0.6111361 0.4147958 0.2889830 #\u0026gt; [8] 0.2683500 0.7181709 0.0000000   A couple of things to note:\n  Including that extra line rng \u0026lt;- range(x) is no longer a problem, since we just type it once. If you are typing things out over and over you might prefer brevity. When you write a function, you should prefer clarity. It\u0026rsquo;s good practice to break the the function down into logical steps, and name them properly. It\u0026rsquo;s much easier for others to \u0026lsquo;read\u0026rsquo; your function, and much easier for you when you come back to it in a couple of years. This is the principle of making your code \u0026lsquo;self-annotated\u0026rsquo;.\n  Functions should be simple, clear, and do one thing well. You create programs by combining simple functions in a modular manner.\n  There\u0026rsquo;s something very important but rather subtle about this use of the argument. As noted in CodeClub 12, once a for loop completes, the variable you\u0026rsquo;re using keeps the value it had at the last iteration of the loop, which persists in the global environment. Below we\u0026rsquo;ll compare that behavior to what happens with the function\u0026rsquo;s x argument.\n  Our original horrible code can now be rewritten as:\ndf$a \u0026lt;- normalize(df$a) df$b \u0026lt;- normalize(df$b) df$c \u0026lt;- normalize(df$c) df$d \u0026lt;- normalize(df$d)   Which is an improvement, but the real power comes from the fact that we can use our new function in for loops and apply statements. Here is the data from the previous couple of Clubs:\ndists_Mar4 \u0026lt;- c(17, 93, 56, 19, 175, 40, 69, 267, 4, 91) dists_Mar5 \u0026lt;- c(87, 143, 103, 223, 106, 18, 87, 72, 59, 5) dist_df \u0026lt;- data.frame(dists_Mar4, dists_Mar5)   Let\u0026rsquo;s first sanity check that our new function behaves sensibly on these vectors:\nnormalize(dists_Mar4) #\u0026gt; [1] 0.04942966 0.33840304 0.19771863 0.05703422 0.65019011 0.13688213 #\u0026gt; [7] 0.24714829 1.00000000 0.00000000 0.33079848   normalize(dists_Mar5) #\u0026gt; [1] 0.37614679 0.63302752 0.44954128 1.00000000 0.46330275 0.05963303 #\u0026gt; [7] 0.37614679 0.30733945 0.24770642 0.00000000   And while we\u0026rsquo;re here, let\u0026rsquo;s circle back to the assignment of the x argument outside and inside the function. Below we first assign a value to x outside the function; pass in a value to x inside the function; then reevaluate x outside the function call, to see what happens:\nx = pi x #\u0026gt; [1] 3.141593 normalize(dists_Mar5) # inside the function, x \u0026lt;- dists_Mar5 #\u0026gt; [1] 0.37614679 0.63302752 0.44954128 1.00000000 0.46330275 0.05963303 #\u0026gt; [7] 0.37614679 0.30733945 0.24770642 0.00000000 x #\u0026gt; [1] 3.141593   Whatever value x has outside the function does not affect, and is not affected by, the value of x inside the function. In computer science terms we say the variable(s) used inside the function are local to the function. They are freshly minted inside it, and safely destroyed before you leave it. So there is no chance of weird or unexpected conflicts with whatever variable values are set outside. In contrast, the variable in the for loop is global. It \u0026lsquo;leaks out\u0026rsquo; from where you actually used it, with perhaps unforeseen consequences. This is extremely important when you start embedding your own functions in larger programs.\nDefault values for arguments In R, we can assign a default value for an argument using = assignment. This means the argument will be called automatically, but can be overridden if explicitly called. First we create a function in the usual way:\nvariable_power \u0026lt;- function(x, p)\u0026#123; x**p # raises x to the power p \u0026#125; variable_power(2, 3) #\u0026gt; [1] 8   And now we create a version with a default value for the power:\nvariable_power_2 \u0026lt;- function(x, p = 2)\u0026#123; x**p \u0026#125; variable_power_2(2) #\u0026gt; [1] 4 variable_power_2(2, 3) #\u0026gt; [1] 8   Functions in for loops Here is how we can use our new function in a for loop over a data frame. In our previous examples of for loops median was a summary statistic and we return a single value for each column, so we created an empty vector of the desired length to hold the values for each column. Here we want to modify the original data frame with the same dimensions and column names. The following code copies the original data frame (so we don\u0026rsquo;t destroy it) and then modifies the copy \u0026lsquo;in place\u0026rsquo;:\ndist_df_norm \u0026lt;- dist_df for (column_number in 1:ncol(dist_df))\u0026#123; dist_df_norm[[column_number]] \u0026lt;- normalize(dist_df[[column_number]]) \u0026#125; dist_df_norm #\u0026gt; dists_Mar4 dists_Mar5 #\u0026gt; 1 0.04942966 0.37614679 #\u0026gt; 2 0.33840304 0.63302752 #\u0026gt; 3 0.19771863 0.44954128 #\u0026gt; 4 0.05703422 1.00000000 #\u0026gt; 5 0.65019011 0.46330275 #\u0026gt; 6 0.13688213 0.05963303 #\u0026gt; 7 0.24714829 0.37614679 #\u0026gt; 8 1.00000000 0.30733945 #\u0026gt; 9 0.00000000 0.24770642 #\u0026gt; 10 0.33079848 0.00000000   Copying an entire data frame could take a lot of time. So we can also create an empty data frame (of the same dimensions) and populate it:\nempty_vec \u0026lt;- vector(length = nrow(dist_df)) dist_df_norm_2 \u0026lt;- tibble(norm_Mar4 = empty_vec, norm_Mar5 = empty_vec) for (column_number in 1:ncol(dist_df))\u0026#123; dist_df_norm_2[[column_number]] \u0026lt;- normalize(dist_df[[column_number]]) \u0026#125; dist_df_norm_2 #\u0026gt; # A tibble: 10 x 2 #\u0026gt; norm_Mar4 norm_Mar5 #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 0.0494 0.376  #\u0026gt; 2 0.338 0.633  #\u0026gt; 3 0.198 0.450  #\u0026gt; 4 0.0570 1  #\u0026gt; 5 0.650 0.463  #\u0026gt; 6 0.137 0.0596 #\u0026gt; 7 0.247 0.376  #\u0026gt; 8 1 0.307  #\u0026gt; 9 0 0.248  #\u0026gt; 10 0.331 0   By writing our own function, we\u0026rsquo;ve effectively extended what R can do. And this is all that packages are: libraries of new functions that extend the capabilities of base R. In fact, if there are functions you design for your particular subject area and find yourself using all the time, you can make your own package and load it, and all your favorite functions will be right there (but that\u0026rsquo;s for another day\u0026hellip;)\nFunctional programming with your own functions We saw above that you assign the function object to a name, just as you would a vector, list or data frame. In R, functions are \u0026lsquo;first class citizens\u0026rsquo;, which means you can pass them as arguments to another function. This is a very powerful idea, and part of the program of functional programming (we introduced this idea in Session 13):\n In functional programming, functions are treated as first-class citizens, meaning that they can be bound to names\u0026hellip;, passed as arguments, and returned from other functions, just as any other data type can.\n Functions that take other functions as arguments are sometimes referred to as functionals.\nIn the previous session we showed how to use built-in functions like median as arguments to functionals. The functions you write yourself can also be used in exactly the same way.\nlapply() We introduced this functional in Session 13: it always returns a list:\nlapply_norm \u0026lt;- lapply(dist_df, normalize) lapply_norm #\u0026gt; $dists_Mar4 #\u0026gt; [1] 0.04942966 0.33840304 0.19771863 0.05703422 0.65019011 0.13688213 #\u0026gt; [7] 0.24714829 1.00000000 0.00000000 0.33079848 #\u0026gt;  #\u0026gt; $dists_Mar5 #\u0026gt; [1] 0.37614679 0.63302752 0.44954128 1.00000000 0.46330275 0.05963303 #\u0026gt; [7] 0.37614679 0.30733945 0.24770642 0.00000000 typeof(lapply_norm) #\u0026gt; [1] \"list\" str(lapply_norm) #\u0026gt; List of 2 #\u0026gt; $ dists_Mar4: num [1:10] 0.0494 0.3384 0.1977 0.057 0.6502 ... #\u0026gt; $ dists_Mar5: num [1:10] 0.376 0.633 0.45 1 0.463 ...   sapply() attempts to simplify the outputs. Here both lists are of type num, and the same length, so in this case R simplifies to a matrix data structure with a single type:\nsapply_norm \u0026lt;- sapply(dist_df, normalize) sapply_norm #\u0026gt; dists_Mar4 dists_Mar5 #\u0026gt; [1,] 0.04942966 0.37614679 #\u0026gt; [2,] 0.33840304 0.63302752 #\u0026gt; [3,] 0.19771863 0.44954128 #\u0026gt; [4,] 0.05703422 1.00000000 #\u0026gt; [5,] 0.65019011 0.46330275 #\u0026gt; [6,] 0.13688213 0.05963303 #\u0026gt; [7,] 0.24714829 0.37614679 #\u0026gt; [8,] 1.00000000 0.30733945 #\u0026gt; [9,] 0.00000000 0.24770642 #\u0026gt; [10,] 0.33079848 0.00000000 typeof(sapply_norm) #\u0026gt; [1] \"double\" dim(sapply_norm) #\u0026gt; [1] 10 2 str(sapply_norm) #\u0026gt; num [1:10, 1:2] 0.0494 0.3384 0.1977 0.057 0.6502 ... #\u0026gt; - attr(*, \"dimnames\")=List of 2 #\u0026gt; ..$ : NULL #\u0026gt; ..$ : chr [1:2] \"dists_Mar4\" \"dists_Mar5\"   lapply() yields a named list, sapply() yields a named matrix.\npurrr::map() The functional map() from the purrr package behaves the same as lapply(), it always returns a list (purrr is automatically loaded as part of the tidyverse):\nmap_norm \u0026lt;- map(dist_df, normalize) map_norm #\u0026gt; $dists_Mar4 #\u0026gt; [1] 0.04942966 0.33840304 0.19771863 0.05703422 0.65019011 0.13688213 #\u0026gt; [7] 0.24714829 1.00000000 0.00000000 0.33079848 #\u0026gt;  #\u0026gt; $dists_Mar5 #\u0026gt; [1] 0.37614679 0.63302752 0.44954128 1.00000000 0.46330275 0.05963303 #\u0026gt; [7] 0.37614679 0.30733945 0.24770642 0.00000000 typeof(map_norm) #\u0026gt; [1] \"list\" str(map_norm) #\u0026gt; List of 2 #\u0026gt; $ dists_Mar4: num [1:10] 0.0494 0.3384 0.1977 0.057 0.6502 ... #\u0026gt; $ dists_Mar5: num [1:10] 0.376 0.633 0.45 1 0.463 ...   Notice another advantage of both lapply() and map(): we don\u0026rsquo;t need to explicitly preallocate any kind of data structure to collect the results. The allocation is done behind the scenes as part of the implementation of lapply() and map(), which makes sure they run efficiently. In fact, R implements these functionals as a for loop behind the scenes, and in map() that for loop is implemented in C, so it optimizes performance.\nIf we want the output to be a data frame to match the input, we can simply coerce it:\nmap_norm_df \u0026lt;- map(dist_df, normalize) %\u0026gt;% as_tibble str(map_norm_df) #\u0026gt; tibble [10 × 2] (S3: tbl_df/tbl/data.frame) #\u0026gt; $ dists_Mar4: num [1:10] 0.0494 0.3384 0.1977 0.057 0.6502 ... #\u0026gt; $ dists_Mar5: num [1:10] 0.376 0.633 0.45 1 0.463 ...   Advantages of using functions Functions:\n avoid duplication, save time avoid coding errors in repetitive code localize variables, avoiding unexpected assignment surprises let you modify code in a single place, not multiple places lets you reuse code, since a single function can often be used on multiple inputs (vectors, lists and data frames), and can be imported from a package, instead of copy and paste.  Breakout rooms Exercise 1 R does not have a built-in function for calculating the coefficient of variation, aka the RSD (relative standard deviation). This is defined as the ratio of the standard deviation to the mean.\nCreate a function that computes this, and test it on a couple of vectors.\n  Hints (click here)  The relevant R built-ins are sd() and mean(). The function should have one argument, which is assumed to be a vector.    Solution (click here)  cv \u0026lt;- function(v)\u0026#123; sd(v)/mean(v) \u0026#125; cv(1:200) #\u0026gt; [1] 0.5759123      Exercise 2 Write a function equalish() which compares two numbers a and b, and checks if they are \u0026lsquo;equal enough\u0026rsquo; according to some threshold epsilon. Set a default threshold of 0.000001. The function should return TRUE if the absolute value of the difference is inside this threshold.\nCheck that it works on a couple of test numbers.\nNow pass in a couple of test vectors. Is this new function vectorized?\nNow call the function explicitly with a different threshold.\n  Hints (click here)  You'll need to use the absolute value function abs(), and the logical comparison operator for \"less than\".    Solution (click here)  equalish \u0026lt;- function(a, b, epsilon = 0.000001)\u0026#123; abs(a - b) \u0026lt; epsilon \u0026#125;   equalish(4.0, 4.01) #\u0026gt; [1] FALSE equalish(4.0, 4.000000001) #\u0026gt; [1] TRUE   v1 \u0026lt;- c(4.000000001, 2) v2 \u0026lt;- c(4.0, 7) equalish(v1, v2) #\u0026gt; [1] TRUE FALSE   equalish(v1, v2, 0.000000000000001) #\u0026gt; [1] FALSE FALSE      Exercise 3 The fastq file format for DNA sequencing uses a letter/punctuation code for the quality of the base called at each position (the fourth line below) which is in one-to-one relationship to the bases in the second line:\n@SIM:1:FCX:1:15:6329:1045 1:N:0:2 TCGCACTCAACGCCCTGCATATGACAAGACAGAATC + \u0026lt;\u0026gt;;##=\u0026gt;\u0026lt;9=AAAAAAAAAA9#:\u0026lt;#\u0026lt;;\u0026lt;\u0026lt;\u0026lt;????#=  To translate a letter code into a numerical phred quality score we have to do two things: (i) translate the character to an integer using the ASCII code look up table (ii) subtract 33 from that value (!).\nFor the first step, R has a function that converts a character into an integer according to that table, for example:\nutf8ToInt(\"!\") #\u0026gt; [1] 33   Write a function phred_score() that computes the phred score for any character. Check that it returns 0 for \u0026ldquo;!\u0026rdquo;.\nApply your function to our example string\n\u0026lt;\u0026gt;;##=\u0026gt;\u0026lt;9=AAAAAAAAAA9#:\u0026lt;#\u0026lt;;\u0026lt;\u0026lt;\u0026lt;????#=\nto convert it to phred quality scores.\nMini Bonus: Why is \u0026ldquo;33\u0026rdquo; the magic number?\n  Hints (click here)  \nRemember when you pass the value to the function it has to be an R character string.\nMini Bonus: look at the position of \u0026ldquo;!\u0026rdquo; in the ASCII table linked above and its raw ASCII integer value.    Solution (click here)  phred_score \u0026lt;- function(character)\u0026#123; utf8ToInt(character) - 33 \u0026#125; phred_score(\"\u0026lt;\u0026gt;;##=\u0026gt;\u0026lt;9=AAAAAAAAAA9#:\u0026lt;#\u0026lt;;\u0026lt;\u0026lt;\u0026lt;????#=\") #\u0026gt; [1] 27 29 26 2 2 28 29 27 24 28 32 32 32 32 32 32 32 32 32 32 24 2 25 27 2 #\u0026gt; [26] 27 26 27 27 27 30 30 30 30 2 28   \u0026ldquo;!\u0026rdquo; is the first printing character in the ASCII table. The previous characters were used historically to control the behavior of teleprinters: \u0026ldquo;the original ASCII specification included 33 non-printing control codes which originated with Teletype machines; most of these are now obsolete\u0026rdquo;. If the ASCII table started with \u0026ldquo;!\u0026rdquo; we wouldn\u0026rsquo;t need the correction (!).    ","date":1615852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616095517,"objectID":"657b84b08bbd34eb732254eb7a147443","permalink":"https://biodash.github.io/codeclub/14_functions/","publishdate":"2021-03-16T00:00:00Z","relpermalink":"/codeclub/14_functions/","section":"codeclub","summary":"In this session of Code Club, we'll look at how to avoid repetition in another way by writing your own functions.","tags":null,"title":"Session 14: Writing your own Functions","type":"codeclub"},{"authors":["Mike Sovic"],"categories":null,"content":" Session Goals  List the functions in the apply() family of functions from base R. Describe how the apply() functions relate to loops in R. Identify the input and output formats associated with different apply() functions. Identify appropriate apply() functions for different scenarios. Use apply() functions to explore some US state temperature data.   Intro: The apply() Functions R is sometimes referred to as a functional programming language, and the apply() family of functions from base R is an example of this functional programming. Let\u0026rsquo;s first take a look at some available functions - they include\u0026hellip;\n apply() lapply() sapply() tapply() mapply()  Last week in session 12, Jelmer introduced for loops as one method for iterating over some set of things in R. Let\u0026rsquo;s briefly revisit one of his examples. First, we\u0026rsquo;ll recreate his distance dataset\u0026hellip;\n#distance data (km) for two dates dists_Mar4 \u0026lt;- c(17, 93, 56, 19, 175, 40, 69, 267, 4, 91) dists_Mar5 \u0026lt;- c(87, 143, 103, 223, 106, 18, 87, 72, 59, 5) dist_df \u0026lt;- data.frame(dists_Mar4, dists_Mar5) #view the data frame dist_df #\u0026gt; dists_Mar4 dists_Mar5 #\u0026gt; 1 17 87 #\u0026gt; 2 93 143 #\u0026gt; 3 56 103 #\u0026gt; 4 19 223 #\u0026gt; 5 175 106 #\u0026gt; 6 40 18 #\u0026gt; 7 69 87 #\u0026gt; 8 267 72 #\u0026gt; 9 4 59 #\u0026gt; 10 91 5   As he showed, one way to get the median distance traveled for each day (column) is to iterate over each column with a for loop, applying the median() function to each one\u0026hellip;\n#create object to store the loop output column_medians \u0026lt;- vector(length = ncol(dist_df)) #for loop to calculate median for each column for (column_number in 1:ncol(dist_df)) \u0026#123; ## We extract one column using \"dataframe_name[[column_number]]\": column_median \u0026lt;- median(dist_df[[column_number]]) ## We add the single-column median to its associated position ## in the vector: column_medians[column_number] \u0026lt;- column_median \u0026#125; #view the result column_medians #\u0026gt; [1] 62.5 87.0   Let\u0026rsquo;s think of this loop as the \u0026ldquo;programming\u0026rdquo; part of the functional programming I mentioned earlier - we\u0026rsquo;ve written, or programmed, some code the computer will execute for us - we\u0026rsquo;ll get to the \u0026ldquo;functional\u0026rdquo; part of functional programming shortly.\nUnless you\u0026rsquo;re brand new to R, you\u0026rsquo;ve probably realized by now that there are a few data structures you find yourself working with pretty frequently. These include data frames, matrices, and lists. Not only do these get used a lot, but there are also certain operations that get performed pretty frequently on each of those types of objects. For example, doing something like iterating over either the rows or columns of a data frame and applying some function to each, like we did with the median function in the data frame above, is pretty common. That means lots of people would end up independently writing for loops that would look a lot like the one in our example. This is where the \u0026ldquo;functional\u0026rdquo; part of \u0026ldquo;functional programming\u0026rdquo; starts to come in. Instead of everyone independently writing that same basic loop over and over, it can be written one time in a general form and packaged into a function that can be called instead. And this is what the apply() functions do. Then, going one step further, functional programming allows us to pass individual functions as arguments to other functions, as we\u0026rsquo;re going to see shortly. Let\u0026rsquo;s take a look at some examples.\n Examples apply() We\u0026rsquo;ll start with the apply() function, which we can use to iterativey apply some function to the margins (rows or columns) of an object that has \u0026ldquo;row by column\u0026rdquo;\u0026quot; structure. There are three arguments that have to be passed to apply() - the object containing the data, the margin the function will be applied to (rows are designated with \u0026lsquo;1\u0026rsquo;, columns with \u0026lsquo;2\u0026rsquo;), and the function of interest.\nIn the example above, we used a loop to apply the median() function to each column of the data frame. Here, we\u0026rsquo;ll do the same thing with apply(), by passing the median() function as an argument to apply()\u0026hellip;\napply_out \u0026lt;- apply(dist_df, 2, median) #view the result apply_out #\u0026gt; dists_Mar4 dists_Mar5  #\u0026gt; 62.5 87.0   Notice how much less code it required here to do the same thing we did with the for loop above!\nNotice too that the output here is a vector (specifically, a named numeric vector). The apply() function determined this was most appropriate in this case, since the output of each iteration consisted of a single value. Here\u0026rsquo;s another scenario\u0026hellip;\napply_out_quantiles \u0026lt;- apply(dist_df, 2, quantile, probs = c(0.25, 0.5, 0.75)) #view the result apply_out_quantiles #\u0026gt; dists_Mar4 dists_Mar5 #\u0026gt; 25% 24.25 62.25 #\u0026gt; 50% 62.50 87.00 #\u0026gt; 75% 92.50 105.25   This time, the function output consisted of 3 values for each iteration, or column of the data frame. In this case, the output from apply is a matrix.\nA quick additional note about how the function above is structured. In it, we applied the quantile() function to each column, passing the probs argument to it to define the specific quantiles we wanted it to return. If we were running quantile() by itself (not in the context of apply()), it might look like this\u0026hellip;\nquantile(dists_Mar4, probs = c(0.25, 0.50, 0.75)) #\u0026gt; 25% 50% 75%  #\u0026gt; 24.25 62.50 92.50   Notice the slight difference in how the probs argument is passed to the quantile() function here versus inside the apply() function above. Here, probs is inside a set of parentheses associated with the function. But inside the apply() function, any arguments associated with the function get passed as a separate argument (separated from the function by a comma). If you check out the apply() documentation, this is indicated with the \u0026ldquo;\u0026hellip;\u0026rdquo; argument, which is described as \u0026ldquo;optional arguments to FUN\u0026rdquo;. You\u0026rsquo;ll see this kind of thing show up in other functions too.\nSo, what about the other types of apply() functions? Well, the different types are designed for different types of input. For example\u0026hellip;\nlapply() Remember that apply() requires you to define whether you\u0026rsquo;ll apply the function in a row-wise or column-wise manner. But lists aren\u0026rsquo;t set up as rows and columns. So, if we want to iterate over the elements of a list, apply() won\u0026rsquo;t work. An alternative is lapply().\nIn the next example, we\u0026rsquo;ll add some new distance data in for two additional dates. The number of observations are different this time though, so the data can\u0026rsquo;t be combined in a data frame (you might remember that a data frame is a special kind of list where each of the list elements are the same length). Since we have different lengths here, we\u0026rsquo;ll store the data as a list\u0026hellip;\n#create a list that includes the new distance data dists_Mar11 \u0026lt;- c(45, 34, 100, 40, 29, 88, 84, 102) dists_Mar12 \u0026lt;- c(90, 50, 19, 123, 77, 13, 70) dist_ls \u0026lt;- list(dists_Mar4, dists_Mar5, dists_Mar11, dists_Mar12) #view the list dist_ls #\u0026gt; [[1]] #\u0026gt; [1] 17 93 56 19 175 40 69 267 4 91 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 87 143 103 223 106 18 87 72 59 5 #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 45 34 100 40 29 88 84 102 #\u0026gt;  #\u0026gt; [[4]] #\u0026gt; [1] 90 50 19 123 77 13 70   Now we\u0026rsquo;ll apply the median() function to each element of the list. Again, we could write a for loop to iterate over each list element, but lapply() will do the same thing with much less code to write\u0026hellip;\nlapply_out \u0026lt;- lapply(dist_ls, median) #view the output lapply_out #\u0026gt; [[1]] #\u0026gt; [1] 62.5 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 87 #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 64.5 #\u0026gt;  #\u0026gt; [[4]] #\u0026gt; [1] 70   This time, the output is a list - lapply() always gives output in list format. But in this specific case, the output could just as easily (and maybe more simply) be stored as a vector of four values - one for each list element. sapply() is an alternative to lapply() that, like lapply() still works on list input, but that attempts to simplify the output where possible\u0026hellip;\nsapply() sapply_out \u0026lt;- sapply(dist_ls, median) #view the output sapply_out #\u0026gt; [1] 62.5 87.0 64.5 70.0   Those three: apply(), lapply(), and sapply() are the apply functions you\u0026rsquo;ll likely encounter most frequently, but there are others that apply in more specific cases - we\u0026rsquo;ll take a look at at least one more later in the Bonus section.\nBreakout Rooms We\u0026rsquo;ll work with a new temperature dataset for the Breakout Room Exercises. I\u0026rsquo;ve filtered and cleaned these data from the original dataset that\u0026rsquo;s available from climate.gov They consist of maximum average temperature values for three states - Colorado, Ohio, and Virginia, with years in rows and months in columns. You can download the data with this code\u0026hellip;\nlibrary(tidyverse) temp_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/temperature/co_oh_va_max_temp.txt' temp_file \u0026lt;- 'state_max_temps.tsv' download.file(url = temp_url, destfile = temp_file)   Exercise 1  First let\u0026rsquo;s load the dataset and assign it to an object named \u0026lsquo;maxtemps\u0026rsquo;. Then preview the dataset and determine its dimensions (number of rows and columns). As the \u0026lsquo;.tsv\u0026rsquo; extension on the file suggests, this is a tab delimited file.\n  Hints (click here)  \nUse read_tsv() to load the dataset. The functions head() and glimpse() are a couple good options for previewing the data. If you don\u0026rsquo;t get the dimensions from the function you preview the data with, the dim() function will provide this info.    Solution (click here)  maxtemps \u0026lt;- read_tsv(\"state_max_temps.tsv\") #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; STATE = col_character(), #\u0026gt; YEAR = col_double(), #\u0026gt; JAN = col_double(), #\u0026gt; FEB = col_double(), #\u0026gt; MAR = col_double(), #\u0026gt; APR = col_double(), #\u0026gt; MAY = col_double(), #\u0026gt; JUN = col_double(), #\u0026gt; JUL = col_double(), #\u0026gt; AUG = col_double(), #\u0026gt; SEP = col_double(), #\u0026gt; OCT = col_double(), #\u0026gt; NOV = col_double(), #\u0026gt; DEC = col_double() #\u0026gt; ) glimpse(maxtemps) #\u0026gt; Rows: 378 #\u0026gt; Columns: 14 #\u0026gt; $ STATE \u0026lt;chr\u0026gt; \"CO\", \"CO\", \"CO\", \"CO\", \"CO\", \"CO\", \"CO\", \"CO\", \"CO\", \"CO\", \"CO… #\u0026gt; $ YEAR \u0026lt;dbl\u0026gt; 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 190… #\u0026gt; $ JAN \u0026lt;dbl\u0026gt; 33.6, 41.2, 34.2, 32.6, 34.0, 40.8, 39.4, 38.4, 37.5, 36.6, 33.… #\u0026gt; $ FEB \u0026lt;dbl\u0026gt; 33.3, 41.3, 36.8, 43.4, 29.4, 39.1, 37.9, 43.2, 28.3, 47.3, 33.… #\u0026gt; $ MAR \u0026lt;dbl\u0026gt; 46.1, 44.8, 42.8, 43.5, 43.7, 51.9, 46.0, 44.3, 44.1, 51.4, 48.… #\u0026gt; $ APR \u0026lt;dbl\u0026gt; 60.8, 58.3, 55.8, 59.0, 58.7, 52.4, 55.5, 59.0, 55.6, 58.3, 53.… #\u0026gt; $ MAY \u0026lt;dbl\u0026gt; 66.5, 68.0, 70.5, 61.8, 66.5, 68.1, 67.6, 68.7, 63.8, 65.5, 61.… #\u0026gt; $ JUN \u0026lt;dbl\u0026gt; 74.0, 80.2, 77.4, 76.6, 77.2, 80.1, 76.8, 78.8, 69.8, 71.7, 77.… #\u0026gt; $ JUL \u0026lt;dbl\u0026gt; 77.7, 80.9, 82.0, 81.9, 80.2, 82.9, 86.7, 80.3, 80.9, 79.0, 79.… #\u0026gt; $ AUG \u0026lt;dbl\u0026gt; 80.0, 81.2, 79.6, 82.0, 79.8, 81.9, 80.7, 80.8, 80.3, 77.8, 81.… #\u0026gt; $ SEP \u0026lt;dbl\u0026gt; 75.7, 70.1, 75.2, 72.2, 74.9, 70.2, 72.7, 72.3, 70.0, 72.2, 73.… #\u0026gt; $ OCT \u0026lt;dbl\u0026gt; 60.3, 59.2, 59.8, 57.7, 58.0, 62.9, 63.1, 61.8, 62.4, 60.2, 57.… #\u0026gt; $ NOV \u0026lt;dbl\u0026gt; 42.3, 42.8, 48.5, 43.0, 50.5, 49.3, 52.9, 46.7, 49.7, 53.0, 48.… #\u0026gt; $ DEC \u0026lt;dbl\u0026gt; 33.9, 43.1, 33.4, 30.9, 35.0, 41.5, 38.6, 36.4, 41.8, 39.8, 35.… dim(maxtemps) #\u0026gt; [1] 378 14       Exercise 2  The dataset is currently in tibble form. This is the default object type created by the read_tsv() command from readr (common in tidy workflows). The apply functions are not associated with the tidyverse, and it turns out they sometimes don\u0026rsquo;t work well with tibbles. So, before we go any further, let\u0026rsquo;s convert the tibble to a data frame.\n  Hints (click here)  Use the as.data.frame() function to convert the tibble to a data frame.\n   Solution (click here)  maxtemps \u0026lt;- as.data.frame(maxtemps) class(maxtemps) #\u0026gt; [1] \"data.frame\"       Exercise 3  Calculate the average temperature for each month across the whole dataset (using the data for all three states together).\n  Hints (click here)  \nChoose an appropriate function from the apply() family of functions and use the mean() function to calculate the mean value for each column of temperatures in the dataset (cols 3 through 14). Remember that when you\u0026rsquo;re designating the margin to apply the function to, \u0026lsquo;1\u0026rsquo; means rows and \u0026lsquo;2\u0026rsquo; means columns.    Solution (click here)  mean_monthly \u0026lt;- apply(maxtemps[,3:14], 2, mean) #OR mean_monthly \u0026lt;- sapply(maxtemps[,3:14], mean) #Remember that a data frame is just a special case of a list (one that's structured in rows and columns), so either `apply()` or `sapply()` will work here #view results mean_monthly #\u0026gt; JAN FEB MAR APR MAY JUN JUL AUG  #\u0026gt; 38.89206 41.93598 50.73148 61.35608 71.26111 79.95503 84.17460 82.23571  #\u0026gt; SEP OCT NOV DEC  #\u0026gt; 75.92857 64.56296 51.49921 41.11508       Exercise 4  Now let\u0026rsquo;s get the average annual (max) temperatures for Ohio for all the years available in the dataset (1895-2020) and view the temperatures for the first 5 years of the dataset (1895-1899). Since it\u0026rsquo;s not really obvious what each of these values correspond to, try converting this vector to a named vector with the years serving as the names.\n  Hints (click here)  \nUse the same apply() and mean() functions as above, but this time, filter the dataset for just the \u0026ldquo;OH\u0026rdquo; entries, and also apply the function by rows. Remember that a two-dimensional object like a data frame or matrix is indexed with the form [rows, columns]. Alternatively, you can use tidy notation (i.e. filter, select). Then index the resulting vector with the square bracket notation (Session 9) to get the first five items. The names() function will allow you to add names to the vector elements.\n   Solution (click here)  #base R indexing... mean_annual_oh \u0026lt;- apply(maxtemps[maxtemps$STATE == \"OH\", 3:14], 1, mean) #OR  #a more tidy approach (actually a hybrid approach here - the apply function is still base R)... mean_annual_oh \u0026lt;- maxtemps %\u0026gt;% filter(STATE == \"OH\") %\u0026gt;% select(JAN:DEC) %\u0026gt;% apply(1, mean) #view first 5 items mean_annual_oh[1:5] #\u0026gt; [1] 60.23333 60.74167 61.20833 61.42500 61.59167 #add names to the vector names(mean_annual_oh) \u0026lt;- 1895:2020 #view first 5 items mean_annual_oh[1:5] #\u0026gt; 1895 1896 1897 1898 1899  #\u0026gt; 60.23333 60.74167 61.20833 61.42500 61.59167       Bonus 1  What if we wanted to compare the mean max July temperatures for each of the three states? Use an appropriate apply() function to calculate the mean values for July separately for CO, OH, and VA.\n  Hints (click here)  \ntapply() allows you to apply a function to subsets of a vector that are defined by a set of grouping variables (factors). Check the help page for tapply() and use the \u0026ldquo;STATE\u0026rdquo; column as the grouping factor.    Solution (click here)  tapply(maxtemps[,\"JUL\"], maxtemps$STATE, mean) #\u0026gt; CO OH VA  #\u0026gt; 82.25238 84.53810 85.73333       Bonus 2  Now, instead of focusing on just July, let\u0026rsquo;s try to get the average max temperatures for each month for each of the three states separately.\n  Hint 1 (click here)  \nThe tapply() function we used in Exercise 4 only works when the input is a single vector. Look toward the end of the tapply() documentation for a suggested related function that might apply here.    Hint 2 (click here)  \nGive the aggregate() function a try. Notice that the grouping variable (the \u0026ldquo;by\u0026rdquo; argument in the function) has to be provided in the form of a list.    Solution (click here)  aggregate(maxtemps[,3:14], by = list(maxtemps$STATE), mean) #\u0026gt; Group.1 JAN FEB MAR APR MAY JUN JUL #\u0026gt; 1 CO 36.85238 40.45952 47.44444 56.49762 66.00952 76.75238 82.25238 #\u0026gt; 2 OH 35.15476 37.99444 48.45238 61.05714 72.28571 80.70000 84.53810 #\u0026gt; 3 VA 44.66905 47.35397 56.29762 66.51349 75.48810 82.41270 85.73333 #\u0026gt; AUG SEP OCT NOV DEC #\u0026gt; 1 79.99286 72.51508 60.87381 47.09365 37.73333 #\u0026gt; 2 82.60952 76.72619 64.47778 50.32698 38.54365 #\u0026gt; 3 84.10476 78.54444 68.33730 57.07698 47.06825       Purrr: An Alternative (Tidy) Approach To apply() Functions In the second exercise, we converted back from a tibble to a data frame, as the apply() functions we\u0026rsquo;ve worked with here are part of base R, and some aren\u0026rsquo;t compatible with tibbles. It\u0026rsquo;s worth mentioning that there are tidy alternatives to the apply functions - they\u0026rsquo;re part of the purrr package, which might be the topic of a future code club session. We decided to go with apply() in this session since there were a couple requests for it, and it still does get used enough that you\u0026rsquo;re likely to at least run across it, even if you don\u0026rsquo;t use it yourself. For now though, if you want more details on purrr you can find them here.\n ","date":1615248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615489080,"objectID":"98b7c3b4309c191255a49396f4ee17f4","permalink":"https://biodash.github.io/codeclub/13_apply/","publishdate":"2021-03-09T00:00:00Z","relpermalink":"/codeclub/13_apply/","section":"codeclub","summary":"In this session of Code Club, we'll consider the `apply()` family of functions, which can often be used as efficient alternatives to writing some of the loops we worked with in the previous session.","tags":null,"title":"Session 13: Applying The Apply Functions","type":"codeclub"},{"authors":["Jelmer Poelstra"],"categories":null,"content":"\n Setup New to Code Club?   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also have pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n  Session goals Today, you will learn:\n That you should avoid copying your code. What different strategies for iteration exist in R. What vectorization is and how to make use of it. How to write a for loop. Best practices when using for loops. When you should (not) use for loops. Bonus: if statements.   Introduction Don\u0026rsquo;t Repeat Yourself Sometimes, you have a block of code and you need to repeat the operations in that code almost exactly. For instance, you may want to rerun a statistical model with different parameter values, rerun an analysis for a different batch of samples, or extract the same information for many different genes.\nYour first instinct may be to copy-and-paste the block of code, and make the necessary slight adjustments in the pasted block. However, iterating and writing your own functions are strategies that are clearer, less error-prone, and more flexible (and these two can also be combined). When the number of repeats are high, iteration is needed. When the code that needs to be repeated is more than a line or two, writing your own functions becomes useful.\nIteration Loops are the most universal iteration tool and the one we will focus on today. However, R has \u0026ldquo;functional programming\u0026rdquo; iteration methods that are less verbose and that can also be quicker to execute. These are the apply family of functions, and a more recent tidyverse approach implemented in the purrr package: we will learn more about those in the two upcoming Code Club sessions.\nLoops are still a very good place to start using iteration because they make the iteration explicit and are therefore more intuitive than functional alternatives. In addition, they can easily accommodate longer blocks of code without the need to also write your own function.\nToday, we will talk about the most common type of loop: the for loops. (Other types of loops in R are while loops and repeat loops. Related to loops are if statements, see the bonus exercise for some basics.)\nBut first\u0026hellip; Before we tackle loops we should take a step back and explore vectorization a bit more, which was briefly introduced by Michael in Code Club session 9. Besides functional programming methods, vectorization is the other reason that loops are not as widely used in R as in other programming languages.\n I: Vectorization Let\u0026rsquo;s say we have a vector (i.e., a collection of values) that consists of distances in miles:\ndists_miles \u0026lt;- c(24, 81, 48, 29, 177, 175, 20, 11, 62, 156)  Of course, we can\u0026rsquo;t science with miles, so we\u0026rsquo;ll have to convert these distances to kilometers by multiplying each value in the vector by 1.61. You may or may not know that this can be done really easily in R:\ndists_km \u0026lt;- dists_miles * 1.61 dists_km #\u0026gt; [1] 38.64 130.41 77.28 46.69 284.97 281.75 32.20 17.71 99.82 251.16  What is happening here is called a vectorized operation: 1.61 is automatically recycled as many times as needed to be multiplied with each individual value in the dist_miles vector. This is a pretty unique and very useful feature of R!\nIn many other languages, we would need a loop or a similar construct to iterate over each value in the vector and multiply by 1.61. In fact, under the hood, R also uses a loop to do this! So does it even make a difference? Yes \u0026ndash; the advantages of using vectorization in R are:\n  You don\u0026rsquo;t have to write the loop, saving you a fair bit of typing and making the code clearer.\n  The under-the-hood-loop is being executed much faster than a loop that you would write. This is because it is written in C/C++ code which only has to be called once (instead of at least as many times as there are iterations in our loop).\n  Other vectorization patterns Above, we saw an example of multiplying a vector by a single number. We can also use vectorized operations when both objects contain multiple items. For instance, say we have a vector with corresponding values for two dates:\ndists_Mar4 \u0026lt;- c(17, 93, 56, 19, 175, 40, 69, 267, 4, 91) dists_Mar5 \u0026lt;- c(87, 143, 103, 223, 106, 18, 87, 72, 59, 5)  To get the sum of these values at each position (index) of the two vectors (17 + 87, 93 + 143, etc.), we can simply do the following:\ndists_Mar4 + dists_Mar5 #\u0026gt; [1] 104 236 159 242 281 58 156 339 63 96   The two vectors don\u0026rsquo;t need to be of equal length, either:\nin the example below, we negate every other value in a vector:\nc(17, 93, 56, 19, 175, 40, 69, 267, 4, 91) * c(1, -1) #\u0026gt; [1] 17 -93 56 -19 175 -40 69 -267 4 -91    This also works for columns of a data frame, which we can extract using the dataframe_name$column_name notation (see Code Club session 9\u0026rsquo;s section on data frames, and the Base R data frame indexing summary below). Let\u0026rsquo;s say we wanted the mean distance this time:\ndist_df \u0026lt;- data.frame(dists_Mar4, dists_Mar5) dist_df$dists_mean = (dist_df$dists_Mar4 + dist_df$dists_Mar5) / 2 head(dist_df) #\u0026gt; dists_Mar4 dists_Mar5 dists_mean #\u0026gt; 1 17 87 52.0 #\u0026gt; 2 93 143 118.0 #\u0026gt; 3 56 103 79.5 #\u0026gt; 4 19 223 121.0 #\u0026gt; 5 175 106 140.5 #\u0026gt; 6 40 18 29.0  Vectorization with matrices Furthermore, we can also perform vectorized operations on entire matrices. With the following matrix:\n## We use the \"sample\" function to get 25 random values between 1 and a 100, ## and put those in a 5*5 matrix: mat \u0026lt;- matrix(sample(1:100, 25), nrow = 5, ncol = 5) mat #\u0026gt; [,1] [,2] [,3] [,4] [,5] #\u0026gt; [1,] 2 55 8 28 24 #\u0026gt; [2,] 81 30 99 33 12 #\u0026gt; [3,] 22 67 41 54 6 #\u0026gt; [4,] 48 84 42 35 100 #\u0026gt; [5,] 57 47 93 10 31  \u0026hellip;we could multiple all values by 10 or get the square of each value simply as follows:\nmat_more \u0026lt;- mat * 10 mat_more #\u0026gt; [,1] [,2] [,3] [,4] [,5] #\u0026gt; [1,] 20 550 80 280 240 #\u0026gt; [2,] 810 300 990 330 120 #\u0026gt; [3,] 220 670 410 540 60 #\u0026gt; [4,] 480 840 420 350 1000 #\u0026gt; [5,] 570 470 930 100 310 mat_squared \u0026lt;- mat * mat mat_squared #\u0026gt; [,1] [,2] [,3] [,4] [,5] #\u0026gt; [1,] 4 3025 64 784 576 #\u0026gt; [2,] 6561 900 9801 1089 144 #\u0026gt; [3,] 484 4489 1681 2916 36 #\u0026gt; [4,] 2304 7056 1764 1225 10000 #\u0026gt; [5,] 3249 2209 8649 100 961  Vectorization with indices We can also use vectorized solutions when we want to operate only on elements that satisfy a certain condition.\nLet\u0026rsquo;s say we consider any distance in one of our vectors that is below 50 to be insufficient, and we want to turn those values into negatives (a little harsh maybe, but we go with it).\nTo do so, we make use of R\u0026rsquo;s ability to index a vector with a logical vector:\n## \"not_far_enough\" will be a vector of logicals: not_far_enough \u0026lt;- dists_Mar4 \u0026lt; 50 not_far_enough #\u0026gt; [1] TRUE FALSE FALSE TRUE FALSE TRUE FALSE FALSE TRUE FALSE ## When we index the original vector with a logical vector, ## we get only those values for which \"not_far_enough\" is TRUE: dists_Mar4[not_far_enough] #\u0026gt; [1] 17 19 40 4  With the following syntax, we can replace just those low distances in our original vector:\ndists_Mar4[not_far_enough] \u0026lt;- dists_Mar4[not_far_enough] * -1 dists_Mar4 #\u0026gt; [1] -17 93 56 -19 175 -40 69 267 -4 91   In a simple case like this, we could also use the vectorized ifelse() function:\nifelse(dists_Mar5 \u0026lt; 50, dists_Mar5 * -1, dists_Mar5) #\u0026gt; [1] 87 143 103 223 106 -18 87 72 59 -5     II: For loops While it is important to use vectorization whenever possible, it can only be applied to a specific set of problems. A more universal solution when you need to repeat operations is the for loop. for loops iterate over a collection of values, allowing you to perform one or more actions for each value in the collection.\nThe basic syntax is as follows:\nfor (variable_name in collection_name) { #...do things for each item (variable_name) in the collection, one at a time... } On the first line, you initialize the for loop, telling it to assign each item in the collection to a variable (here, variable_name) one at a time.\nThe variable name is arbitrary, and the collection is whatever you want to loop over. However, for, the parentheses (), in, and the curly braces {} are all fixed elements of for loops. A simple example will help to understand the synax:\n## A loop to print negated values: for (one_number in c(1, 2, 3, 4)) \u0026#123; # We iterate over 1, 2, 3, 4 print(one_number * -1) # Multiply each number by -1 \u0026#125; #\u0026gt; [1] -1 #\u0026gt; [1] -2 #\u0026gt; [1] -3 #\u0026gt; [1] -4  Note that we don\u0026rsquo;t have to use the variable that we are looping over: we could also use a for loop as a roundabout way to simply repeat something as many times as there are values in our collection:\nfor (dummy in c(1, 2, 3, 4)) \u0026#123; print(\"Yes!\") # Print \"Yes!\" in each of our four iterations  \u0026#125; #\u0026gt; [1] \"Yes!\" #\u0026gt; [1] \"Yes!\" #\u0026gt; [1] \"Yes!\" #\u0026gt; [1] \"Yes!\"  As mentioned, the variable name that we assign is arbitrary: we could use anything, as long as we reference it with the same name inside the loop:\n## Example 1 with a different variable name: \"positive_number\" for (positive_number in c(1, 2, 3, 4)) \u0026#123; print(positive_number * -1) \u0026#125; #\u0026gt; [1] -1 #\u0026gt; [1] -2 #\u0026gt; [1] -3 #\u0026gt; [1] -4 ## Example 2 with a different variable name: \"i\" for (i in c(1, 2, 3, 4)) \u0026#123; print(i * -1) \u0026#125; #\u0026gt; [1] -1 #\u0026gt; [1] -2 #\u0026gt; [1] -3 #\u0026gt; [1] -4  Note that the variable as it was last assigned in the loop does persist in your environment:\ni #\u0026gt; [1] 4  The curly braces are not strictly necessary for one-liners like this:\nfor (i in 1:4) print(i * -1) #\u0026gt; [1] -1 #\u0026gt; [1] -2 #\u0026gt; [1] -3 #\u0026gt; [1] -4  for loop output Note that we need the print() function to print anything to screen \u0026ndash; nothing will be printed if we omit this:\nfor (i in 1:4) \u0026#123; i * -1 \u0026#125;  Similarly, if we want the output to be saved in an object of some kind, we need to explicitly make an assignment in each iteration of the loop. This is where we need to start paying attention to the design of our loop. Unless computational speed is of no concern at all, you should avoid growing an object in each iteration of the loop.\nFor example, you might be inclined to do the following if you wanted to compute the median of each column in a data frame:\n## We initialize a vector in which we collect the column medians: column_medians \u0026lt;- vector() for (column_number in 1:ncol(dist_df)) \u0026#123; ## We extract one column using \"dataframe_name[[column_number]]\": column_median \u0026lt;- median(dist_df[[column_number]]) ## We add the single-column median to our vector of medians: column_medians \u0026lt;- c(column_medians, column_median) \u0026#125; column_medians #\u0026gt; [1] 62.50 87.00 78.75  Similarly, you may be tempted to add a column (with cbind()) or a row (with rbind()) to a data frame in each iteration of the loop. However, the problem with these approaches is that R has to create an entirely new object in each iteration of the loop, because the object\u0026rsquo;s memory requirements keep increasing.\nInstead, you\u0026rsquo;ll want to give the final vector (here, column_medians) the appropriate size before you start the loop:\ncolumn_medians \u0026lt;- vector(length = ncol(dist_df)) for (column_number in 1:ncol(dist_df)) \u0026#123; column_median \u0026lt;- median(dist_df[[column_number]]) column_medians[column_number] \u0026lt;- column_median \u0026#125;  Note that for very small problems, such as the example above, there will not be a noticeable difference in computation time between pre-assigning a properly sized object versus growing an object inside the loop. However, it is still good to get into the habit of pre-assigning an object of the right size.\nSummary guidelines (when speed is an issue)  Don\u0026rsquo;t use a loop when you can instead use vectorized operations. Don\u0026rsquo;t grow objects inside the loop. Instead, pre-assign an object large enough to contain all output of the loop and fill it in inside the loop. When you write a loop, avoid doing things inside the loop that don\u0026rsquo;t need to be repeated.  Learning about how to create your own functions and/or to use functional programming techniques like purrr and the apply family of functions (upcoming Code Club sessions!) will likely reduce your reliance on loops. For instance, as we\u0026rsquo;ll see next week, computing the median of each column in a data frame can be done much more succinctly with apply().\nEven for more experienced users, loops remain a more viable option when longer blocks of code need to be repeated: we will practice with that in the exercises.\n Breakout rooms! For the exercises, you can download an R Markdown file with some code to get set up (I recommend coding in that document to get a nice overview of the maps that you will make):\ndir.create('S12') todays_rmd \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/12_loops/exercises.Rmd' download.file(url = todays_rmd, destfile = 'S12/exercises.Rmd')  The following code is already in your R Markdown file, which will download and read the bird dataset and the necessary packages:\n## Download the file with bird data: birds_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_sample_error.tsv' birds_file \u0026lt;- 'backyard-birds_sample_error.tsv' download.file(url = birds_url, destfile = birds_file)   ## Load the tidyverse: library(tidyverse) ## Read the file with bird data: birds \u0026lt;- read_tsv(birds_file) ## Load the maps package and get the state map: # install.packages('maps') # first install if necessary library(maps) states \u0026lt;- map_data(\"state\")  Last week, we learned about making maps. If you attended one of the first few Code Club sessions, you\u0026rsquo;ll recall our Great Backyard Birdcount data set. Here, we\u0026rsquo;ll use a country-wide random subset of this data (the full file is over 4 GB) to see where Carolina Chickadees were seen:\n## With this line, we select only the rows where the column \"species_en\" ## (English species name) equals \"Carolina Chickadee\", ## i.e. we are getting just the records for the Carolina Chickadee: caro_chickadee \u0026lt;- birds[birds$species_en == 'Carolina Chickadee', ] ## Or in tidyverse-speak: # caro_chickadee \u0026lt;- birds %\u0026gt;% filter(species_en == 'Carolina Chickadee') # Next, we create a map much like we did last week: ggplot(data = states, # Use \"states\" for underlying map mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + # Black state outlines, white fill geom_point(data = caro_chickadee, # Plot points from bird data set aes(x = long, y = lat, group = NULL), color = \"green4\", alpha = 0.5) + # Green points, somewhat transparent coord_fixed(1.3) + # Fix projection labs(title = 'Carolina Chickadee')   Uh-oh! Something appears to have gone wrong. In the first exercise, you\u0026rsquo;ll use vectorization to fix the coordinates in the bird data set.\nIn the second exercise, you\u0026rsquo;ll use a loop to quickly produce similar plots for several other species.\n Exercise 1: Vectorization Try to fix the coordinates using vectorized operations, and recreate the map to see if it worked.\n Start with the latitude, which is wrong for all points.    Hints (click here)     You\u0026rsquo;ll need to modify the caro_chickadee data frame, while you can keep the plotting code exactly the same.\n  Simply prepending the latitude column with a minus sign (-) will negate the values.\n  Equivalent base R ways to refer to the column with latitudes are caro_chickadee$lat and caro_chickadee[['lat']].\n     Solution (click here)  First we fix the latitude, which was simply negated:\ncaro_chickadee$lat \u0026lt;- -caro_chickadee$lat ## Or equivalently: # caro_chickadee[['lat']] \u0026lt;- -caro_chickadee[['lat']] ## Or a tidyverse way of doing this: # caro_chickadee \u0026lt;- caro_chickadee %\u0026gt;% mutate(lat = -lat)  Create the first map with the same code as the example:\nggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = caro_chickadee, aes(x = long, y = lat, group = NULL), color = \"green4\", alpha = 0.5) + coord_fixed(1.3) + labs(title = 'Carolina Chickadee')     Once you have fixed the latitude, you should notice that for one state, there is a problem with the longitude (the offset is 10 decimal degrees).    Hints (click here)     The displaced state is North Carolina.\n  The state of each sighting is in the stateProvince column, and North Carolina\u0026rsquo;s name is simply \u0026ldquo;North Carolina\u0026rdquo; in that column.\n  It may help to first create a logical vector indicating whether for each row in the caro_chickadee data frame, stateProvincefor equals \u0026ldquo;North Carolina\u0026rdquo;.\n  Your final map will look nicer if you get rid of the plotting canvas by adding\n+ theme_void() to the code for the plot.\n     Solution (click here)  It turns out that North Carolina\u0026rsquo;s chickadees are above the Atlantic. Let\u0026rsquo;s perform a rescue operation by fixing the longitudes, which are offset by 10 degrees, just for North Carolina:\n## Get a vector of logicals, indicating which rows are from North Carolina: NC_rows \u0026lt;- caro_chickadee$stateProvince == \"North Carolina\" ## Only for North Carolina rows, change the longitude: caro_chickadee$long[NC_rows] \u0026lt;- caro_chickadee$long[NC_rows] - 10 ## Or with ifelse in one line: # caro_chickadee$long \u0026lt;- ifelse(caro_chickadee$stateProvince == \"North Carolina\", # caro_chickadee$long - 10, # caro_chickadee$long) ## Or with mutate and ifelse: # caro_chickadee %\u0026gt;% # mutate(long = ifelse(stateProvince == \"North Carolina\", long - 10, long))  And we create the final map:\nggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = caro_chickadee, aes(x = long, y = lat, group = NULL), color = \"green4\", alpha = 0.5) + coord_fixed(1.3) + labs(title = 'Carolina Chickadee') + theme_void()   Nice!\n    Exercise 2: for loops Find the 10 most commonly observed bird species in the data set, and save their English names (found in the species_en column) in a vector.\nFeel free to check out the solution if you\u0026rsquo;re not sure how, because the focus here is on the next step: trying to create a loop.\n  Solution (click here)   top10 \u0026lt;- birds %\u0026gt;% count(species_en, sort = TRUE) %\u0026gt;% # Produces a sorted count table for \"species_en\" pull(species_en) %\u0026gt;% # Extracts the \"species_en\" column head(n = 10) # Take the top 10   Next, loop over the top-10 species to produce a plot for each one of them.\nStart with the code for the Carolina Chickadee, including the subsetting operation, and modify that.\n  Hints (click here)     In the subsetting operation where you select data for the focal species, replace \u0026ldquo;Carolina Chickadee\u0026rdquo; with whatever you name the variable (indicating an individual species) that you loop over.\nBecause this is a variable name, and not a string like \u0026ldquo;Carolina Chickadee\u0026rdquo;, don\u0026rsquo;t forget to omit the quotes.\n  You\u0026rsquo;ll also need to change the title with the looping variable.\n     Solution (click here)  for (one_species in top10) \u0026#123; ## Select just the data for one species: one_bird_data \u0026lt;- birds[birds$species_en == one_species, ] ## Or in tidyverse-speak: # one_bird_data \u0026lt;- birds %\u0026gt;% filter(species_en == one_species) p \u0026lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = one_bird_data, aes(x = long, y = lat, group = NULL), color = \"green4\", alpha = 0.5) + coord_fixed(1.3) + labs(title = one_species) + # Make sure to change this to the looping variable theme_void() print(p) \u0026#125;      Bonus exercise: if statements if statements are similar in syntax to for loops, and are also considered a \u0026ldquo;control flow\u0026rdquo; structure. But their purpose is different from loops: instead of iterating, if statements do something once and they only do it when a condition is fulfilled.\nFor instance, we may want to check in a script whether a certain directory (folder) exists on our computer, and if it doesn\u0026rsquo;t, then we create the directory:\nif (dir.exists('path/to/my/dir')) \u0026#123; warning(\"Oh my, the output directory doesn't exist yet!\") dir.create('path/to/my/dir') \u0026#125;  Inside the parentheses () after if should be a statement that evaluates to either TRUE or FALSE (dir.exists() will be TRUE if the directory exists, and FALSE if it does not). If it is TRUE, whatever is inside the curly braces {} will be executed, and if it is FALSE, what is inside the curly braces will be ignored.\nif statements are commonly combined with for loops: we may want to only execute the functions in our loop for items in our collection that fulfill a certain condition:\nfor (one_number in 1:10) \u0026#123; if(one_number \u0026gt; 7) \u0026#123; print(one_number) \u0026#125; \u0026#125; #\u0026gt; [1] 8 #\u0026gt; [1] 9 #\u0026gt; [1] 10  In the example above, one number \u0026gt; 7 will only be TRUE for numbers larger than 7. This example is quite contrived, as it would have been easier (and faster!) to remove these items from the vector before the loop, but it hopefully gets the point across of how an if statement works.\n Many of the maps we produced in the previous exercise looked quite similar, with most species very widespread and a few restricted to the east of the US. Maybe if we select species that haven\u0026rsquo;t been seen in Ohio, we can find some other distributional patterns.\nFirst, select the the top 50 most observed bird species, just like you did in exercise 2.\nThen, use an if statement to create plots only for those top-50 birds that have not been seen in Ohio.\n  Solution (click here)   Select the top-50 birds:  all_species \u0026lt;- birds %\u0026gt;% count(species_en, sort = TRUE) %\u0026gt;% pull(species_en) %\u0026gt;% head(n = 50)   Loop over the species:  for (one_species in all_species) \u0026#123; ## Select the focal species: one_bird \u0026lt;- birds[birds$species_en == one_species, ] ## Create a data frame with only records from Ohio: one_bird_ohio \u0026lt;- one_bird[one_bird$stateProvince == 'Ohio', ] ## Test whether the data frame with only records from Ohio has any rows. ## If it does not, we create the map for the species in question:  if(nrow(one_bird_ohio) == 0) \u0026#123; p \u0026lt;- ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = one_bird, aes(x = long, y = lat, group = NULL), color = \"green4\", alpha = 0.5) + coord_fixed(1.3) + labs(title = one_species) + theme_void() print(p) \u0026#125; \u0026#125;       Going further  Base R data frame indexing Extract a column as a vector:\n## By name: birds$lat birds[['lat']] # Equivalent, $ notation is shorthand ## By index (column number): birds[[8]]  Extract one or more columns as a data frame using [row, column] notation,\nwith a leading comma ([, column]) meaning all rows:\n## By name: birds[, 'lat'] # dataframe['row_name', 'column_name'] birds[, c('lat', 'long')] ## By index (column numbers): birds[, 8] # dataframe[row_number, column_number] birds[, c(8, 9)]   Subset rows by a condition, with a trailing comma ([row, ]) meaning all columns:\nbirds[birds$lat \u0026gt; 25, ] birds[birds$species_en == 'Carolina Chickadee', ]     seq_along() To loop over column indices, we have used 1:ncol() above, and to loop over vector indices, you could similarly use 1:length().\nHowever, an alternative is seq_along(), which will create an index for you.\nbirds \u0026lt;- c('titmouse', 'chickadee', 'cardinal') seq_along(birds) #\u0026gt; [1] 1 2 3  The advantage of seq_along() is thtat it will behave better when your vector accidentally has length 0 (because 1:length() will have 1 and 0 when the length is 0, and you\u0026rsquo;ll get odd-seeming errors).\n  Further reading  Vectorization in R: Why? (Noam Ross, 2014) The Iteration chapter in Hadley Wickham\u0026rsquo;s R for Data Science (2017)  ","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629301677,"objectID":"0d1188d36cd786cdd66d047b20214d54","permalink":"https://biodash.github.io/codeclub/12_loops/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/codeclub/12_loops/","section":"codeclub","summary":"This will be the first of several sessions broadly about iterating in order to avoid copying-and-pasting of code, and today we will talk about vectorization and for loops.","tags":["codeclub","markdown","rmarkdown"],"title":"Session 12: Vectorization and loops in R","type":"codeclub"},{"authors":["Stephen Opiyo"],"categories":null,"content":"\n Prep and setup New to Code Club?   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n  New to ggplot2? Check out the two Code Club pages for Session 4 and Session 5.\nIf you\u0026rsquo;ve never used ggplot2 before (or even if you have), you may find this cheat sheet useful.\nDownload the CSV file on Ohio ohio_csv \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/11_ggplot-maps/Ohio.csv' download.file(url = ohio_csv, destfile = 'Ohio.csv')    Creating maps in R Today, we will cover the visualization of spatial data in R using the layered grammar of graphics implementation of ggplot2 in conjunction with the contextual information of static maps from world maps in the maps package.\nBefore we look at mapping using ggplot2, let us define some terms.\nAreal data  Areal data is data which corresponds to geographical extents with polygonal boundaries.\nThe layered grammar of graphics  By definition, the layered grammar demands that every plot consist of five components: \n  a default dataset with aesthetic mappings,\n  one or more layers, each with either a geometric object (\u0026ldquo;geom\u0026rdquo;), a statistical transformation (\u0026ldquo;stat\u0026rdquo;), etc.\n  a scale for each aesthetic mapping (which can be automatically generated),\n  a coordinate system, and \n  a facet specification. \n  Since ggplot2 is an implementation of the layered grammar of graphics, every plot made with ggplot2 has each of the above elements. Consequently, map plots also have these elements, but certain elements are ﬁxed to map components: the x aesthetic is ﬁxed to longitude, the y aesthetic is ﬁxed to latitude.\nDrawing a map  Drawing a map in R requires two things. First, we have to draw the map using data that directs R to draw the polygon shapes that constitute the map. Then we add information to our map to plot color and marks. It\u0026rsquo;s the same basic logic that we have used in ggplot figures. The key thing is to have datasets that link that geographic data with the information that we want to put on the plot.\nThe maps package in R  The \u0026ldquo;maps\u0026rdquo; package in R contains a set of maps of the United States and the world drawn using longitude and latitude data. With world map, the USA map with the individual states you can accomplish a lot of the mapping tasks using the maps package. The maps package contains a lot of outlines of continents, countries, states, and counties\nMaking dataframes from map outlines by ggplot2  Recall that ggplot2 operates on dataframes. Therefore, we need some way to translate the maps data into a data frame format the ggplot can use. The package ggplot2 provides the map_data() function. The function turns a series of points along an outline into a data frame of those points. The package ggplot2 uses the following syntax: map_data(\u0026quot;name\u0026quot;) where \u0026ldquo;name\u0026rdquo; is a quoted string of the name of a map in the maps package.\nOur first maps Let us start by drawing maps of the World, USA, states, Ohio, Ohio and Indiana, and part of Europe using the maps package.\nlibrary(tidyverse) library(maps) library(scales) library(stringr) # Let us get a world map using the \"map_data\" function  world \u0026lt;- map_data(\"world\") ## Let us get a US map: usa \u0026lt;- map_data(\"usa\") # Let us get the states: states \u0026lt;- map_data(\"state\") # Select Ohio using the filter function: ohio \u0026lt;- states %\u0026gt;% filter(region == \"ohio\")    Let us plot a world map:  ggplot(data = world, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(fill = \"white\", color = \"black\")    Let us plot a map of the US:  ggplot(data = usa, mapping = aes(x = long, y= lat, group = group)) + geom_polygon(fill = \"white\", color = \"black\")    Let us plot a map of the US with states:  ggplot(data = states, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(fill = \"blue\", color = \"black\")    Let us plot a map of Ohio:  ggplot(data = ohio, mapping=aes(x = long, y = lat, group = group)) + geom_polygon(fill = \"white\", color = \"green\")    We can also plot a map for an arbitrary selection of states:  # We can select data for two states, for example Ohio and Indiana: ohio_indiana \u0026lt;- states %\u0026gt;% filter(region == \"ohio\" | region == \"indiana\") # Plot the map of Ohio and Indiana: ggplot(data = ohio_indiana, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(fill = \"green\" , color = \"red\")    We can also plot only a specific region by filtering by latitude and longitude:  world \u0026lt;- map_data(\"world\") a_region \u0026lt;- filter(world, long \u0026gt;- 10 \u0026amp; long \u0026lt; 15.1 \u0026amp; lat \u0026gt; 32 \u0026amp; lat \u0026lt; 55) ggplot(data = a_region, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(fill = \"white\", color = \"black\") + coord_fixed(1.3)   The structure of the dataframe ohio. head(ohio) #\u0026gt; long lat group order region subregion #\u0026gt; 1 -80.51776 40.64563 42 10440 ohio \u0026lt;NA\u0026gt; #\u0026gt; 2 -80.55787 40.63990 42 10441 ohio \u0026lt;NA\u0026gt; #\u0026gt; 3 -80.62089 40.63417 42 10442 ohio \u0026lt;NA\u0026gt; #\u0026gt; 4 -80.66100 40.61698 42 10443 ohio \u0026lt;NA\u0026gt; #\u0026gt; 5 -80.66673 40.60552 42 10444 ohio \u0026lt;NA\u0026gt; #\u0026gt; 6 -80.67245 40.58833 42 10445 ohio \u0026lt;NA\u0026gt;   Look at the variables in ohio, note what they refer to: \n  long = longitude. Lines of longitude, or meridians, run between the North and South Poles and measure east-west positions. While prime meridian is assigned the value of 0 degrees, and runs through Greenwich (England), meridians to the west of the prime meridian are measured in degrees west (up to 180 degrees) and those to the east of the prime meridian are measured to in degrees east (up to 180 degrees).\n  lat = latitude. Lines of latitude measure north-south position between the poles with the equator defined as 0 degrees, the North Pole defined as 90 degrees north, and the South Pole defined as 90 degrees south. \n  group = an identifier that is unique for each subregion (here the counties). Group is very important! ggplot2\u0026rsquo;s functions can take a group argument which controls (amongst other things) whether adjacent points should be connected by lines. If they are in the same group, then they get connected, but if they are in different groups then they don\u0026rsquo;t. \n  order = an identifier that indicates the order in which the boundary lines should be drawn \n  region = string indicator for regions (here the states) \n  subregion = string indicator for sub-regions (here the county names) \n  Add information to the maps The second part of mapping in R, is to add information on the map created in the first part.  In drawing the map, the \u0026ldquo;maps\u0026rdquo; package creates the backbone for visualizations. Then we add additional information to show colors and shapes. \nWe will:  - fill a map by region,  - draw a Bubble map using city population,  - make a point for every city,  - vary size of point by city size and vary the color of the dots, and  - add external data to the map. \n Let us fill by region and make sure the the lines of state borders are white:  ggplot(data = states) + geom_polygon(aes(x = long, y = lat, fill = region, group = group), color = \"white\") + coord_fixed(1.3) + guides(fill = FALSE) # Do this to omit the legend    Let us draw a \u0026ldquo;Bubble map\u0026rdquo;:  # The maps package has city data head(maps::world.cities) #\u0026gt; name country.etc pop lat long capital #\u0026gt; 1 'Abasan al-Jadidah Palestine 5629 31.31 34.34 0 #\u0026gt; 2 'Abasan al-Kabirah Palestine 18999 31.32 34.35 0 #\u0026gt; 3 'Abdul Hakim Pakistan 47788 30.55 72.11 0 #\u0026gt; 4 'Abdullah-as-Salam Kuwait 21817 29.36 47.98 0 #\u0026gt; 5 'Abud Palestine 2456 32.03 35.07 0 #\u0026gt; 6 'Abwein Palestine 3434 32.03 35.20 0 my_cities \u0026lt;- maps::world.cities usa_cities \u0026lt;- filter(my_cities,country.etc == \"USA\") head(usa_cities) #\u0026gt; name country.etc pop lat long capital #\u0026gt; 1 Abilene USA 113888 32.45 -99.74 0 #\u0026gt; 2 Akron USA 206634 41.08 -81.52 0 #\u0026gt; 3 Alameda USA 70069 37.77 -122.26 0 #\u0026gt; 4 Albany USA 45535 44.62 -123.09 0 #\u0026gt; 5 Albany USA 75510 31.58 -84.18 0 #\u0026gt; 6 Albany USA 93576 42.67 -73.80 0    Make a point for every city:  ggplot(data = usa, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = usa_cities, color = \"red\", aes(x = long, y = lat, group = NULL))    Let\u0026rsquo;s pick just the big cities:  usa_big_cities \u0026lt;- filter(my_cities, country.etc == \"USA\" \u0026amp; pop \u0026gt; 500000) ggplot(data = usa, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = usa_big_cities, color = \"red\", aes(x = long, y = lat, group = NULL))    Vary size of point by city size:  ggplot(data = usa, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = usa_big_cities, color = \"red\", aes(x = long, y = lat, group = NULL, size = pop))    Now vary the color of the dots:  usa_big_cities$qual \u0026lt;- sample(LETTERS[1:5], nrow(usa_big_cities), replace = TRUE) ggplot(data = usa, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = usa_big_cities, aes(x = long, y = lat, group = NULL, color = qual, size = pop))    Tweak the map:  # No scientific notation in legend r ggplot: # scales package adds the \"scale_size_continuous\" function, and we can set label=comma library(scales) # Change the column name to make the legend nicer\" usa_big_cities$Population \u0026lt;- usa_big_cities$pop usa_big_cities$Qualitative \u0026lt;- usa_big_cities$qual # Do some additional refining: ggplot(data = usa, mapping = aes(x = long, y= lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = usa_big_cities, aes(x = long, y = lat, group = NULL, color = Qualitative, size = Population)) + scale_size_continuous(label = comma)    Work with Ohio counties with external data:  # Get basic map data for all USA counties: usa_counties = map_data(\"county\") # Subset to counties in Ohio: oh = subset(usa_counties, region == \"ohio\") head(oh) #\u0026gt; long lat group order region subregion #\u0026gt; 59960 -83.66902 39.02989 2012 59960 ohio adams #\u0026gt; 59961 -83.56590 39.02989 2012 59961 ohio adams #\u0026gt; 59962 -83.37109 39.06426 2012 59962 ohio adams #\u0026gt; 59963 -83.30806 39.06426 2012 59963 ohio adams #\u0026gt; 59964 -83.30233 39.05280 2012 59964 ohio adams #\u0026gt; 59965 -83.25649 39.01842 2012 59965 ohio adams   # Plot ohio counties ggplot() + geom_polygon(data = oh, aes(x = long, y = lat, group = group, fill = subregion), color = \"black\", alpha = 0.3) + coord_fixed(1.3) + guides(fill = FALSE) + ggtitle(\"Ohio counties\")    Read population data for Ohio counties:  # The data of the estimated population of each county in 2021 and percent change from 2010 Ohio \u0026lt;- read_csv(\"Ohio.csv\") head(Ohio) #\u0026gt; # A tibble: 6 x 6 #\u0026gt; county Pop Perc Town x_1 y_1 #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Adams 27706 -2.91 West Union -83.5 38.8 #\u0026gt; 2 Allen 101603 -4.47 Lima -84.1 40.7 #\u0026gt; 3 Ashland 53040 -0.53 Ashland -82.3 40.9 #\u0026gt; 4 Ashtabula 96549 -4.79 Jefferson -80.8 41.7 #\u0026gt; 5 Athens 64943 -0.35 Athens -82.1 39.3 #\u0026gt; 6 Auglaize 45496 -0.88 Wapakoneta -84.2 40.6    Prepare the data for plotting:  # Create a new column called \"county\" so that counties start with capital letters # using str_to_title function  oh$county \u0026lt;- str_to_title(oh$subregion) # Merge population data with counties data by county variable using inner_join # function, and named the new object \"ohio_pop\" ohio_pop \u0026lt;- inner_join(oh, Ohio, by = \"county\") # Select counties with population greater than 100000 ohio_big_pop \u0026lt;- filter(ohio_pop, Pop \u0026gt; 100000)    Create the plot where we vary point size by population size:  ### vary size of point by population size ggplot(data = ohio_pop, mapping = aes(x = long, y = lat, group = group))+ geom_polygon(color = \"black\", fill = \"white\")+ geom_point(data = ohio_big_pop, color = \"red\", aes(x = x_1, y = y_1, group = NULL, size = Pop)) + coord_fixed(1.3) + guides(size = FALSE) # Omit the legend    Improve the graph by creating groups of population using quantile.  ApplyQuintiles \u0026lt;- function(x) \u0026#123; cut(x, breaks = c(quantile(ohio_pop$Pop, probs = seq(0, 1, by = 0.2))), labels = c(\"0-20\", \"20-40\", \"40-60\", \"60-80\", \"80-100\"), include.lowest = TRUE) \u0026#125; ohio_pop$grouped_pop \u0026lt;- sapply(ohio_pop$Pop, ApplyQuintiles) head(ohio_pop) #\u0026gt; long lat group order region subregion county Pop Perc Town #\u0026gt; 1 -83.66902 39.02989 2012 59960 ohio adams Adams 27706 -2.91 West Union #\u0026gt; 2 -83.56590 39.02989 2012 59961 ohio adams Adams 27706 -2.91 West Union #\u0026gt; 3 -83.37109 39.06426 2012 59962 ohio adams Adams 27706 -2.91 West Union #\u0026gt; 4 -83.30806 39.06426 2012 59963 ohio adams Adams 27706 -2.91 West Union #\u0026gt; 5 -83.30233 39.05280 2012 59964 ohio adams Adams 27706 -2.91 West Union #\u0026gt; 6 -83.25649 39.01842 2012 59965 ohio adams Adams 27706 -2.91 West Union #\u0026gt; x_1 y_1 grouped_pop #\u0026gt; 1 -83.54616 38.79483 0-20 #\u0026gt; 2 -83.54616 38.79483 0-20 #\u0026gt; 3 -83.54616 38.79483 0-20 #\u0026gt; 4 -83.54616 38.79483 0-20 #\u0026gt; 5 -83.54616 38.79483 0-20 #\u0026gt; 6 -83.54616 38.79483 0-20    Plot the map:  ggplot() + geom_polygon(data = ohio_pop, aes(x = long, y = lat, group = group, fill = grouped_pop), color = \"black\") + coord_fixed(1.3) + scale_fill_brewer(palette = \"Reds\", direction = 1) + labs(fill = \"Population Quantiles\")   Breakout rooms Exercise 1 Use the dataset of 2021 Ohio county\u0026rsquo;s population to plot counties with % positive population growth.\n  Solution (click here)  # Get basic map data for all USA counties: usa_counties = map_data(\"county\") # Subset to counties in Ohio: oh = subset(usa_counties, region == \"ohio\") # Read population data: Ohio \u0026lt;- read_csv(\"Ohio.csv\") # Create a new column called \"county\" so that counties start with capital # letters using str_to_title function  oh$county = str_to_title(oh$subregion) # Merge counties with population: ohio_pop\u0026lt;-inner_join(oh, Ohio, by = \"county\") # Select counties with % positive population growth: ohio_pos_pop \u0026lt;- filter(ohio_pop, Perc \u0026gt; 0) ggplot(data = ohio_pop, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = ohio_pos_pop, color = \"red\", aes(x = x_1, y = y_1, group = NULL, size = Perc)) + coord_fixed(1.3) + guides(size = FALSE) # Omit the legend     Exercise 2 Use the same data to plot counties with % negative population growth with quantile of 0-20, 20-40, 40-60, 60-80, and 80-100.\n  Solution (click here)  ohio_neg_pop \u0026lt;- filter(ohio_pop, Perc\u0026lt;0) ggplot(data = ohio_pop, mapping = aes(x= long, y= lat, group = group))+ geom_polygon(color=\"black\",fill=\"white\")+ geom_point(data = ohio_neg_pop, color = \"red\", aes(x = x_1,y = y_1, group = NULL, size = Perc)) + coord_fixed(1.3) + guides(size = FALSE) # Omit the legend   ApplyQuintiles_n \u0026lt;- function(x) \u0026#123; cut(x, breaks = c(quantile(ohio_neg_pop$Perc, probs = seq(0, 1, by = 0.2))), labels = c(\"0-20\", \"20-40\", \"40-60\", \"60-80\", \"80-100\"), include.lowest = TRUE) \u0026#125; ohio_neg_pop$grouped_pop \u0026lt;- sapply(ohio_neg_pop$Perc, ApplyQuintiles_n) # Plot the map ggplot() + geom_polygon(data = ohio_neg_pop, aes(x = long, y = lat, group = group, fill = grouped_pop), color = \"black\") + coord_fixed(1.3) + scale_fill_brewer(palette = \"Set1\", direction = -1) + labs(fill = \"Negative population growth counties\")     Bonus exercise Plot the cities of France with population greater than 100,000. Vary size of point by city size, and vary the color of the dots.\n  Solution (click here)  world \u0026lt;- map_data(\"world\") france \u0026lt;- filter(world,region == \"France\") ggplot(data = france, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + labs(fill = \"France\")  # The \"maps\" package has city data head(maps::world.cities) #\u0026gt; name country.etc pop lat long capital #\u0026gt; 1 'Abasan al-Jadidah Palestine 5629 31.31 34.34 0 #\u0026gt; 2 'Abasan al-Kabirah Palestine 18999 31.32 34.35 0 #\u0026gt; 3 'Abdul Hakim Pakistan 47788 30.55 72.11 0 #\u0026gt; 4 'Abdullah-as-Salam Kuwait 21817 29.36 47.98 0 #\u0026gt; 5 'Abud Palestine 2456 32.03 35.07 0 #\u0026gt; 6 'Abwein Palestine 3434 32.03 35.20 0 my_cities \u0026lt;-maps::world.cities france_cities \u0026lt;- filter(my_cities, country.etc == \"France\") head(france_cities) #\u0026gt; name country.etc pop lat long capital #\u0026gt; 1 Abbeville France 26656 50.12 1.83 0 #\u0026gt; 2 Acheres France 23219 48.97 2.06 0 #\u0026gt; 3 Agde France 23477 43.33 3.46 0 #\u0026gt; 4 Agen France 34742 44.20 0.62 0 #\u0026gt; 5 Aire-sur-la-Lys France 10470 50.64 2.39 0 #\u0026gt; 6 Aix-en-Provence France 148622 43.53 5.44 0 # Make a point for every city: ggplot(data = france, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = france_cities, color = \"red\", aes(x = long, y = lat, group = NULL))   # Let's pick just the big cities: france_big_cities \u0026lt;- filter(my_cities,country.etc == \"France\" \u0026amp; pop \u0026gt; 100000) ggplot(data = france, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = france_big_cities, color = \"red\", aes(x = long, y = lat, group = NULL))   # vary size of point by city size ggplot(data = france, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = france_big_cities, color = \"red\", aes(x = long, y = lat, group = NULL, size = pop))   # Now vary the color of the dots france_big_cities$qual \u0026lt;- sample(LETTERS[1:5], nrow(france_big_cities), replace = TRUE) ggplot(data = france, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\",fill = \"white\") + geom_point(data = france_big_cities, aes(x = long, y = lat, group = NULL, color = qual, size = pop))   # Do some tweaking: # no scientific notation in legend r ggplot # scales package adds the \"scale_size_continuous\" function to our arsenal, and we can set label=comma library(scales) # Change the column name to make the legend nicer: france_big_cities$Population \u0026lt;- france_big_cities$pop france_big_cities$Qualitative \u0026lt;- france_big_cities$qual # Do some additional refining: ggplot(data = france, mapping = aes(x = long, y = lat, group = group)) + geom_polygon(color = \"black\", fill = \"white\") + geom_point(data = france_big_cities, aes(x = long, y = lat, group = NULL, color = Qualitative, size = Population)) + scale_size_continuous(label = comma)     ","date":1614124800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614293945,"objectID":"29ed38d8f1680daed1e667b71019651a","permalink":"https://biodash.github.io/codeclub/11_ggplot-maps/","publishdate":"2021-02-24T00:00:00Z","relpermalink":"/codeclub/11_ggplot-maps/","section":"codeclub","summary":"Today, we will be making cool maps in R!","tags":null,"title":"Session 11: Spatial data visualization with ggplot2","type":"codeclub"},{"authors":["Jessica Cooperstone"],"categories":null,"content":"\n Prep homework Basic computer setup   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll help you troubleshoot.\n  New to ggplot? Check out the two Code Club pages for Session 4 and Session 5.\nIf you\u0026rsquo;ve never used ggplot2 before (or even if you have), you may find this cheat sheet useful.\n Getting Started RMarkdown for today\u0026rsquo;s session # directory for Code Club Session 2: dir.create(\"S10\") # directory for our RMarkdown # (\"recursive\" to create two levels at once.) dir.create(\"S10/Rmd/\") # save the url location for today's script todays_R_script \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/10_faceting-animating/Session10_faceting_animating_multifigs.Rmd' # indicate the name of the new script file Session10_Rmd \u0026lt;- \"S10/Rmd/Session10_faceting_animating_multifigs.Rmd\" # go get that file!  download.file(url = todays_R_script, destfile = Session10_Rmd)   1 - How can I do more with my figures? Artwork by Allison Horst\nSometimes we have so much data that it is difficult to make sense of it if we look at it all at once. One way to get around this is to create facets in your data \u0026ndash; small subplots that help you to see different relationships among different variables in your dataset.\nToday we will be using ggplot2 to make a series of plots that help us better understand the underlying structure in our dataset.\n What will we go over today\nThese functions or packages will help you to get better visualize with your data.\n facet_wrap() and facet_grid()- makes small multiple plots based on some variable. set scales to indicate the linked or not-linked nature of your axes in a faceted plot gghighlight() - allows you to direct focus on a particular portion of your data. patchwork - to compose super easy multi-plot figures gganimate - to make your plots gif!  I will also go over a few tricks along the way.\n   2 - Accessing our data Let\u0026rsquo;s get set up and grab some data so that we can learn more about this world (and ggplot2)\n You can do this locally, or at OSC. You can find instructions if you are having trouble here.  First load your libraries. We are using a lot of new packages today.\nIf you\u0026rsquo;ve never downloaded these packages before, use the chunk below.\ninstall.packages(c(\"gghighlight\", \"gganimate\", \"magick\", \"patchwork\", \"ggrepel\", \"gapminder\"))  Once you have the packages above downloaded, load your libraries.\nlibrary(tidyverse) library(gghighlight) # for bringing attention to certain parts of your plot library(gganimate) # for animating library(magick) # for rendering gifs and saving them library(patchwork) # for making multi-panel plots library(ggrepel) # for getting labels to not be on top of your points # data for today library(gapminder)  Then let\u0026rsquo;s access the dataset gapminder, which is both the name of the package, and the name of the dataset. It contains a subset of data from Gapminder.org, an educational non-profit aimed to fight global misconceptions about statistics of our world.\nFrom Gapminder.org\nLet\u0026rsquo;s look at the data in gapminder.\n# look at the first 6 rows, all columns head(gapminder) #\u0026gt; # A tibble: 6 x 6 #\u0026gt; country continent year lifeExp pop gdpPercap #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #\u0026gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #\u0026gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #\u0026gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #\u0026gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #\u0026gt; 6 Afghanistan Asia 1977 38.4 14880372 786. # check the structure # this tell us what is contained within our df glimpse(gapminder) #\u0026gt; Rows: 1,704 #\u0026gt; Columns: 6 #\u0026gt; $ country \u0026lt;fct\u0026gt; Afghanistan, Afghanistan, Afghanistan, Afghanistan, Afghani… #\u0026gt; $ continent \u0026lt;fct\u0026gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia,… #\u0026gt; $ year \u0026lt;int\u0026gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997,… #\u0026gt; $ lifeExp \u0026lt;dbl\u0026gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.… #\u0026gt; $ pop \u0026lt;int\u0026gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 1… #\u0026gt; $ gdpPercap \u0026lt;dbl\u0026gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134,…  This dataset contains the following measurements about the life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007. It includes the following variables:\n country continent year lifeExp pop gdpPercap  Note, this data is already in tidy-style format meaning:\n Each variable must have its own column. Each observation must have its own row. Each value must have its own cell.  Learn more about tidy data here.\nTo make things a bit less complex, let\u0026rsquo;s look at data just from the Americas (i.e., North and South America). To do that, we can use filter() like we learned using dplyr back in Code Club Session 2\n# make a df with data only from the Americas gapminder_americas \u0026lt;- gapminder %\u0026gt;% filter(continent == \"Americas\") # what countries do we have? unique(gapminder_americas$country) #\u0026gt; [1] Argentina Bolivia Brazil  #\u0026gt; [4] Canada Chile Colombia  #\u0026gt; [7] Costa Rica Cuba Dominican Republic  #\u0026gt; [10] Ecuador El Salvador Guatemala  #\u0026gt; [13] Haiti Honduras Jamaica  #\u0026gt; [16] Mexico Nicaragua Panama  #\u0026gt; [19] Paraguay Peru Puerto Rico  #\u0026gt; [22] Trinidad and Tobago United States Uruguay  #\u0026gt; [25] Venezuela  #\u0026gt; 142 Levels: Afghanistan Albania Algeria Angola Argentina Australia ... Zimbabwe   3 - Life expectancy vs. time We will plot the relationship between lifeExp and year with the goal of understanding how life expectancy has changed in the second half of the 20th century. We will use geom_line() to make a line plot.\ngapminder_americas %\u0026gt;% ggplot(aes(x = year, y = lifeExp, group = country, color = country)) + geom_line()   This plot has so many countries, and we can only visually distinguish colors so well, that it makes this a bit of a mess. We can do better!\n 4 - Highlighting What if we want to highlight one country of interest, with the backdrop of all the data in the Americas? We can do this using gghighlight(), which will distinguish our country of interest, from the rest of the countries which will be indicated in gray.\nLet\u0026rsquo;s highlight the United States, and since we are at it, let\u0026rsquo;s also add x and y axis labels, a title, subtitle, and caption with labs().\ngapminder_americas %\u0026gt;% ggplot(aes(x = year, y = lifeExp, group = country, color = country)) + geom_line() + gghighlight(country == \"United States\") + labs(x = \"Year\", y = \"Life Expectancy (years)\", title = \"Life Expectancy in Countries in the Americas\", subtitle = \"From 1952 to 2007\", caption = \"Data from gapminder.org\") #\u0026gt; Warning: Tried to calculate with group_by(), but the calculation failed. #\u0026gt; Falling back to ungrouped filter operation... #\u0026gt; label_key: country    5 - Faceting What if we want to see all the data at once, but just be able to better attribute each line to the correct country? We can use the principle of small multiples, popularized by Edward Tufte, to make a series of charts all on the same scale to allow comparison between them easily.\nWe can facet using facet_wrap to create small plots for each country. If you want a certain number of rows or columns you can indicate them by including ncol and nrow in the facet_wrap() statement.\nI have also made the strip text, or the label on top of each of the facets bigger using theme.\ngapminder_americas %\u0026gt;% ggplot(aes(x = year, y = lifeExp, color = country)) + geom_line() + theme(strip.text.x = element_text(size = 14)) + facet_wrap(vars(country)) + # facet_wrap(~country) also works labs(x = \"Year\", y = \"Life Expectancy (years)\", title = \"Life Expectancy in Countries in the Americas\", subtitle = \"From 1952 to 2007\", caption = \"Data from gapminder.org\")   Now our legend is not necessary, so let\u0026rsquo;s remove it. Let\u0026rsquo;s also remove the gray background since its not really doing much for us. We will also change to theme_minimal() to get rid of the grey background which I don\u0026rsquo;t think we need.\ngapminder_americas %\u0026gt;% ggplot(aes(x = year, y = lifeExp)) + geom_line(aes(color = country)) + theme_minimal() + theme(legend.position = \"none\", strip.text.x = element_text(size = 14)) + facet_wrap(~country) + labs(x = \"Year\", y = \"Life Expectancy (years)\", title = \"Life Expectancy in Countries in the Americas\", subtitle = \"From 1952 to 2007\", caption = \"Data from gapminder.org\")   Wow better! But now its a bit hard to contextualize the line for each country to the whole dataset. We can fix this too.\n 6 - Highlighting plus faceting Let\u0026rsquo;s bring the rest of data back in, and highlight in each facet the country of interest. We can do this by just adding gghighlight() to our ggplot call.\nNote: if you want to assign something in R to an object, and then view it, you can put the whole thing in parentheses, without having to call that object back at the end.\n(americas_lifeexp \u0026lt;- gapminder_americas %\u0026gt;% ggplot(aes(x = year, y = lifeExp)) + geom_line(aes(color = country)) + gghighlight() + theme_minimal() + theme(legend.position = \"none\", strip.text.x = element_text(size = 14)) + facet_wrap(~country) + labs(x = \"Year\", y = \"Life Expectancy (years)\", title = \"Life Expectancy in Countries in the Americas\", subtitle = \"From 1952 to 2007\", caption = \"Data from gapminder.org\")) #\u0026gt; label_key: country #\u0026gt; Too many data series, skip labeling   Wow, we now have so much more information about our data!\n 7 - Adjusting scales while faceting The default in faceting is that the x and y-axes for each plot are all the same. This aids in the interpretation of each small plot in relation to the others, but sometimes you may want freedom to adjust your axes.\nFor example, if we wanted to plot population over time, if we used the same scale, it would be really hard to see trends within a country.\n(americas_pop \u0026lt;- gapminder_americas %\u0026gt;% ggplot(aes(x = year, y = pop)) + geom_line(aes(color = country)) + theme_minimal() + theme(legend.position = \"none\", strip.text.x = element_text(size = 14)) + facet_wrap(~country) + labs(x = \"Year\", y = \"Population\", title = \"Population in Countries in the Americas\", subtitle = \"From 1952 to 2007\", caption = \"Data from gapminder.org\"))   Let\u0026rsquo;s change the scales so that the y-axis is \u0026ldquo;free\u0026rdquo; - i.e., each plot will have an independent y-axis. Note, when you do this, you aren\u0026rsquo;t really using the principle of small multiples anymore, since the data isn\u0026rsquo;t all on comparable scales.\ngapminder_americas %\u0026gt;% ggplot(aes(x = year, y = pop)) + geom_line(aes(color = country)) + theme_minimal() + theme(legend.position = \"none\", strip.text.x = element_text(size = 14)) + facet_wrap(~country, scales = \"free_y\") + labs(x = \"Year\", y = \"Population\", title = \"Population of Countries in the Americas\", subtitle = \"From 1952 to 2007\", caption = \"Data from gapminder.org\")   The default for scales is \u0026quot;fixed\u0026quot;, but you can also set to be \u0026quot;free_x\u0026quot;, \u0026quot;free_y\u0026quot;, or \u0026quot;free\u0026quot;, which means both x and y are free.\n 8 - Multi-panel plots What if I take plots I\u0026rsquo;ve already made and assemble them together? You can do that simply with the package patchwork().\nArtwork by Allison Horst\nYou can use the syntax:\n plot1 + plot2 to get two plots next to each other plot1 / plot2 to get two plots stacked vertically plot1 | (plot2 + plot3) to get plot1 in the first row, and plots 2 and 3 in a second row  You can use plot_annotation() to indicate your plots with letters or numbers.\nI am going to make some quick plots so we can see how it works. Let\u0026rsquo;s look at some plots of the United States.\n# make df with just United States data gapminder_usa \u0026lt;- gapminder %\u0026gt;% filter(country == \"United States\") # make some plots (usa_lifeexp \u0026lt;- gapminder_usa %\u0026gt;% ggplot(aes(x = year, y = lifeExp)) + geom_point())   (usa_gdppercap \u0026lt;- gapminder_usa %\u0026gt;% ggplot(aes(x = year, y = gdpPercap)) + geom_line())   (usa_pop \u0026lt;- gapminder_usa %\u0026gt;% ggplot(aes(x = year, y = pop)) + geom_col())   Let\u0026rsquo;s make multi-panel plots. If you need to wrap around a line, make sure you don\u0026rsquo;t start your line with the +, it won\u0026rsquo;t work (this is true for all ggplot2 syntax).\n(usa_lifeexp + usa_gdppercap) / usa_pop + plot_annotation(title = \"Some plots about the United States\", tag_levels = \"A\")   You can see how this would be really useful for publications!\n 9 - Animating Artwork by Allison Horst\nSince we have time-scale data here, we could also build an animation that would help us look at our data. What if we wanted to look at how life expectancy (lifeExp) and population (pop) change over time? We could animate over the variable year, and do this by using the function animate(), and set transition_states() to the variable we are giffing over.\nNote, I have included closest_state in the subtitle so the viewer can see what is the year at any stage of the animation.\nTo be able to tell which dot belongs to which country, I added a geom_text_repel() statement, which labels each point but is smart enough to not let the labels overlap.\nI have also set pop to be on a log10 scale.\nIf you want to increase the resolution of your gif, and set the code chunk to cache = TRUE if the chunk runs slowly, so that it doesn\u0026rsquo;t re-run when knitting if nothing has been edited, you can do this in the curly brackets at the top of your chunk, like this:\n{r, cache = TRUE, dpi = 600}\n# install.packages(\"transformr\")  # if you are having problems with gganimate you may need to install transformr (p \u0026lt;- ggplot(gapminder_americas, aes(x = lifeExp, y = pop, fill = country, label = country)) + geom_point(shape = 21, color = \"black\") + geom_text_repel() + scale_y_log10() + theme_classic() + theme(legend.position = 'none') + labs(title = \"Population and Life Expectancy in the Americas\", subtitle = 'Year: \u0026#123;closest_state\u0026#125;', x = \"Life Expectancy\", y = \"Log10 Population\") + transition_states(year))  There are many different ways to transition your data in gganimate - and you can learn more about them here.\nSaving my gif\nNow I want to save my gif. We can do that simply with the function anim_save() which works a lot like ggsave().\n# set parameters for your animation animate(p, duration = 10, fps = 10, width = 700, height = 700, renderer = magick_renderer()) # save it anim_save(filename = \"gapminder_gif.gif\", animation = last_animation(), path = \"/Users/jessicacooperstoneimac\")   10 - Breakout rooms Loading data and get set up Load the palmerpenguins dataset, look at its structure, and view the beginning of the df.\nlibrary(palmerpenguins) str(penguins) #\u0026gt; tibble [344 × 8] (S3: tbl_df/tbl/data.frame) #\u0026gt; $ species : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ... #\u0026gt; $ island : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ... #\u0026gt; $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... #\u0026gt; $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... #\u0026gt; $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... #\u0026gt; $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... #\u0026gt; $ sex : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ... #\u0026gt; $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... head(penguins) #\u0026gt; # A tibble: 6 x 8 #\u0026gt; species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex  #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; #\u0026gt; 1 Adelie Torge… 39.1 18.7 181 3750 male  #\u0026gt; 2 Adelie Torge… 39.5 17.4 186 3800 fema… #\u0026gt; 3 Adelie Torge… 40.3 18 195 3250 fema… #\u0026gt; 4 Adelie Torge… NA NA NA NA NA  #\u0026gt; 5 Adelie Torge… 36.7 19.3 193 3450 fema… #\u0026gt; 6 Adelie Torge… 39.3 20.6 190 3650 male  #\u0026gt; # … with 1 more variable: year \u0026lt;int\u0026gt;   Main exercises Exercise 1  Like we did in Code Club 7, convert the two columns about penguin bill dimensions bill_length_mm and bill_depth_mm to two columns called bill_dimension and value. Drop your NAs also. Save this as a new df called penguins_long.\n  Hints (click here)  Use a combination of drop_na() and pivot_longer(), and it\u0026rsquo;s helpful if you also set names_prefix in your pivot_longer() statement but not totally necessary.    Solutions (click here)  penguins_long \u0026lt;- penguins %\u0026gt;% drop_na() %\u0026gt;% pivot_longer(cols = bill_length_mm:bill_depth_mm, names_to = \"bill_dimension\", values_to = \"value_mm\", names_prefix = \"bill_\") head(penguins_long) #\u0026gt; # A tibble: 6 x 8 #\u0026gt; species island flipper_length_… body_mass_g sex year bill_dimension #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Adelie Torge… 181 3750 male 2007 length_mm  #\u0026gt; 2 Adelie Torge… 181 3750 male 2007 depth_mm  #\u0026gt; 3 Adelie Torge… 186 3800 fema… 2007 length_mm  #\u0026gt; 4 Adelie Torge… 186 3800 fema… 2007 depth_mm  #\u0026gt; 5 Adelie Torge… 195 3250 fema… 2007 length_mm  #\u0026gt; 6 Adelie Torge… 195 3250 fema… 2007 depth_mm  #\u0026gt; # … with 1 more variable: value_mm \u0026lt;dbl\u0026gt;      Exercise 2  Plot body mass (body_mass_g) as related to bill length and depth.\n  Hints (click here)  Faceting will be useful here.    Solutions (click here)  penguins_long %\u0026gt;% ggplot(aes(x = body_mass_g, y = value_mm)) + geom_point() + facet_wrap(vars(bill_dimension))       Exercise 3  Take your plot from Exercise 2 and make it prettier. You can do things like change your axis labels, add title, change themes as you see fit. Color your points by sex.\n  Hints (click here)  Pick a theme you like. theme_classic() is a good place to start, and if you want to download the package hrbrthemes, I really like the theme_ipsum_rc().\n   Solutions (click here)  I\u0026rsquo;ve included some code that let\u0026rsquo;s you re-name the strip text, or the text that is above each of your facets. You do this with the labeller() function.\nlibrary(hrbrthemes) # for pretty \u0026amp; easy themes # formatting facet strip text labels dim_mm \u0026lt;- c(\"Culman Bill Depth\", \"Culman Bill Length\") names(dim_mm) \u0026lt;- c(\"depth_mm\", \"length_mm\") # this is just one example penguins_long %\u0026gt;% ggplot(aes(x = body_mass_g, y = value_mm, color = sex)) + geom_point() + theme_ipsum_rc() + theme(axis.title.x = element_text(hjust = 0.5), axis.title.y = element_text(hjust = 0.5), strip.text = element_text(hjust = 0.5)) + labs(x = \"Body Mass (g)\", y = \"mm\", title = \"Bill length and depth vs. body mass in penguins\", color = \"Sex\", caption = \"Data from https://allisonhorst.github.io/palmerpenguins/\") + facet_wrap(vars(bill_dimension), labeller = labeller(bill_dimension = dim_mm))       Exercise 4  Add a second dimension of faceting by species.\n  Hints (click here)  You do this within your facet_wrap() call. You might want to try the formula syntax, which works like this: var1~var2.    Solutions (click here)  penguins_long %\u0026gt;% ggplot(aes(x = body_mass_g, y = value_mm, color = sex)) + geom_point() + theme_ipsum_rc() + theme(axis.title.x = element_text(hjust = 0.5), axis.title.y = element_text(hjust = 0.5), strip.text = element_text(hjust = 0.5)) + labs(x = \"Body Mass (g)\", y = \"mm\", title = \"Bill length and depth vs. body mass in penguins\", color = \"Sex\", caption = \"Data from https://allisonhorst.github.io/palmerpenguins/\") + facet_wrap(bill_dimension~species, labeller = labeller(bill_dimension = dim_mm))       Exercise 5  Using your plot from Exercise 3, highlight the datapoints coming from Dream Island in purple.\n  Hints (click here)  You can use syntax inside gghighlight() just like you do in filter().    Solutions (click here)  # what are our islands? unique(penguins_long$island) #\u0026gt; [1] Torgersen Biscoe Dream  #\u0026gt; Levels: Biscoe Dream Torgersen penguins_long %\u0026gt;% ggplot(aes(x = body_mass_g, y = value_mm)) + geom_point(color = \"purple\") + gghighlight(island == \"Dream\") + facet_wrap(vars(bill_dimension))       Exercise 6  Using your sample plot for Exercise 3, highlight penguins that have a body_mass_g less than 3500 g, in blue.\n  Hints (click here)  You can use syntax inside gghighlight() just like you do in filter(), and you can also use these filter functions like \u0026lt;, \u0026gt;, \u0026lt;=, ! and AND inside your call.    Solutions (click here)  # what are our islands? unique(penguins_long$island) #\u0026gt; [1] Torgersen Biscoe Dream  #\u0026gt; Levels: Biscoe Dream Torgersen penguins_long %\u0026gt;% ggplot(aes(x = body_mass_g, y = value_mm)) + geom_point(color = \"blue\") + gghighlight(island == \"Dream\") + facet_wrap(vars(bill_dimension))       Bonus exercises Bonus 1  Plot flipper_length_mm vs. body_mass_g and animate the plot to show only one species at a time.\n  Hints (click here)  Try animating over species, using transition_states() and set {closest_state} in your title or subtitle so you can tell what you\u0026rsquo;re looking at.    Solutions (click here)  flipper_by_BW \u0026lt;- penguins %\u0026gt;% ggplot(aes(x = body_mass_g, y = flipper_length_mm, fill = species)) + geom_point(shape = 21, color = \"black\") + theme_classic() + theme(legend.position = 'none') + labs(title = \"Population and Life Expectancy in the Americas\", subtitle = 'Penguin Species: \u0026#123;closest_state\u0026#125;', x = \"Body Mass (g)\", y = \"Flipper Length (mm)\") + transition_states(species) animate(flipper_by_BW)      Bonus 2  You have now made an excellent gif, so save it!\n  Hints (click here)  Use anim_save() to save your animation, which works in a similar way to ggsave(), which is another very useful function.    Solutions (click here)  # set parameters for your animation animate(flipper_by_BW, duration = 10, fps = 10, width = 700, height = 700, renderer = magick_renderer()) # save it anim_save(filename = \"flippers_by_mass.gif\", animation = last_animation(), path = \"YOUR_PATH_HERE\")      Bonus 3  Let\u0026rsquo;s practice making multi-panel plots. Plot:\nBoxplot of body_mass_g by sex\nHistogram of number of observations per island\nDistribution of flipper_length_mm by species.\nTag your plots so each has a lowercase letter associated with it.\n  Hints (click here)  Use the syntax from the package patchwork. You can learn more here. Also use plot_annotation().    Solutions (click here)   title allows you to set a title tag_levels allows you to determine how you want your panels to be tagged.  Boxplot of body_mass_g by sex.\npenguins_mass_by_sex \u0026lt;- penguins_long %\u0026gt;% ggplot(aes(x = sex, y = body_mass_g)) + geom_boxplot() penguins_mass_by_sex   Histogram of number of observations per island.\npenguins_by_island \u0026lt;- penguins_long %\u0026gt;% ggplot(aes(y = island, fill = island)) + geom_histogram(stat = \"count\") #\u0026gt; Warning: Ignoring unknown parameters: binwidth, bins, pad penguins_by_island   Distribution of flipper_length_mm by species.\npenguins_flipper_species \u0026lt;- penguins_long %\u0026gt;% ggplot(aes(x = flipper_length_mm, group = species, fill = species)) + geom_density(alpha = 0.5) + scale_fill_viridis_d() penguins_flipper_species   penguins_flipper_species / (penguins_mass_by_sex + penguins_by_island) + plot_annotation(title = \"Looking at penguins...\", tag_levels = \"a\")       ","date":1613520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613604588,"objectID":"3abf1bebd3e7269759e016e707cae871","permalink":"https://biodash.github.io/codeclub/10_faceting-animating/","publishdate":"2021-02-17T00:00:00Z","relpermalink":"/codeclub/10_faceting-animating/","section":"codeclub","summary":"During this tenth session of Code Club, we will be continuing to work on making visualizations using ggplot2, including faceting plots, making multi-panel figures, and animating charts.","tags":null,"title":"Session 10: Faceting, multi-plots, and animating","type":"codeclub"},{"authors":["Michael Broe"],"categories":null,"content":"  Image from https://r4ds.had.co.nz    New To Code Club?   First, check out the Code Club Computer Setup instructions, which also has some pointers that might be helpful if you\u0026rsquo;re new to R or RStudio.\n  Please open RStudio before Code Club to test things out \u0026ndash; if you run into issues, join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n   Session Goals  Learn the uses of R\u0026rsquo;s three basic subsetting operators: [ ], [[ ]], and $. Learn how the behavior of these operators varies depending on the data structure you are subsetting (vector, matrix, list, or data frame). Prepare to learn how these resemble, and differ from, subsetting operators in Python.   Intro: What is \u0026lsquo;subsetting\u0026rsquo; anyway? Subsetting (also known as indexing) is simply a formal way of pulling out specific pieces of a data structure. We\u0026rsquo;ve already seen two dplyr verbs that perform this kind of operation for tibbles: filter (to pull out specific rows) and select (to pull out specific columns).\nBut these are tidyverse commands, and only work with tibbles. R has two more-basic data structures, vectors and lists, and for these we need different subsetting operators. We\u0026rsquo;ll also see that matrices are simply a special kind of vector, that data frames are a special kind of list, and basic subsetting operators also work for these.\nSince the behavior of these operators depends on the actual data structure you are working with, it\u0026rsquo;s useful when experimenting to use them in conjunction with the str() function, which compactly displays the internal structure of an arbitrary R object. A knowledge of the make-up of these data structures is also important when you come to write your own loops, iterations, and functions.\nThe most important distinction between vectors and lists is that vectors are homogeneous, while lists can be heterogeneous.\n Terminological note: \u0026lsquo;under-the-hood\u0026rsquo; both of these are vectors in the technical sense, and sometimes the distinction is referred to as atomic vectors versus recursive vectors. I\u0026rsquo;ll continue to use just \u0026lsquo;vector\u0026rsquo; and \u0026lsquo;list\u0026rsquo; here. This usage also lines-up with Python.\n   Vectors A vector is absolutely the most basic data structure in R. Every value in a vector must be of the same type. Strikingly, this sets R apart from Python. Using this kind of vector in Python requires loading a whole separate package: numpy. The most basic data structure in Python is the list.\nThere are four basic types of vector: integer, double, character, and logical. Vectors are created by hand with the c() (combine, concatenate) function. We can check the type with the typeof() operator. This is totally redundant if you just created the vector yourself, but when you are debugging code or creating a vector using an expression you might want to check exactly what type of vector is being used:\nvec_dbl \u0026lt;- c(1, 2, 3, 4, 5) typeof(vec_dbl) #\u0026gt; [1] \"double\"   vec_int \u0026lt;- c(1L, 2L, 3L, 4L, 5L) typeof(vec_int) #\u0026gt; [1] \"integer\"   vec_which \u0026lt;- seq(1, 10) typeof(vec_which) #\u0026gt; [1] \"integer\"   vec_which2 \u0026lt;- 1:10 typeof(vec_which2) #\u0026gt; [1] \"integer\"   vec_log \u0026lt;- c(TRUE, TRUE, FALSE, TRUE, FALSE) typeof(vec_log) #\u0026gt; [1] \"logical\"   vec_chr \u0026lt;- c(\"a\", \"b\", \"c\", \"d\", \"e\") typeof(vec_chr) #\u0026gt; [1] \"character\"   What happens when we perform a basic mathematical operation on a vector?\n2 * vec_int #\u0026gt; [1] 2 4 6 8 10   (This is completely different than what you obtain when multiplying a Python list).\nL = [1, 2, 3, 4, 5] 2 * L # [1, 2, 3, 4, 5, 1, 2, 3, 4, 5] So it\u0026rsquo;s not just that vectors are a basic R data structure, but R is a vectorised language. In many cases applying an operation to a vector automagically applies the operation to every element in the vector. This means that for many basic operations for loops and mapping functions, necessary in Python, are not needed in R (although if you write your own functions you will need these iteration tools). In Python we could use a \u0026lsquo;list comprehension\u0026rsquo; (a compact and fast version of a for loop):\n[2 * i for i in L] # [2, 4, 6, 8, 10] Or install the numpy package that makes vectors and vectorized functions available.\nVectors have an insanely simple structure:\nstr(vec_dbl) #\u0026gt; num [1:5] 1 2 3 4 5   str() also displays the type, and RStudio displays the result of str() in the Values pane.\nFor such a simple structure, there are a surprisingly large number of ways to subset a vector. We\u0026rsquo;ll use the following example:\nx \u0026lt;- c(2.1, 4.2, 3.3, 5.4)   (Notice that the number after the decimal point indicates the position (index) of the element of the vector.)\nPositive integers return elements at the specified positions. Any expression that evaluates to a vector of positive integers can be used as the index. The index operator is []:\nx[3] #\u0026gt; [1] 3.3 x[c(3, 1)] #\u0026gt; [1] 3.3 2.1 x[2:4] #\u0026gt; [1] 4.2 3.3 5.4 x[seq(1, 4, 2)] #\u0026gt; [1] 2.1 3.3   (In R the indices run from 1 to the length of the object: in Python indices run from 0 to length-1).\nNegative integers exclude elements at the specified positions:\nx[-3] #\u0026gt; [1] 2.1 4.2 5.4 x[-c(3, 1)] #\u0026gt; [1] 4.2 5.4 #\u0026gt; [1] 4.2 5.4   Logical vectors select elements where the corresponding logical value is TRUE. This is most useful if you can write a comparison expression 2 \u0026gt; 3, 4 == 4, that returns TRUE (or FALSE) for each element of the vector:\nx[c(TRUE, TRUE, FALSE, FALSE)] #\u0026gt; [1] 2.1 4.2 x[x \u0026gt; 3] #\u0026gt; [1] 4.2 3.3 5.4   Attributes. One of the unusual features of R as opposed to Python is that you can assign metadata of various kinds to the elements of vectors (and lists). For example, we can assign a name to each element, and then use a character vector as the index expression:\ny \u0026lt;- c(a = 2.1, b = 4.2, c = 3.3, d = 5.4) str(y) #\u0026gt; Named num [1:4] 2.1 4.2 3.3 5.4 #\u0026gt; - attr(*, \"names\")= chr [1:4] \"a\" \"b\" \"c\" \"d\" y[c(\"d\", \"c\", \"a\")] #\u0026gt; d c a  #\u0026gt; 5.4 3.3 2.1   (Again, Python has no direct equivalent of this, but we can get a similar effect using a dictionary data structure, which explicitly assigns a name to each value).\nNothing ([]) returns the entire vector:\nx[] #\u0026gt; [1] 2.1 4.2 3.3 5.4   This is not useful for (one dimensional) vectors, but is behind the notation for extracting rows and columns from matrices. Keep in mind a \u0026ldquo;nothing\u0026rdquo; index returns \u0026ldquo;everything\u0026rdquo;.\nMatrices A matrix is simply a vector with a dimensions attribute. Here we convert a vector to a two-dimensional matrix, with two rows and three columns, with dim(rows, cols).\nz \u0026lt;- c(2.1, 4.2, 3.3, 5.4, 8.5, 1.6) dim(z) \u0026lt;- c(2, 3) z #\u0026gt; [,1] [,2] [,3] #\u0026gt; [1,] 2.1 3.3 8.5 #\u0026gt; [2,] 4.2 5.4 1.6   Now we can index a specific value using comma notation, where the first index specifies the row, and the second index the column (in Python this is reversed):\nz[2,3] #\u0026gt; [1] 1.6   And in two dimensions the nothing after the , returns every column for that row:\nz[2,] #\u0026gt; [1] 4.2 5.4 1.6   And here is a way of selecting a submatrix (every row for all columns except the first):\nz[,-1] #\u0026gt; [,1] [,2] #\u0026gt; [1,] 3.3 8.5 #\u0026gt; [2,] 5.4 1.6   Lists There are two main differences between vectors and lists: (i) lists can contain elements of different types; and (ii) lists can contain other lists. This is why lists are sometimes referred to as recursive vectors. We will see examples of these below, but first let\u0026rsquo;s directly compare a list of numbers to a vector of numbers, and examine the structure. Lists are constructed with the list() function.\nl \u0026lt;- list(2.1, 4.2, 3.3, 5.4) l #\u0026gt; [[1]] #\u0026gt; [1] 2.1 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 4.2 #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 3.3 #\u0026gt;  #\u0026gt; [[4]] #\u0026gt; [1] 5.4 str(l) #\u0026gt; List of 4 #\u0026gt; $ : num 2.1 #\u0026gt; $ : num 4.2 #\u0026gt; $ : num 3.3 #\u0026gt; $ : num 5.4   Here we see the appearance of a new subsetting operator [[ ]]. What does it yield?\nll_2 \u0026lt;- l[[2]] ll_2 #\u0026gt; [1] 4.2 typeof(ll_2) #\u0026gt; [1] \"double\"   Now compare this to the result of using the [ ] operator:\nl_2 \u0026lt;- l[2] l_2 #\u0026gt; [[1]] #\u0026gt; [1] 4.2 typeof(l_2) #\u0026gt; [1] \"list\" str(l_2) #\u0026gt; List of 1 #\u0026gt; $ : num 4.2   The behavior of the [ ] operator is very different for lists: it selects the element(s) you request, but it always returns a subsetted version of the original list. It \u0026lsquo;shrinks\u0026rsquo; the original list. There is nothing like this in Python; it\u0026rsquo;s quite unique to R. (The reason this is the case will become clear when we examine data frames.) The [[ ]] operator on the other hand just returns the object you select.\nAs mentioned above, it\u0026rsquo;s quite possible that an element of a list might itself be a list:\nm \u0026lt;- list(2.1, list(4.21, 4.22), 3.3, 5.4) m #\u0026gt; [[1]] #\u0026gt; [1] 2.1 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [[2]][[1]] #\u0026gt; [1] 4.21 #\u0026gt;  #\u0026gt; [[2]][[2]] #\u0026gt; [1] 4.22 #\u0026gt;  #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 3.3 #\u0026gt;  #\u0026gt; [[4]] #\u0026gt; [1] 5.4   This (print) output focuses on content, whereas the str() function focuses on structure, and is very useful for nested lists:\nstr(m) #\u0026gt; List of 4 #\u0026gt; $ : num 2.1 #\u0026gt; $ :List of 2 #\u0026gt; ..$ : num 4.21 #\u0026gt; ..$ : num 4.22 #\u0026gt; $ : num 3.3 #\u0026gt; $ : num 5.4   Once we combine nested lists and multiple types, things can get pretty hairy. There are various ways to visualize what\u0026rsquo;s going on. Here is one example:\nx1 \u0026lt;- list(c(1, 2), c(3, 4)) x2 \u0026lt;- list(list(1, 2), list(3, 4)) x3 \u0026lt;- list(1, list(2, list(3)))   However the printed form provides us a clue on how to extract an individual element from inside a nested list:\n# m \u0026lt;- list(2.1, list(4.21, 4.22), 3.3, 5.4) m[[2]] #\u0026gt; [[1]] #\u0026gt; [1] 4.21 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 4.22   m[[2]][[1]] #\u0026gt; [1] 4.21   In short, [[ ]] drills down into a list, while [ ] returns a diminished version of the original list.\nHere\u0026rsquo;s a visualization of various list subsetting operations:\na \u0026lt;- list(1:3, \"a string\", pi, list(-1, -5)) a #\u0026gt; [[1]] #\u0026gt; [1] 1 2 3 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] \"a string\" #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 3.141593 #\u0026gt;  #\u0026gt; [[4]] #\u0026gt; [[4]][[1]] #\u0026gt; [1] -1 #\u0026gt;  #\u0026gt; [[4]][[2]] #\u0026gt; [1] -5 str(a) #\u0026gt; List of 4 #\u0026gt; $ : int [1:3] 1 2 3 #\u0026gt; $ : chr \"a string\" #\u0026gt; $ : num 3.14 #\u0026gt; $ :List of 2 #\u0026gt; ..$ : num -1 #\u0026gt; ..$ : num -5   Subsetting a list, visually. Here is a recursive pepper shaker, p\nHere is the first packet, but still inside the shaker, p[1]\nHere is the first packet by itself, p[[1]]\nAnd here is the contents of that packet, p[[1]][[1]]\nWe\u0026rsquo;ll play with yet another type of visualization in the exercises.\nData frames Let\u0026rsquo;s look at a simple data frame:\ndf \u0026lt;- data.frame(x = 1:3, y = c(\"a\", \"b\", \"c\")) typeof(df) #\u0026gt; [1] \"list\" str(df) #\u0026gt; 'data.frame': 3 obs. of 2 variables: #\u0026gt; $ x: int 1 2 3 #\u0026gt; $ y: chr \"a\" \"b\" \"c\"   So a data frame is basically a list (of columns), with a names attribute for the column names; and with the extra condition that all the columns are of the same length. So we should be able to use our standard list subsetting operators on it:\ndf_col_1 \u0026lt;- df[1] str(df_col_1) #\u0026gt; 'data.frame': 3 obs. of 1 variable: #\u0026gt; $ x: int 1 2 3   Since a data frame is a list, subsetting using [ ] returns the specified column still inside a data frame. What about [[ ]]?\ncol_1 \u0026lt;- df[[1]] str(col_1) #\u0026gt; int [1:3] 1 2 3   Using [[ ]] returns the individual column.\nWe can also subset a data frame by name:\ndf_name \u0026lt;- df[\"x\"] str(df_name) #\u0026gt; 'data.frame': 3 obs. of 1 variable: #\u0026gt; $ x: int 1 2 3   df_nname \u0026lt;- df[[\"x\"]] str(df_nname) #\u0026gt; int [1:3] 1 2 3   Finally df$x is simply a shorthand for df[[\u0026quot;x\u0026quot;]] without the [[ ]] and the \u0026quot; \u0026quot;:\ndf_dollar_name \u0026lt;- df$x str(df_dollar_name) #\u0026gt; int [1:3] 1 2 3   Just as a matter of interest, in the grand scheme of things lists are just a special kind of vector (a \u0026lsquo;heterogeneous recursive vector\u0026rsquo;), so it should be possible to stick a list column into a data frame. We can, but we have to use the I \u0026lsquo;identity\u0026rsquo; operator around the list:\ndf_mixed \u0026lt;- data.frame( x = 1:3, y = I(list(4L, 7.2, \"string\"))) str(df_mixed) #\u0026gt; 'data.frame': 3 obs. of 2 variables: #\u0026gt; $ x: int 1 2 3 #\u0026gt; $ y:List of 3 #\u0026gt; ..$ : int 4 #\u0026gt; ..$ : num 7.2 #\u0026gt; ..$ : chr \"string\" #\u0026gt; ..- attr(*, \"class\")= chr \"AsIs\"   Further reading and acknowledgement For more details on subsetting see R for Data Science and Advanced R both by Hadley Wickham, from which much of the material in this module was borrowed.\n Exercise 1 A surprisingly useful operator for extracting elements of a numerical vector is the modulo operator x %% y. This returns the remainder when x is divided by y. It is a vectorized operation, so we can apply it to a list.\nx \u0026lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) x %% 3 #\u0026gt; [1] 1 2 0 1 2 0 1 2 0 1   Use this operator to extract every third element of the above vector x.\n  Hints (click here)  \nCheck the example in the presentation about selecting elements when the logical comparison is TRUE. What is the logical test we need to identify every third element?    Solution (click here)  x \u0026lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) x[x %% 3 == 0] #\u0026gt; [1] 3 6 9      Exercise 2 Here is a visualization of a list:\nCreate a list in R called train that captures this structure. Print the list, and also display its structure.\n  Hints (click here)  \nThis list has no nested lists, it\u0026rsquo;s just a list of vectors and individual values.    Solution (click here)  train \u0026lt;- list(1:3, \"a\", 4:6) train #\u0026gt; [[1]] #\u0026gt; [1] 1 2 3 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] \"a\" #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 4 5 6 str(train) #\u0026gt; List of 3 #\u0026gt; $ : int [1:3] 1 2 3 #\u0026gt; $ : chr \"a\" #\u0026gt; $ : int [1:3] 4 5 6      Exercise 3 For each of the following sub-trains/carriages, determine the subsetting expression by eye, and then check that it works by subsetting your train list from exercise 1.\n  Hints (click here)  There's more than one way to do these; you will have to use both `[ ]` and `[[ ]]` operators. The last two are tricky, experiment with them...    Solution (click here)  train[1] #\u0026gt; [[1]] #\u0026gt; [1] 1 2 3   train[[1]] #\u0026gt; [1] 1 2 3   train[1:2] #\u0026gt; [[1]] #\u0026gt; [1] 1 2 3 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] \"a\"   train[-2] #\u0026gt; [[1]] #\u0026gt; [1] 1 2 3 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 4 5 6   train[c(1, 1)] #\u0026gt; [[1]] #\u0026gt; [1] 1 2 3 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 1 2 3   train[0] #\u0026gt; list()      Exercise 4 A common use of recursive structures in biology is to represent phylogenetic trees. Create a recursive list in R called tree which captures the following visual representation\n  Hints (click here)  Start at the top and work down. Start with a simpler subtree, then expand terminals. Alternatively, start at the bottom with the smallest subtree, then work up, adding sisters into parent nodes.\nIn either case, check your working with str() as you incrementally add structure.\nNotice this is a binary branching tree, so the root node of every subtree should contain two elements.\nOne of the tricks with these nested lists is to keep track of paired parentheses\u0026hellip;\nStay calm and recurse.    Solution (click here)  tree \u0026lt;- list(\"a\", list(list(\"b\", \"c\"), \"d\")) str(tree) #\u0026gt; List of 2 #\u0026gt; $ : chr \"a\" #\u0026gt; $ :List of 2 #\u0026gt; ..$ :List of 2 #\u0026gt; .. ..$ : chr \"b\" #\u0026gt; .. ..$ : chr \"c\" #\u0026gt; ..$ : chr \"d\"      \n","date":1612915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613152528,"objectID":"1f0acc316d61e12ddf0b12b66dfb0a7c","permalink":"https://biodash.github.io/codeclub/09_subsetting/","publishdate":"2021-02-10T00:00:00Z","relpermalink":"/codeclub/09_subsetting/","section":"codeclub","summary":"In this session of Code Club, we'll move below and beyond the tidyverse to get an overview of subsetting various kinds of data structure in R.","tags":null,"title":"Session 9: Subsetting","type":"codeclub"},{"authors":["Mike Sovic"],"categories":null,"content":" Session Goals  Describe differences in long data vs wide data. Identify scenarios where it might be helpful to have data in one format over another (longer vs. wider). Use the functions pivot_longer() and pivot_wider() to reshape data. Use NHANES data to address whether blood pressure values vary in a predictable way with successive measurements.   Intro: The Shape Of A Dataset A single set of data can sometimes be stored in different ways, or in other words, it can have different shapes. Below is a small example. It\u0026rsquo;s a hypothetical dataset that stores the number of visitors at each of two parks over a long weekend, and we\u0026rsquo;ll look at two different versions of it\u0026hellip;\nWide Format #create the dataset visitors_wide \u0026lt;- data.frame(\"park\" = c(\"north_park\", \"south_park\"), \"Fri\" = c(65, 80), \"Sat\" = c(184, 160), \"Sun\" = c(135, 140), \"Mon\" = c(87, 71)) #view the dataset visitors_wide #\u0026gt; park Fri Sat Sun Mon #\u0026gt; 1 north_park 65 184 135 87 #\u0026gt; 2 south_park 80 160 140 71   Long Format #create the dataset visitors_long \u0026lt;- data.frame(\"park\" = rep(c(\"north_park\", \"south_park\"), 4), \"day\" = c(\"Fri\",\"Fri\",\"Sat\",\"Sat\",\"Sun\",\"Sun\",\"Mon\",\"Mon\"), \"visitors\" = c(65,80,184,160,135,140,87,71)) #view the dataset visitors_long #\u0026gt; park day visitors #\u0026gt; 1 north_park Fri 65 #\u0026gt; 2 south_park Fri 80 #\u0026gt; 3 north_park Sat 184 #\u0026gt; 4 south_park Sat 160 #\u0026gt; 5 north_park Sun 135 #\u0026gt; 6 south_park Sun 140 #\u0026gt; 7 north_park Mon 87 #\u0026gt; 8 south_park Mon 71   Notice that both datasets store the same information - it\u0026rsquo;s just formatted differently. These two datasets can be said to have different shapes. The first has a wider shape - it has more columns, stretching it out from left to right. The second has a longer shape, as it has fewer columns and more rows. Again, importantly, both datasets store the same information.\nWhat Shape Should Your Data Be In? The best answer to the question of what shape your data should be in is probably something like \u0026lsquo;Whatever shape makes it easiest to accomplish your goals with the data at any given time\u0026rsquo;. For example, sometimes when you\u0026rsquo;re entering data - say in to a spreadsheet in Excel or a similar program, you might find the data entry process easier if the dataset is in a wider format. In contrast, longer formats will generally be better when analyzing your data. This is consistent with the idea of tidy data we talked about in Session 2. For example, tidy data will be long because a characteristic of tidy data is that each variable has its own column. For these reasons, you might find it helpful or even necessary to reshape the data - possibly multiple times as you continue to work with the same dataset.\nHow To Reshape Data R offers several approaches for reshaping data. Functions for doing so often come in pairs that transform from wider to longer, and longer to wider, respectively. Pairs of functions include cast() and melt(), spread() and gather(), and pivot_longer() and pivot_wider(). While any of these can be used, we\u0026rsquo;ll focus on the \u0026lsquo;pivot\u0026rsquo; pair that come from the package tidyr, as they were written most recently with a goal of being the most user-friendly of the available functions so far.\nPivoting Resources If you want to dig in to pivoting a bit more, R offers a very useful vignette on pivoting, which is worth a look - portions of today\u0026rsquo;s breakout sessions will come from there. Chapter 12 of \u0026ldquo;R For Data Science\u0026rdquo; by Wickham and Grolemund, which covers tidy data, also includes a nice section on pivoting.\n Examples Let\u0026rsquo;s revisit the park visitors dataset for an example of how pivot_longer() and pivot_wider() work in their most basic form. Previously, I created each of the wide and long forms of this dataset by hand. It was manageable to do that, since it\u0026rsquo;s a very small dataset, but for most datasets, you\u0026rsquo;re not going to want to just recreate a data frame from scratch each time you need to reshape the data. Let\u0026rsquo;s start with the data in wide format\u0026hellip;\n#view the data frame visitors_wide #\u0026gt; park Fri Sat Sun Mon #\u0026gt; 1 north_park 65 184 135 87 #\u0026gt; 2 south_park 80 160 140 71   What if we wanted to plot the total mean number of visitors per day across both parks? To get the mean values, we might think about applying some of the functions we\u0026rsquo;ve been working with in previous sessions like group_by() and summarize(). For example, we might want to try grouping by day and then calculating the means from a column that stores the number of visitors. However, in it\u0026rsquo;s current wide form, this dataset doesn\u0026rsquo;t have the day and visitors columns we need. pivot_longer() can help us here. The command might look like this\u0026hellip;\nlibrary(tidyverse) visitors_longer \u0026lt;- visitors_wide %\u0026gt;% pivot_longer(-park, names_to = \"day\", values_to = \"visitors\")   First, we need to point it to the dataset we\u0026rsquo;re interested in reshaping - I\u0026rsquo;m doing that by piping the visitors_wide data frame to pivot_longer(). Next, we need to specify what columns to use to lengthen the dataset. This argument recognizes tidy-select notation, which can really simplify things. Here, I\u0026rsquo;m using -park, which tells it to use all the column names except park. Those column names will be transformed to values in a single new column, which needs a name. We\u0026rsquo;ll call it day, so names_to = \u0026quot;day\u0026quot;. Finally, the values in the current columns will be stacked in to a single column, and it too needs a name, so values_to = \u0026quot;visitors\u0026quot;. This lengthens the dataset, taking it from 5 columns down to 3.\n#view the data visitors_longer #\u0026gt; # A tibble: 8 x 3 #\u0026gt; park day visitors #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 north_park Fri 65 #\u0026gt; 2 north_park Sat 184 #\u0026gt; 3 north_park Sun 135 #\u0026gt; 4 north_park Mon 87 #\u0026gt; 5 south_park Fri 80 #\u0026gt; 6 south_park Sat 160 #\u0026gt; 7 south_park Sun 140 #\u0026gt; 8 south_park Mon 71   In this longer format, we\u0026rsquo;re able to apply the group_by() and summarize() functions\u0026hellip;\nvisitors_longer %\u0026gt;% group_by(day) %\u0026gt;% summarise(\"mean\" = mean(visitors)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 4 x 2 #\u0026gt; day mean #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Fri 72.5 #\u0026gt; 2 Mon 79  #\u0026gt; 3 Sat 172  #\u0026gt; 4 Sun 138.   And we can go in the opposite direction with pivot_wider()\u0026hellip;\nvisitors_longer %\u0026gt;% pivot_wider(names_from = day, values_from = visitors) #\u0026gt; # A tibble: 2 x 5 #\u0026gt; park Fri Sat Sun Mon #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 north_park 65 184 135 87 #\u0026gt; 2 south_park 80 160 140 71   The examples above represent the most basic uses of pivot_longer() and pivot_wider(). But each of these functions offer additional arguments that can help deal with more complicated situations. The next example is from the pivoting vignette I referenced above. It uses the billboard dataset that should already be available in your R session, and that stores weekly rankings of Billboard top 100 songs from the year 2000.\n#preview billboard data head(billboard) #\u0026gt; # A tibble: 6 x 79 #\u0026gt; artist track date.entered wk1 wk2 wk3 wk4 wk5 wk6 wk7 wk8 #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 2 Pac Baby… 2000-02-26 87 82 72 77 87 94 99 NA #\u0026gt; 2 2Ge+h… The … 2000-09-02 91 87 92 NA NA NA NA NA #\u0026gt; 3 3 Doo… Kryp… 2000-04-08 81 70 68 67 66 57 54 53 #\u0026gt; 4 3 Doo… Loser 2000-10-21 76 76 72 69 67 65 55 59 #\u0026gt; 5 504 B… Wobb… 2000-04-15 57 34 25 17 17 31 36 49 #\u0026gt; 6 98^0 Give… 2000-08-19 51 39 34 26 26 19 2 2 #\u0026gt; # … with 68 more variables: wk9 \u0026lt;dbl\u0026gt;, wk10 \u0026lt;dbl\u0026gt;, wk11 \u0026lt;dbl\u0026gt;, wk12 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk13 \u0026lt;dbl\u0026gt;, wk14 \u0026lt;dbl\u0026gt;, wk15 \u0026lt;dbl\u0026gt;, wk16 \u0026lt;dbl\u0026gt;, wk17 \u0026lt;dbl\u0026gt;, wk18 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk19 \u0026lt;dbl\u0026gt;, wk20 \u0026lt;dbl\u0026gt;, wk21 \u0026lt;dbl\u0026gt;, wk22 \u0026lt;dbl\u0026gt;, wk23 \u0026lt;dbl\u0026gt;, wk24 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk25 \u0026lt;dbl\u0026gt;, wk26 \u0026lt;dbl\u0026gt;, wk27 \u0026lt;dbl\u0026gt;, wk28 \u0026lt;dbl\u0026gt;, wk29 \u0026lt;dbl\u0026gt;, wk30 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk31 \u0026lt;dbl\u0026gt;, wk32 \u0026lt;dbl\u0026gt;, wk33 \u0026lt;dbl\u0026gt;, wk34 \u0026lt;dbl\u0026gt;, wk35 \u0026lt;dbl\u0026gt;, wk36 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk37 \u0026lt;dbl\u0026gt;, wk38 \u0026lt;dbl\u0026gt;, wk39 \u0026lt;dbl\u0026gt;, wk40 \u0026lt;dbl\u0026gt;, wk41 \u0026lt;dbl\u0026gt;, wk42 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk43 \u0026lt;dbl\u0026gt;, wk44 \u0026lt;dbl\u0026gt;, wk45 \u0026lt;dbl\u0026gt;, wk46 \u0026lt;dbl\u0026gt;, wk47 \u0026lt;dbl\u0026gt;, wk48 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk49 \u0026lt;dbl\u0026gt;, wk50 \u0026lt;dbl\u0026gt;, wk51 \u0026lt;dbl\u0026gt;, wk52 \u0026lt;dbl\u0026gt;, wk53 \u0026lt;dbl\u0026gt;, wk54 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk55 \u0026lt;dbl\u0026gt;, wk56 \u0026lt;dbl\u0026gt;, wk57 \u0026lt;dbl\u0026gt;, wk58 \u0026lt;dbl\u0026gt;, wk59 \u0026lt;dbl\u0026gt;, wk60 \u0026lt;dbl\u0026gt;, #\u0026gt; # wk61 \u0026lt;dbl\u0026gt;, wk62 \u0026lt;dbl\u0026gt;, wk63 \u0026lt;dbl\u0026gt;, wk64 \u0026lt;dbl\u0026gt;, wk65 \u0026lt;dbl\u0026gt;, wk66 \u0026lt;lgl\u0026gt;, #\u0026gt; # wk67 \u0026lt;lgl\u0026gt;, wk68 \u0026lt;lgl\u0026gt;, wk69 \u0026lt;lgl\u0026gt;, wk70 \u0026lt;lgl\u0026gt;, wk71 \u0026lt;lgl\u0026gt;, wk72 \u0026lt;lgl\u0026gt;, #\u0026gt; # wk73 \u0026lt;lgl\u0026gt;, wk74 \u0026lt;lgl\u0026gt;, wk75 \u0026lt;lgl\u0026gt;, wk76 \u0026lt;lgl\u0026gt;   Notice there are columns named \u0026lsquo;wk1\u0026rsquo; through \u0026lsquo;wk73\u0026rsquo; that store the weekly ranking for each song. Week itself is a variable with values that could be represented in a single column. We could do something similar to our above use of pivot_longer()\u0026hellip;\nbillboard %\u0026gt;% pivot_longer(cols = starts_with(\"wk\"), names_to = \"week\", values_to = \"rank\") %\u0026gt;% head() #\u0026gt; # A tibble: 6 x 5 #\u0026gt; artist track date.entered week rank #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 2 Pac Baby Don't Cry (Keep... 2000-02-26 wk1 87 #\u0026gt; 2 2 Pac Baby Don't Cry (Keep... 2000-02-26 wk2 82 #\u0026gt; 3 2 Pac Baby Don't Cry (Keep... 2000-02-26 wk3 72 #\u0026gt; 4 2 Pac Baby Don't Cry (Keep... 2000-02-26 wk4 77 #\u0026gt; 5 2 Pac Baby Don't Cry (Keep... 2000-02-26 wk5 87 #\u0026gt; 6 2 Pac Baby Don't Cry (Keep... 2000-02-26 wk6 94   This is a start - we\u0026rsquo;ve gone from 79 columns to just 6. But we can clean this up a bit more. Notice the values in the new week column all include the \u0026lsquo;wk\u0026rsquo; prefix. Since we\u0026rsquo;ve labeled the column \u0026lsquo;week\u0026rsquo;, it\u0026rsquo;s kind of redundant and unnecessary to have \u0026lsquo;wk\u0026rsquo; at the beginning of each value. We can add the \u0026lsquo;names_prefix\u0026rsquo; argument, which accepts a regular expression (regex). Characters at the beginning of column names that match the regex get removed.\nbillboard %\u0026gt;% pivot_longer(cols = starts_with(\"wk\"), names_to = \"week\", values_to = \"rank\", names_prefix = \"wk\") %\u0026gt;% head() #\u0026gt; # A tibble: 6 x 5 #\u0026gt; artist track date.entered week rank #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 2 Pac Baby Don't Cry (Keep... 2000-02-26 1 87 #\u0026gt; 2 2 Pac Baby Don't Cry (Keep... 2000-02-26 2 82 #\u0026gt; 3 2 Pac Baby Don't Cry (Keep... 2000-02-26 3 72 #\u0026gt; 4 2 Pac Baby Don't Cry (Keep... 2000-02-26 4 77 #\u0026gt; 5 2 Pac Baby Don't Cry (Keep... 2000-02-26 5 87 #\u0026gt; 6 2 Pac Baby Don't Cry (Keep... 2000-02-26 6 94   We haven\u0026rsquo;t dealt with regular expressions in Code Club yet - they\u0026rsquo;ll make a good topic for a future session, but if you\u0026rsquo;re interested in the meantime, I did a couple short videos introducing them as part of this set of videos on command line computing.\nBreakout Rooms In the breakout rooms, we\u0026rsquo;ll use a pivot function to analyze a portion of the NHANES dataset. We\u0026rsquo;ll use the data to try to address whether successive blood pressure measurements from the same individual differ in a predictable way.\nIf you haven\u0026rsquo;t already done it, you can install the NHANES dataset with\u0026hellip;\ninstall.packages(\"NHANES\", repos = \"http://cran.us.r-project.org\") #\u0026gt;  #\u0026gt; The downloaded binary packages are in #\u0026gt; /var/folders/s7/y_mgh3c54h9fjcyw9wqdkb8x4zs_jy/T//RtmpWxvWIv/downloaded_packages   Exercise 1  First let\u0026rsquo;s load and preview the NHANES dataset.\n  Hints (click here)  \nUse library() to load the dataset. The functions head() are glimpse() are a couple good options for previewing the data.    Solution (click here)  library(NHANES) glimpse(NHANES) #\u0026gt; Rows: 10,000 #\u0026gt; Columns: 76 #\u0026gt; $ ID \u0026lt;int\u0026gt; 51624, 51624, 51624, 51625, 51630, 51638, 51646, 516… #\u0026gt; $ SurveyYr \u0026lt;fct\u0026gt; 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10… #\u0026gt; $ Gender \u0026lt;fct\u0026gt; male, male, male, male, female, male, male, female, … #\u0026gt; $ Age \u0026lt;int\u0026gt; 34, 34, 34, 4, 49, 9, 8, 45, 45, 45, 66, 58, 54, 10,… #\u0026gt; $ AgeDecade \u0026lt;fct\u0026gt; 30-39, 30-39, 30-39, 0-9, 40-49, 0-9, 0-9, 4… #\u0026gt; $ AgeMonths \u0026lt;int\u0026gt; 409, 409, 409, 49, 596, 115, 101, 541, 541, 541, 795… #\u0026gt; $ Race1 \u0026lt;fct\u0026gt; White, White, White, Other, White, White, White, Whi… #\u0026gt; $ Race3 \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ Education \u0026lt;fct\u0026gt; High School, High School, High School, NA, Some Coll… #\u0026gt; $ MaritalStatus \u0026lt;fct\u0026gt; Married, Married, Married, NA, LivePartner, NA, NA, … #\u0026gt; $ HHIncome \u0026lt;fct\u0026gt; 25000-34999, 25000-34999, 25000-34999, 20000-24999, … #\u0026gt; $ HHIncomeMid \u0026lt;int\u0026gt; 30000, 30000, 30000, 22500, 40000, 87500, 60000, 875… #\u0026gt; $ Poverty \u0026lt;dbl\u0026gt; 1.36, 1.36, 1.36, 1.07, 1.91, 1.84, 2.33, 5.00, 5.00… #\u0026gt; $ HomeRooms \u0026lt;int\u0026gt; 6, 6, 6, 9, 5, 6, 7, 6, 6, 6, 5, 10, 6, 10, 10, 4, 3… #\u0026gt; $ HomeOwn \u0026lt;fct\u0026gt; Own, Own, Own, Own, Rent, Rent, Own, Own, Own, Own, … #\u0026gt; $ Work \u0026lt;fct\u0026gt; NotWorking, NotWorking, NotWorking, NA, NotWorking, … #\u0026gt; $ Weight \u0026lt;dbl\u0026gt; 87.4, 87.4, 87.4, 17.0, 86.7, 29.8, 35.2, 75.7, 75.7… #\u0026gt; $ Length \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ HeadCirc \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ Height \u0026lt;dbl\u0026gt; 164.7, 164.7, 164.7, 105.4, 168.4, 133.1, 130.6, 166… #\u0026gt; $ BMI \u0026lt;dbl\u0026gt; 32.22, 32.22, 32.22, 15.30, 30.57, 16.82, 20.64, 27.… #\u0026gt; $ BMICatUnder20yrs \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ BMI_WHO \u0026lt;fct\u0026gt; 30.0_plus, 30.0_plus, 30.0_plus, 12.0_18.5, 30.0_plu… #\u0026gt; $ Pulse \u0026lt;int\u0026gt; 70, 70, 70, NA, 86, 82, 72, 62, 62, 62, 60, 62, 76, … #\u0026gt; $ BPSysAve \u0026lt;int\u0026gt; 113, 113, 113, NA, 112, 86, 107, 118, 118, 118, 111,… #\u0026gt; $ BPDiaAve \u0026lt;int\u0026gt; 85, 85, 85, NA, 75, 47, 37, 64, 64, 64, 63, 74, 85, … #\u0026gt; $ BPSys1 \u0026lt;int\u0026gt; 114, 114, 114, NA, 118, 84, 114, 106, 106, 106, 124,… #\u0026gt; $ BPDia1 \u0026lt;int\u0026gt; 88, 88, 88, NA, 82, 50, 46, 62, 62, 62, 64, 76, 86, … #\u0026gt; $ BPSys2 \u0026lt;int\u0026gt; 114, 114, 114, NA, 108, 84, 108, 118, 118, 118, 108,… #\u0026gt; $ BPDia2 \u0026lt;int\u0026gt; 88, 88, 88, NA, 74, 50, 36, 68, 68, 68, 62, 72, 88, … #\u0026gt; $ BPSys3 \u0026lt;int\u0026gt; 112, 112, 112, NA, 116, 88, 106, 118, 118, 118, 114,… #\u0026gt; $ BPDia3 \u0026lt;int\u0026gt; 82, 82, 82, NA, 76, 44, 38, 60, 60, 60, 64, 76, 82, … #\u0026gt; $ Testosterone \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ DirectChol \u0026lt;dbl\u0026gt; 1.29, 1.29, 1.29, NA, 1.16, 1.34, 1.55, 2.12, 2.12, … #\u0026gt; $ TotChol \u0026lt;dbl\u0026gt; 3.49, 3.49, 3.49, NA, 6.70, 4.86, 4.09, 5.82, 5.82, … #\u0026gt; $ UrineVol1 \u0026lt;int\u0026gt; 352, 352, 352, NA, 77, 123, 238, 106, 106, 106, 113,… #\u0026gt; $ UrineFlow1 \u0026lt;dbl\u0026gt; NA, NA, NA, NA, 0.094, 1.538, 1.322, 1.116, 1.116, 1… #\u0026gt; $ UrineVol2 \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ UrineFlow2 \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ Diabetes \u0026lt;fct\u0026gt; No, No, No, No, No, No, No, No, No, No, No, No, No, … #\u0026gt; $ DiabetesAge \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ HealthGen \u0026lt;fct\u0026gt; Good, Good, Good, NA, Good, NA, NA, Vgood, Vgood, Vg… #\u0026gt; $ DaysPhysHlthBad \u0026lt;int\u0026gt; 0, 0, 0, NA, 0, NA, NA, 0, 0, 0, 10, 0, 4, NA, NA, 0… #\u0026gt; $ DaysMentHlthBad \u0026lt;int\u0026gt; 15, 15, 15, NA, 10, NA, NA, 3, 3, 3, 0, 0, 0, NA, NA… #\u0026gt; $ LittleInterest \u0026lt;fct\u0026gt; Most, Most, Most, NA, Several, NA, NA, None, None, N… #\u0026gt; $ Depressed \u0026lt;fct\u0026gt; Several, Several, Several, NA, Several, NA, NA, None… #\u0026gt; $ nPregnancies \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, 1, 1, 1, NA, NA, NA, NA, … #\u0026gt; $ nBabies \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, N… #\u0026gt; $ Age1stBaby \u0026lt;int\u0026gt; NA, NA, NA, NA, 27, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ SleepHrsNight \u0026lt;int\u0026gt; 4, 4, 4, NA, 8, NA, NA, 8, 8, 8, 7, 5, 4, NA, 5, 7, … #\u0026gt; $ SleepTrouble \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, No, No, … #\u0026gt; $ PhysActive \u0026lt;fct\u0026gt; No, No, No, NA, No, NA, NA, Yes, Yes, Yes, Yes, Yes,… #\u0026gt; $ PhysActiveDays \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, 5, 5, 5, 7, 5, 1, NA, 2,… #\u0026gt; $ TVHrsDay \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ CompHrsDay \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ TVHrsDayChild \u0026lt;int\u0026gt; NA, NA, NA, 4, NA, 5, 1, NA, NA, NA, NA, NA, NA, 4, … #\u0026gt; $ CompHrsDayChild \u0026lt;int\u0026gt; NA, NA, NA, 1, NA, 0, 6, NA, NA, NA, NA, NA, NA, 3, … #\u0026gt; $ Alcohol12PlusYr \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, Yes, … #\u0026gt; $ AlcoholDay \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, 3, 3, 3, 1, 2, 6, NA, NA,… #\u0026gt; $ AlcoholYear \u0026lt;int\u0026gt; 0, 0, 0, NA, 20, NA, NA, 52, 52, 52, 100, 104, 364, … #\u0026gt; $ SmokeNow \u0026lt;fct\u0026gt; No, No, No, NA, Yes, NA, NA, NA, NA, NA, No, NA, NA,… #\u0026gt; $ Smoke100 \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, Yes, No,… #\u0026gt; $ Smoke100n \u0026lt;fct\u0026gt; Smoker, Smoker, Smoker, NA, Smoker, NA, NA, Non-Smok… #\u0026gt; $ SmokeAge \u0026lt;int\u0026gt; 18, 18, 18, NA, 38, NA, NA, NA, NA, NA, 13, NA, NA, … #\u0026gt; $ Marijuana \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, NA, Y… #\u0026gt; $ AgeFirstMarij \u0026lt;int\u0026gt; 17, 17, 17, NA, 18, NA, NA, 13, 13, 13, NA, 19, 15, … #\u0026gt; $ RegularMarij \u0026lt;fct\u0026gt; No, No, No, NA, No, NA, NA, No, No, No, NA, Yes, Yes… #\u0026gt; $ AgeRegMarij \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 20, 15, … #\u0026gt; $ HardDrugs \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, No, Yes,… #\u0026gt; $ SexEver \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, Yes, … #\u0026gt; $ SexAge \u0026lt;int\u0026gt; 16, 16, 16, NA, 12, NA, NA, 13, 13, 13, 17, 22, 12, … #\u0026gt; $ SexNumPartnLife \u0026lt;int\u0026gt; 8, 8, 8, NA, 10, NA, NA, 20, 20, 20, 15, 7, 100, NA,… #\u0026gt; $ SexNumPartYear \u0026lt;int\u0026gt; 1, 1, 1, NA, 1, NA, NA, 0, 0, 0, NA, 1, 1, NA, NA, 1… #\u0026gt; $ SameSex \u0026lt;fct\u0026gt; No, No, No, NA, Yes, NA, NA, Yes, Yes, Yes, No, No, … #\u0026gt; $ SexOrientation \u0026lt;fct\u0026gt; Heterosexual, Heterosexual, Heterosexual, NA, Hetero… #\u0026gt; $ PregnantNow \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …       Exercise 2  As you might know, blood pressure consists of two values - systolic and diastolic. Each participant in the NHANES survey had their blood pressure measured three times in succession, giving us the columns: BPSys1, BPDia1, BPSys2, BPDia2, BPSys3, BPDia3. Let\u0026rsquo;s work first with just the three systolic values.\nSubset the dataset to get just the columns BPSys1, BPSys2, and BPSys3. Name the new object \u0026lsquo;sys_values\u0026rsquo;, then get the dimensions of sys_values and preview it.\n  Hints (click here)  \nUse select() from dplyr to get the three columns we want. dim() and glimpse() can be used to get the dimensions and preview the data, respectively.    Solution (click here)  sys_values \u0026lt;- NHANES %\u0026gt;% select(matches(\"BPSys[123]$\")) #I used the 'matches' helper along with a regular expression  #above, but there are a number of ways you could do this.  #One equivalent would be... # sys_values \u0026lt;- NHANES %\u0026gt;% select(BPSys1, BPSys2, BPSys3) dim(sys_values) #\u0026gt; [1] 10000 3 head(sys_values) #\u0026gt; # A tibble: 6 x 3 #\u0026gt; BPSys1 BPSys2 BPSys3 #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 114 114 112 #\u0026gt; 2 114 114 112 #\u0026gt; 3 114 114 112 #\u0026gt; 4 NA NA NA #\u0026gt; 5 118 108 116 #\u0026gt; 6 84 84 88       Exercise 3  We can see just from the preview in Exercise 2 that the dataset has some missing data - let\u0026rsquo;s remove rows that have NA\u0026rsquo;s. Call the new dataset \u0026lsquo;sys_noNA\u0026rsquo;. Then check the dimensions and preview again.\n  Hints (click here)  \nTry the drop_na function from tidyr to eliminate rows containing missing data.    Solution (click here)  sys_noNA \u0026lt;- sys_values %\u0026gt;% drop_na() dim(sys_noNA) #\u0026gt; [1] 7971 3 head(sys_noNA) #\u0026gt; # A tibble: 6 x 3 #\u0026gt; BPSys1 BPSys2 BPSys3 #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 114 114 112 #\u0026gt; 2 114 114 112 #\u0026gt; 3 114 114 112 #\u0026gt; 4 118 108 116 #\u0026gt; 5 84 84 88 #\u0026gt; 6 114 108 106       Exercise 4  We\u0026rsquo;ll explore these data a bit to see if there\u0026rsquo;s any evidence of a trend in systolic blood pressure with respect to the sequence of measurements (differences among measurements 1, 2, and 3). First, lets reshape the data so we end up with just two columns named \u0026lsquo;measurement\u0026rsquo; and \u0026lsquo;sys_bp\u0026rsquo;. Save the new objects as \u0026lsquo;sys_long\u0026rsquo;. Then check the dimensions and preview again.\n  Hints (click here)  \nUse pivot_longer() to lengthen the dataset. You\u0026rsquo;ll need to include the arguments \u0026ldquo;cols\u0026rdquo;, \u0026ldquo;names_to\u0026rdquo;, and \u0026ldquo;values_to\u0026rdquo;.    Solution (click here)  sys_long \u0026lt;- sys_noNA %\u0026gt;% pivot_longer(cols = starts_with(\"BP\"), names_to = \"measurement\", values_to = \"sys_bp\") dim(sys_long) #\u0026gt; [1] 23913 2 head(sys_long) #\u0026gt; # A tibble: 6 x 2 #\u0026gt; measurement sys_bp #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 BPSys1 114 #\u0026gt; 2 BPSys2 114 #\u0026gt; 3 BPSys3 112 #\u0026gt; 4 BPSys1 114 #\u0026gt; 5 BPSys2 114 #\u0026gt; 6 BPSys3 112       Exercise 5  Now let\u0026rsquo;s calculate and compare the mean values for each measurement.\n  Hints (click here)  \nUse group_by() and summarize() to get a mean for each of the three measurements.    Solution (click here)  sys_long %\u0026gt;% group_by(measurement) %\u0026gt;% summarize(\"mean_sys\" = mean(sys_bp)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; measurement mean_sys #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 BPSys1 119. #\u0026gt; 2 BPSys2 118. #\u0026gt; 3 BPSys3 118.       Exercise 6  The summarise() functions outputs a tibble. Tibbles are intended to be tidy, and as part of that, by default the values they display tend to be truncated/rounded to a greater degree than they would be otherwise in R. In this case, we might want to see a bit more precision in the values. Try adjusting (increasing) the number of significant figures that are displayed in the tibble that was output in Exercise 5.\n  Hints (click here)  \nThis can be done in a couple different ways. One is to convert the tibble to a data frame with as.data.frame(), since data frames, by default, will likely show more significant digits. Alternatively, try setting options(pillar.sigfig) to a new value.    Solution (click here)  sys_long %\u0026gt;% group_by(measurement) %\u0026gt;% summarize(\"mean_sys\" = mean(sys_bp)) %\u0026gt;% as.data.frame() #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; measurement mean_sys #\u0026gt; 1 BPSys1 119.1682 #\u0026gt; 2 BPSys2 118.4333 #\u0026gt; 3 BPSys3 117.8479 #OR options(pillar.sigfig = 6) sys_long %\u0026gt;% group_by(measurement) %\u0026gt;% summarize(\"mean_sys\" = mean(sys_bp)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; measurement mean_sys #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 BPSys1 119.168 #\u0026gt; 2 BPSys2 118.433 #\u0026gt; 3 BPSys3 117.848       Bonus 1  Are those differences statistically significant? A one-way anova might be a good option to test that. Check out the help page for the function aov() and try running an ANOVA.\n  Hint 1 (click here)  \nR often uses the tilde (~) to indicate formula notation. So, for example, you can generate a scatterplot in base R by plotting y~x, assuming y and x are numeric vectors of equal lengths. The aov() function requires a formula with the pattern values~group. You can use the column names in the data frame to define these, but then you need to use the \u0026lsquo;data\u0026rsquo; argument to tell the function the name of the data frame where those columns exist.    Hint 2 (click here)  \nOnce you get the aov() function to work, you can get a p-value with the summary function. See info under the \u0026ldquo;Value\u0026rdquo; heading on the help page for aov().    Solution (click here)  aov(sys_bp~measurement, data = sys_long) %\u0026gt;% summary() #\u0026gt; Df Sum Sq Mean Sq F value Pr(\u0026gt;F)  #\u0026gt; measurement 2 6977 3489 11.87 7.05e-06 *** #\u0026gt; Residuals 23910 7028228 294  #\u0026gt; --- #\u0026gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1       Bonus 2  Repeat all of the above for diastolic blood pressure with a couple of modifications along the way. First, when you reshape/lengthen the data, make the values in the \u0026lsquo;measurement\u0026rsquo; column numeric. For example, in the sys_long data frame we created above, the values in the measurement column were characters, and looked like \u0026ldquo;BPsys1\u0026rdquo;. This time, make them a factor with the levels \u0026ldquo;1\u0026rdquo;, \u0026ldquo;2\u0026rdquo;, and \u0026ldquo;3\u0026rdquo;.\n  Hint (click here)  \nUse the pivot_longer() arguments \u0026ldquo;names_prefix\u0026rdquo; and \u0026ldquo;names_transform\u0026rdquo;.    Solution (click here)  dia_data \u0026lt;- NHANES %\u0026gt;% select(matches(\"BPDia[123]$\")) %\u0026gt;% drop_na() %\u0026gt;% pivot_longer(cols = starts_with(\"BP\"), names_to = \"measurement\", values_to = \"dia_bp\", names_prefix = \"BPDia\", names_transform = list(measurement = \"as.factor\")) head(dia_data) #\u0026gt; # A tibble: 6 x 2 #\u0026gt; measurement dia_bp #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 1 88 #\u0026gt; 2 2 88 #\u0026gt; 3 3 82 #\u0026gt; 4 1 88 #\u0026gt; 5 2 88 #\u0026gt; 6 3 82 dia_data %\u0026gt;% group_by(measurement) %\u0026gt;% summarize(\"mean_dia\" = mean(dia_bp)) %\u0026gt;% as.data.frame() #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; measurement mean_dia #\u0026gt; 1 1 68.28830 #\u0026gt; 2 2 67.46280 #\u0026gt; 3 3 67.06762 aov(dia_bp~measurement, data = dia_data) %\u0026gt;% summary() #\u0026gt; Df Sum Sq Mean Sq F value Pr(\u0026gt;F)  #\u0026gt; measurement 2 6185 3092.3 14.91 3.38e-07 *** #\u0026gt; Residuals 23910 4958916 207.4  #\u0026gt; --- #\u0026gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1       ","date":1612224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612457344,"objectID":"0ce28958d05d4030b2130203b1616eb7","permalink":"https://biodash.github.io/codeclub/08_pivoting/","publishdate":"2021-02-02T00:00:00Z","relpermalink":"/codeclub/08_pivoting/","section":"codeclub","summary":"In this session of Code Club, we'll consider the shape of our datasets and practice with the *tidyr* functions `pivot_longer()` and `pivot_wider()`, which allow us to reformat, or reshape our data - going from a longer form to a wider form, or vice versa.","tags":null,"title":"Session 8: Reshaping Your Data","type":"codeclub"},{"authors":["Jelmer Poelstra"],"categories":null,"content":"\n Introduction R Markdown consists of an amazing ecosystem of R packages to produce many types of technical content. Its signature capability is that is can run R code and print the code along with its results and nicely formatted prose.\nTo understand R Markdown, we need to learn about three new things:\n  Markdown, a very lightweight text formatting language.\n  Code chunks, which allow us to incorporate R code that can be executed and whose results we can display in text, figures, and tables.\n  The YAML header, which encodes metadata about the output, such as the desired output format and specific formatting features.\n  We\u0026rsquo;ll focus on HTML page output, but will glimpse at the many possibilities for the output format: with R Markdown, it is possible to create not just technical reports, but also slide decks, websites, books, scientific articles, and so on.\nSetup At the core of the R Markdown ecosystem is the rmarkdown package. We need to install this but don\u0026rsquo;t need to load it:\ninstall.packages(\"rmarkdown\")   Inside your directory for Code Club, create a directory for this week:\ndir.create('S07')   First, an example Before we go into details, let\u0026rsquo;s first see a quick demonstration of what we are talking about:\n  Go to File =\u0026gt; New File =\u0026gt; R Markdown, change the Title to \u0026ldquo;Markdown demo\u0026rdquo;, and click OK.\n  Take a look at the R Markdown document, and notice that there seems to be some sort of header (=\u0026gt; YAML), followed by R code wrapped in strange constructs with backticks (=\u0026gt; Code chunks), and plain written text (=\u0026gt; Markdown).\n  Before we can create output, we need to save the document. Click the Save button and save the files as demo.Rmd inside your newly created directory.\n  Now click the Knit button in one of the top bars, and a document should show up in a pop-up or the Viewer pane. This is the rendered output from the R Markdown document.\n  Notice that the YAML header is not printed, at least not verbatim, while some of the code is printed, and we also see code output including a plot!\nThis is what the raw and rendered output look side-by-side:\nWe\u0026rsquo;ll now talk about Markdown, code chunks, and the YAML header in turn.\n I: Markdown Markdown is a very lightweight language to format plain text files, which evolved from simple in-line formatting applied in emails before those started using HTML.\nNeed to emphasize a word without being able to make it italic or bold? How about adding emphasis with asterisks *like so*?\nAn overview of commonly used Markdown syntax    Syntax Result     # My Title Header level 1 (largest)   ## My Section Header level 2   ### My Subsection Header level 3 \u0026ndash; and so forth   *italic* or _italic_ italic   **bold** or __bold__ bold   [Markdown Guide](markdownguide.org) Markdown Guide (Link with custom text)   ![](path/to/figure.png) Figure   - List item Unordered (bulleted) list   1. List item Ordered (numbered) list   `inline code` inline code   ``` \u0026hellip;code\u0026hellip; ``` Generic code block (for formatting only) (Alternative syntax: 4 leading spaces.)   ```r \u0026hellip;code\u0026hellip; ``` r code block (for formatting only)   --- Horizontal rule (line)    To see this formatting in action, see below an example of a raw Markdown file on the left, and its rendered (formatted) output on the right:\n \u0026ldquo;Plain\u0026rdquo; Markdown files have the extension .md, whereas R Markdown files have the extension .Rmd.\n   II: Integrating R code As we saw above, plain Markdown has syntax for code formatting, but the code is not actually being executed. In R Markdown, however, we are able run code! The syntax to do so is only slightly modified from what we saw above:\n  For inline code, we add r and a space before the R code that is to be executed, for example:\n   Raw Rendered     There are `r 365*24` hours in a year There are 8760 hours in a year      To generate code blocks, which we call code chunks in an R Markdown context,\nwe add r inside curly braces: ```{r}\nWe can optionally add settings that we want to apply to that chunk and/or chunk labels:\n```{r, option1=value, ...} or ```{r, unique-chunk-label, option1=value, ...}\n RStudio keyboard shortcut to insert a code chunk: Cmd/Ctrl+Alt+I.\n    Code chunk examples   A code chunk with default options\u0026hellip;\n\u0026hellip;will be executed and shown followed by the output of the code:\nmean(penguins$bill_depth_mm, na.rm = TRUE) #\u0026gt; [1] 17.15117     As an example of using a code chunk option, we will disable printing the code using echo=FALSE (the code will still run and the output will still be shown):\n#\u0026gt; [1] 17.15117     Figures can, of course, also be printed:\nggplot(penguins) + geom_point(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + theme_bw() #\u0026gt; Warning: Removed 2 rows containing missing values (geom_point).  Fig. 1: Bill length and depth are correlated within species, and differ subtly between species.     Above, we added a caption for the figure using the fig.cap argument (with a little trick to force a line break, using the \u0026lt;br\u0026gt; HTML syntax).\n Code chunk options Here is an overview of some the most commonly made changes to defaults for code chunk options. This quickly gets confusing, but you\u0026rsquo;ll get the hang of it after experimenting a bit.\n echo=FALSE \u0026ndash; Don\u0026rsquo;t print the code in the output file. eval=FALSE \u0026ndash; Don\u0026rsquo;t run (evaluate) the code. include=FALSE \u0026ndash; Run but don\u0026rsquo;t print the code, nor any of its results. results=\u0026quot;hide\u0026quot; \u0026ndash; Don\u0026rsquo;t print the text output of the code. fig.show=\u0026quot;hide\u0026quot; \u0026ndash; Don\u0026rsquo;t print figures produced by the code.  Furthermore, you can use message=FALSE and warning=FALSE to suppress any messages (like the output when loading packages) and warnings (like the warning for the penguin figure above), respectively, that R might produce.\nFor figures, the following options are especially useful:\n fig.cap=\u0026quot;My caption\u0026quot; \u0026ndash; Include a caption. fig.asp=0.6 \u0026ndash; Aspect ratio. fig.width=6 \u0026ndash; Width of in inches: same as sizing in regular R code. fig.height=9.6 \u0026ndash; Height in inches: same as sizing in regular R code. out.width=\u0026quot;70%\u0026quot; \u0026ndash; Figure width as printed in the document (in % or pixels, px). out.height=\u0026quot;500px\u0026quot; \u0026ndash; Figure height as printed in the document.  Finally, if your document takes a long time to knit, use cache=TRUE to enable caching of results.\n   Default chunk options It is often practical to set default chunk options for the entire document, and you can do so with the opts_chunk$set() function as shown below:\nThis is usually done in separate \u0026ldquo;global setup chunk\u0026rdquo; at the start of the document.\nWhenever necessary, you can then override these defaults for specific chunks.\n   III: The YAML header YAML (\u0026ldquo;YAML Ain\u0026rsquo;t Markup Language\u0026rdquo;) is a simple format commonly used for configuration files, which allows you to provide key-value pairs such as author: John Doe.\nIn R Markdown files, it is used as a header which configures certain aspects of the output, especially the formatting. Put another way, the YAML header contains the metadata for the output.\nA basic YAML header Here is an example of a very basic YAML header:\n--- author: My name title: The document's title output: html_document ---  Note the lines which just contain three dashes, which mark the beginning and the end of the YAML header.\nAdding options Often, a value (like html_document) can itself be given key-value pairs to specify additional options \u0026ndash; see the example below where we include a Table of Contents (toc) and also set it to \u0026ldquo;float\u0026rdquo;:\n--- output: html_document: toc: true toc_float: true ---    Note the syntax changes (newlines and added indentation) between the above two examples, this is perhaps a little awkward and often leads to mistakes.\n  Indentation in YAML is using two or four spaces (no tabs!) per indentation level, and it is sensitive to indentation errors. (Fortunately, RStudio inserts spaces for tabs by default \u0026ndash; check/set in Tools =\u0026gt; Global Options =\u0026gt; Code =\u0026gt; Editing.)\n   Some options for html_document output html_document is the most commonly used output format for R Markdown documents, and here are few particularly useful options to customize the output:\n code_download: true \u0026ndash; Include a button to download the code. code_folding: hide \u0026ndash; Using hide or show will enable the folding of code chunks, with hide hiding them by default. toc: true \u0026ndash; Include a table of contents (Also: toc_depth: 3 sets depth to 3, toc_float: true lets the TOC \u0026ldquo;float\u0026rdquo; as you scroll down the document). number_sections: true \u0026ndash; Number the section headings. df_print: paged \u0026ndash; Get nicely formatted and paged data frame printing (also try: df_print: kable). theme: cerulean \u0026ndash; Use a pre-built theme, controlling the overall look and feel of the document. See here for a visual overview.    Three HTML document theme options: darkly, flatly, and cerulean.      IV: R Markdown and RStudio The RMarkdown ecosystem of packages is being developed by RStudio, so it should come as no surprise that the RStudio IDE has some nice RMarkdown functionality.\nKnitting and previewing your document The process of rendering an R Markdown file into another format, as specified by the YAML header, is called knitting. We already saw the button to knit the current document (keyboard shortcut: Cmd/Ctrl+Shift+K).\n If you get preview pop-up windows in RStudio, click the cog wheel icon next to the Knit button, and then select \u0026ldquo;Preview in Viewer Pane\u0026rdquo;.\n  Instead of knitting the entire document, you can also run individual code chunks using the green \u0026ldquo;play button\u0026rdquo; (or Cmd/Ctrl+Shift+Enter), or all code chunks up until the current one (button to the left of the play button).\nFor a live preview (!) of R Markdown output for your active document,\nuse the infinite moon reader from the xaringan package:\ninstall.packages(\"xaringan\") # Simply running the function without arguments will start the preview: xaringan::inf_mr() # To shut down the preview server, if needed, run `servr::daemon_stop()`   Visual Markdown Editor If your RStudio version is at least 1.4 (Click Help =\u0026gt; About RStudio), which was released last fall, you can also use the Visual Markdown Editor.\nThis makes writing in R Markdown almost like using a word processor, and also includes many other features such as better citation support with Zotero integration. Read more about the visual editor here.\nTo switch between the visual editor and regular (\u0026ldquo;source\u0026rdquo;) editing mode, click the A-shaped ruler button in the top-right corner or press Cmd/Ctrl+Shift+F4.\nThis is what our document looks like in the visual editor \u0026ndash; kind of intermediate between the raw R Markdown and the rendered output:\n V: A single source doc, many output formats! One of the greatest features of R Markdown is that you can output to many formats. So from one source document, or very similar variants, you can create completely different output depending on what you need.\nBuilt-in output formats The built-in output formats, which can be used with just the rmarkdown package, are listed below. These include HTML, PDF, Word, PowerPoint, and different HTML slide show formats!\nExtension output formats It\u0026rsquo;s worth highlighting a few of the output formats that can be used with the following packages in the R Markdown ecosystem:\n  distill \u0026ndash; An output format geared towards technical content, e.g. with extended support for equations, citations, and footnotes. Can also create websites.\n  rticles \u0026ndash; R Markdown templates to format output for specific scientific journals.\n  flexdashboard \u0026ndash; Create interactive \u0026ldquo;dashboards\u0026rdquo; to present data.\n  bookdown \u0026ndash; A book format, the R Markdown book is an example.\n  xaringan \u0026ndash; Create fancier presentation slides thanks to a JavaScript library.\n  Starting to use these and other output formats is often as simple as changing the YAML header:\n---output:distill::distill_article---\n Breakout rooms! In the exercises, we will work with an .Rmd file that you can download as follows:\n# dir.create(\"S07\") # You should have already done this # Save the URL for the Rmd file: todays_rmd \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/07_rmarkdown/penguins.Rmd' # Download the Rmd file: download.file(url = todays_rmd, destfile = 'S07/penguins.Rmd')   Next, open the document in RStudio, and fire up the infinite moon reader:\n# install.packages(\"xaringan\") xaringan::inf_mr()   This way, you will be able to nearly instantaneously see the effect of your changes: save the document whenever you want the server to update.\nYou can use either the \u0026ldquo;visual editor\u0026rdquo; or the regular (\u0026ldquo;source\u0026rdquo;) editor \u0026ndash; and you could also start by compating the two.\n Exercise 1: Output formatting with YAML In this exercise, you will fiddle with the YAML header to modify aspects of the html_document output format:\n  Add a theme key to html_output, and try a few of the available value options (\u0026quot;default\u0026quot;, \u0026ldquo;cerulean\u0026rdquo;, \u0026ldquo;journal\u0026rdquo;, \u0026ldquo;flatly\u0026rdquo;, \u0026ldquo;darkly\u0026rdquo;, \u0026ldquo;readable\u0026rdquo;, \u0026ldquo;spacelab\u0026rdquo;, \u0026ldquo;united\u0026rdquo;, \u0026ldquo;cosmo\u0026rdquo;, \u0026ldquo;lumen\u0026rdquo;, \u0026ldquo;paper\u0026rdquo;, \u0026ldquo;sandstone\u0026rdquo;, \u0026ldquo;simplex\u0026rdquo;, \u0026ldquo;yeti\u0026quot;).\nDetermine, once and for all, what the best theme is.\n  Try some of the other options mentioned above (code_download, code_folding, toc, toc_float, toc_depth, df_print), and look at the effects on the rendered output.\n    Hints (click here)     To add options to html_document in the YAML header, you\u0026rsquo;ll need to go from output: html_document on a single line, to a multi-line format with indentation, and with a colon added after html_document:\noutput:html_document:\u0026lt;option\u0026gt;     Solutions (click here)   An example YAML header with several options added:  ---title:\u0026#34;Penguins, demystified.\u0026#34;author:\u0026#34;Jelmer Poelstra\u0026#34;date:\u0026#34;1/29/2021\u0026#34;output:html_document:theme:flatlytoc:truetoc_float:truetoc_depth:5number_sections:truecode_download:truecode_folding:hidedf_print:kable---\n    Exercise 2: Code chunks Our output document looks nice, but there is plenty of room for improvement. In this exercise, we\u0026rsquo;ll refine the output using code chunk options.\nBefore you start, take another look at the box Code chunk options above.\n  Did you notice those messages (when the tidyverse is loaded) and warnings (for the two plots) in the output? Let\u0026rsquo;s get rid of those all at once: suppress R messages and warnings for all chunks by adding arguments to the knitr::opts_chunk$set() function in the first code chunk.\n  Currently, the code line in the install-package code chunk is commented out to avoid the code from running, while still printing it. Try to accomplish this using a code chunk option instead, so you can uncomment the line.\n  We do want to print the code in some cases, but not in others. For the chunk labeled print-tibble, which prints penguins, alter the settings such that the code is no longer printed.\n  Our first figure is kind of squished, and the point and font sizes are perhaps too large. Compare this with the second figure, which has a different setting only for out.width.\nPlay around with the values for the three options that are already in the code chunks (fig.width, out.width, and fig.asp), for one or both figures, see what the effects are, and try to make some improvements.\nDo you understand the difference between the two methods to indicate the figure size (fig.width and out.width)?\n  Insert a new code chunk that prints the penguins_raw tibble in some way (this is available in your environment).\n    Hints (click here)     To suppress messages and warnings throughout:\nAdd message=FALSE and warnings=FALSE inside knitr::opts_chunk$set() in the setup chunk.\n  To avoid running the code:\nUse eval=FALSE in the header of the install-package code chunk.\n  To avoid printing the code:\nUse the echo option in the header of the print-tibble code chunk.\n  Figure sizing:\nThere are two types of sizes that you can set: the size at which R creates figures (fig.width and fig.height), and the size at which the figures are inserted in the document (out.width and out.height). The former will effectively only control relative font and point sizes, whereas the latter controls the \u0026ldquo;actual\u0026rdquo; / final size. For more details and advice, see this section in R for Data Science.\nThe aspect ratio (fig.asp) is height/width, so a value smaller than one creates a wide figure and a value larger than one creates a narrow figure.\nHere, we\u0026rsquo;ve been setting width only \u0026ndash; you can also set fig.height and out.height, but these options become redundant when you set the width and the aspect ratio.\n     Solutions (click here)    To suppress messages and warnings throughout:\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n  To avoid running the code: {r install-package, eval=FALSE}\n  To avoid printing the code:\n{r print-tibble, echo=FALSE}\n  Figure sizing:\nExample settings for better-sized figures \u0026ndash;\n{r plot-bills, out.width=\u0026quot;80%\u0026quot;, fig.width=6, fig.asp=0.7}\n  A code chunk to print the penguins_raw tibble (replace single quotes by backticks):\n  '''{r} penguins_raw '''      Bonus 1: Markdown and inline code The formatting for the prose in our document could also be improved. For instance:\n  Use inline code formatting in a couple of cases where this is appropriate.\n  Instead of simply saying \u0026ldquo;8 variables (n = 344 penguins)\u0026rdquo; (under the Summary of the dataset\u0026quot; heading), use inline R code that makes these calculations and print the results.\n  Try a couple of other things: heading levels (one of them is currently not right!), italic text, bold text, and/or ordered (numbered) and unordered (bulleted) lists.\n    Hints (click here)     Simply put backticks around the inline text you want have formatted as code. You can do this, for instance, for mentions of palmerpenguins::penguins.\n  For inline code that runs, use `r my-code`.\nThe number of variables and penguins in the penguin dataset are the number of columns and rows, respectively, in the penguin tibble.\n     Solutions (click here)  Inline calculation of the number of variables and penguins:\n[...] that contains `r ncol(penguins)` variables (n = `r nrow(penguins)` penguins).      Bonus 2: Other output formats Try one or more output formats other than html_document, see this website for the list of available options. If you want to try presentations, note that three dashes --- are used to separate slides.\n It might be confusing that on the website linked to above (see also the screenshot in section V), the output formats are listed functions (html_document() rather than html_document) \u0026ndash; but this is simply because under the hood, these functions are called via the YAML header.\n    \n Go further Pitfalls / Tips   The working directory\nBy default, the working directory for an R Markdown document is the directory in which the file resides.\nThis can be a bit annoying if you\u0026rsquo;re used to using your project\u0026rsquo;s root directory as your working directory (which you should be) and the R Markdown file is not in the project\u0026rsquo;s root directory (which it probably shouldn\u0026rsquo;t be). Nevertheless, simply using ../ notation to move one or two directories up should generally work.\nIf you really need to set a different working directory, you should be aware that surprisingly, setting the working directory with setwd() in a code chunk is not persistent across code chunks. To set a different working directory for the entire document, use knitr::opts_knit$set(root.dir = '/my/working/dir') in a setup chunk.\n  Chunk labels\nChunk labels are optional but if you do give them, note that they have to be unique: the document will fail to render if have two chunks with the same label. Also, avoid using spaces and underscores in the labels (good-chunk-label, bad chunk label, bad_chunk_label).\n  Tables   Tables produced by Markdown text\nThe syntax for basic Markdown tables is as follows:\n| Time | Session | Topic | |:--------------|:-------:|---------:| | _left_ | _center_| _right_ | | Wed 5 pm | 1 | Getting started | | Fri 3 pm | | | | Wed 5 pm | 2 | *dplyr* | | Fri 3 pm | | *Break* |     Time Session Topic     left center right   Wed 5 pm 1 Getting started   Fri 3 pm     Wed 5 pm 2 dplyr   Fri 3 pm  Break    In the Visual Markdown editor in RStudio, you can simply insert a table with a little dialogue box after clicking Table =\u0026gt; Insert Table.\n  Tables (dataframes) produced by R code\nUsing kable(my_df) in a code chunk will create nicer output for individual dataframes (recall the df_print: kable YAML option for document-wide \u0026ldquo;kable\u0026rdquo; printing).\nThere are many packages available for more advanced options, such as GT, DT, and reactable.\n  Websites Note that rmarkdown::render_site() can create simple websites that connects multiple pages with a navigation bar. All you need is a simple YAML file called _site.yml with some settings, and a file for the front page which needs to be called index.Rmd. See here in the R Markdown book for more details.\nOptions with more features, like a blog, are distill websites, and the blogdown package for Hugo sites.\nFurther resources  Free online books by the primary creator of R Markdown and other authors:  R Markdown \u0026ndash; The Definitive Guide R Markdown Cookbook   RStudio\u0026rsquo;s 5-page R Markdown Reference PDF RStudio\u0026rsquo;s R Markdown Cheatsheet RStudio R Markdown lessons Markdown tutorial  ","date":1611446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611941749,"objectID":"c2268ec4049a3a40fece1f72853db533","permalink":"https://biodash.github.io/codeclub/07_rmarkdown/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/codeclub/07_rmarkdown/","section":"codeclub","summary":"In this 7th session of Code Club, we will learn about Markdown syntax and some of the great functionality of R Markdown.","tags":["codeclub","markdown","rmarkdown"],"title":"Session 7: R Markdown","type":"codeclub"},{"authors":["Stephen Opiyo"],"categories":null,"content":"\n Factors form the basis for many powerful operations in R, including many performed on tabular data. The motivation for factors comes from the notion of categorical variables. These variables are non-numeric in nature corresponding to categories such as male and female, or Democrat, Republican and Independent.\nA factor might be viewed simply as a vector with a bit of more information added. The extra information consists of a record of distinct values in that vector, which are called: levels.\nLet us look at some examples of factors. We will make use of the package forcats, which is one of the 8 core tidyverse packages. Therefore, we start by loading the tidyverse:\nlibrary(tidyverse) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.3 ✔ purrr  0.3.4 #\u0026gt; ✔ tibble  3.0.4 ✔ dplyr  1.0.2 #\u0026gt; ✔ tidyr  1.1.2 ✔ stringr 1.4.0 #\u0026gt; ✔ readr  1.4.0 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag() ## Check whether \"forcats\" is listed among the loaded packages. ## Alternatively, you could load \"forcats\" (and \"ggplot2\") separately: # install.packages(\"forcats\") # library(forcats) # library(ggplot2)    Example 1: From a numeric vector to a factor Let us create a factor xf from a vector x with the numbers 5, 12, 13, and 12:\nx \u0026lt;- c(5,12, 13,12) x #\u0026gt; [1] 5 12 13 12 # Convert the vector to a factor: xf \u0026lt;- factor(x) xf #\u0026gt; [1] 5 12 13 12 #\u0026gt; Levels: 5 12 13   The distinct values in xf are 5, 12 and 13, and are listed as levels.\nLet us look in a bit more details at our factor using the R functions str and unclass:\nstr(xf) #\u0026gt; Factor w/ 3 levels \"5\",\"12\",\"13\": 1 2 3 2 unclass(xf) #\u0026gt; [1] 1 2 3 2 #\u0026gt; attr(,\"levels\") #\u0026gt; [1] \"5\" \"12\" \"13\"   Notice that the values in the factor are not stored as (5, 12, 13, 12), but rather as (1, 2, 3, 2)!\nThis means that our data consists first of a level-1 value, then level-2 and level 3 values, and finally another level-2 value. So, the data has been recorded by level.\nThe values attached to each level are recorded too, but as characters such as \u0026quot;5\u0026quot; rather than as numbers such as 5.\n Example 2: From a character vector to a factor We will use the levels Democrat (D), Republican (R), and Independent (I). First, we save a vector:\ny \u0026lt;- c(\"D\", \"R\", \"R\", \"I\", \"R\", \"I\", \"D\", \"I\") y #\u0026gt; [1] \"D\" \"R\" \"R\" \"I\" \"R\" \"I\" \"D\" \"I\" str(y) #\u0026gt; chr [1:8] \"D\" \"R\" \"R\" \"I\" \"R\" \"I\" \"D\" \"I\"   Then, we again convert the vector to a factor, and look at the levels:\nfy \u0026lt;- factor(y) fy #\u0026gt; [1] D R R I R I D I #\u0026gt; Levels: D I R unclass(fy) #\u0026gt; [1] 1 3 3 2 3 2 1 2 #\u0026gt; attr(,\"levels\") #\u0026gt; [1] \"D\" \"I\" \"R\"    Example 3: Ordering factor levels Some variables can be challenging to sort automatically, because the desired sorting order is not alphabetical or numeric.\nFor instance, months that are listed using characters:\nmonths_vector \u0026lt;- c(\"Dec\", \"Apr\", \"Jan\", \"Mar\") # Try to sort using the `sort` function sort(months_vector) #\u0026gt; [1] \"Apr\" \"Dec\" \"Jan\" \"Mar\"   That didn\u0026rsquo;t sort in a useful way. But, the problem can be fixed by using a factor.\nFirst, we create a list of the valid levels, which are all 12 months in a year:\nmonth_levels \u0026lt;- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")   Then we convert the vector into a factor, like before, but now we additionally specify the desired levels of the factor, in order, using the levels argument:\nmonths_factor \u0026lt;- factor(months_vector, levels = month_levels)   Now it sorts the way we want to!\nsort(months_factor) #\u0026gt; [1] Jan Mar Apr Dec #\u0026gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec    Example 4: Use of factors in plots with forcats 4A: Plot after reordering manually with fct_relevel() We will use the mtcars data, which was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973\u0026ndash;74 models) \u0026ndash; a data frame with 32 observations for 11 (numeric) variables,\ndata(mtcars) names(mtcars) #\u0026gt; [1] \"mpg\" \"cyl\" \"disp\" \"hp\" \"drat\" \"wt\" \"qsec\" \"vs\" \"am\" \"gear\" #\u0026gt; [11] \"carb\" dim(mtcars) #\u0026gt; [1] 32 11 str(mtcars) #\u0026gt; 'data.frame': 32 obs. of 11 variables: #\u0026gt; $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... #\u0026gt; $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... #\u0026gt; $ disp: num 160 160 108 258 360 ... #\u0026gt; $ hp : num 110 110 93 110 175 105 245 62 95 123 ... #\u0026gt; $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... #\u0026gt; $ wt : num 2.62 2.88 2.32 3.21 3.44 ... #\u0026gt; $ qsec: num 16.5 17 18.6 19.4 17 ... #\u0026gt; $ vs : num 0 0 1 1 0 1 0 1 1 1 ... #\u0026gt; $ am : num 1 1 1 0 0 0 0 0 0 0 ... #\u0026gt; $ gear: num 4 4 4 3 3 3 3 4 4 4 ... #\u0026gt; $ carb: num 4 4 1 1 2 1 4 2 2 4 ...   we will select six variables (mpg, cyl, disp, hp, and wt) to create a dataset Data.\n mpg: Miles per (US) gallon, cyl: Number of cylinders disp: Displacement (cu.in.) hp: Horse power wt: Weight (in 1000 lbs)  Data \u0026lt;- mtcars %\u0026gt;% select(\"mpg\", \"cyl\", \"disp\", \"hp\", \"wt\")   Now, we\u0026rsquo;ll add a new column cyl_chr by converting cyl from numeric to character:\nData \u0026lt;- Data %\u0026gt;% mutate(cyl_chr = recode(cyl,`4` = \"Four\", `6` = \"Six\", `8` = \"Eight\")) head(Data) #\u0026gt; mpg cyl disp hp wt cyl_chr #\u0026gt; 1 21.0 6 160 110 2.620 Six #\u0026gt; 2 21.0 6 160 110 2.875 Six #\u0026gt; 3 22.8 4 108 93 2.320 Four #\u0026gt; 4 21.4 6 258 110 3.215 Six #\u0026gt; 5 18.7 8 360 175 3.440 Eight #\u0026gt; 6 18.1 6 225 105 3.460 Six   We plot a bar chart for cyl_chr:\nData %\u0026gt;% ggplot(aes(x = cyl_chr)) + geom_bar()   In the plot, the levels of the factor were arranged in alphabetical order (Eight, Four, and Six).\nInstead, we want the bar graph arranged in the order Four, Six, and Eight.\nAn alternative to using factor(levels = ...) like we did above, is to use the fct_relevel() function from the forcats package:\nData %\u0026gt;% mutate(cyl_chr = fct_relevel(cyl_chr, \"Four\", \"Six\", \"Eight\")) %\u0026gt;% ggplot(aes(x = cyl_chr)) + geom_bar() + labs(x = \"Cylinder\", y = \"Number of cars\")   4B: Plot after reordering by the value of another column (fct_reorder) Create a dataset called Data_a:\nData_a \u0026lt;- data.frame(name = c(\"North\", \"South\", \"East\", \"West\"), var = sample(seq(1, 10), 4))   Plot a bar chart of Data_a:\nData_a %\u0026gt;% ggplot(aes(x = name, y = var)) + geom_bar(stat = \"identity\", fill = \"#f68034\", alpha = 0.6, width = 0.4)   Reorder following the value of another column using the fct_reorder() function, and flip the plot:\nData_a %\u0026gt;% mutate(name = fct_reorder(name, var)) %\u0026gt;% ggplot(aes(x = name, y = var)) + geom_bar(stat = \"identity\", fill = \"#f68034\", alpha = 0.6, width = 0.4) + coord_flip()   There are several more convenient reordering functions in the forcats package, including:\n  fact_infreq() to reorder by occurrence frequencies of each level (see the picture at the top of the post).\n  fct_inorder() to reorder by order of appearance in the dataframe. This can be useful, for example, if your dataframe has already been sorted properly, and you just need to prevent automatic alphabetic reordering when plotting.\n   Breakout rooms! For the Breakout room exercises, we will use datasets from mtcars and the gss_cat dataset from the forcats package.\nExercise 1  Convert the variable gear from mtcars to a character vector with words for each number (link in example 4A), and plot a bar chart.\nThen, use a factor to reorder the bars to appear in the regular \u0026ldquo;numeric\u0026rdquo; order: \u0026ldquo;Three\u0026rdquo; then \u0026ldquo;Four\u0026rdquo; then \u0026ldquo;Five\u0026rdquo;.\n  Hints (click here)     First, create a dataframe with a column that codes the gears as words, using the mutate() and recode() functions.\n  Then, create a factor from this modified gear column, and order it manually using the fct_relevel() function.\n     Solutions (click here)   Start by loading the dataset:  data(\"mtcars\")    Now, create a new dataset Gear from mtcars, adding a column gear_chr:  gear_df \u0026lt;- mtcars %\u0026gt;% mutate(gear_chr = recode(gear, `3`= \"Three\", `4` =\"Four\", `5`= \"Five\")) head(gear_df) #\u0026gt; mpg cyl disp hp drat wt qsec vs am gear carb gear_chr #\u0026gt; 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Four #\u0026gt; 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Four #\u0026gt; 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Four #\u0026gt; 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Three #\u0026gt; 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Three #\u0026gt; 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Three    Finally, use the forcats function fct_relevel() to rearrange gear_chr in nonalphabetical order, and plot the barchart using geom_bar():  gear_df %\u0026gt;% mutate(gear_fct = fct_relevel(gear_chr, \"Three\", \"Four\", \"Five\")) %\u0026gt;% ggplot(aes(x = gear_fct)) + geom_bar() + labs(x = \"Gear\", y = \"Number of cars\")       Exercise 2  Using the gss_cat dataset from the forcats package (available as gsscat in your environment), create a plot that compares the average number of hours spent watching TV per day across religions, and where religions are ordered by the average number of hours.\n(Despite what we\u0026rsquo;ve learned last week, start by merely plotting the mean, and no distributions, using a barplot or with geom_point().)\nSource: (R for Data Science)\n  Hints (click here)  In order to be able to order the factor by the average number of hours spent watching TV, first compute this average per religion, and save the results in a dataframe (use `mutate()` and `summarize()`). Then, use fct_recorder() to reorder the factor.\n   Solutions (click here)  First, have a look at the dataset:\nforcats::gss_cat #\u0026gt; # A tibble: 21,483 x 9 #\u0026gt; year marital age race rincome partyid relig denom tvhours #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 2000 Never ma… 26 White $8000 to … Ind,near r… Protesta… Souther… 12 #\u0026gt; 2 2000 Divorced 48 White $8000 to … Not str re… Protesta… Baptist… NA #\u0026gt; 3 2000 Widowed 67 White Not appli… Independent Protesta… No deno… 2 #\u0026gt; 4 2000 Never ma… 39 White Not appli… Ind,near r… Orthodox… Not app… 4 #\u0026gt; 5 2000 Divorced 25 White Not appli… Not str de… None Not app… 1 #\u0026gt; 6 2000 Married 25 White $20000 - … Strong dem… Protesta… Souther… NA #\u0026gt; 7 2000 Never ma… 36 White $25000 or… Not str re… Christian Not app… 3 #\u0026gt; 8 2000 Divorced 44 White $7000 to … Ind,near d… Protesta… Luthera… NA #\u0026gt; 9 2000 Married 44 White $25000 or… Not str de… Protesta… Other 0 #\u0026gt; 10 2000 Married 47 White $25000 or… Strong rep… Protesta… Souther… 3 #\u0026gt; # … with 21,473 more rows   Then, calculate the mean number of tv-hours and create a plot:\nrelig \u0026lt;- gss_cat %\u0026gt;% group_by(relig) %\u0026gt;% summarize(tvhours = mean(tvhours, na.rm = TRUE)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) ggplot(relig, aes(tvhours, relig)) + geom_point()   It is difficult to interpret this plot because there is no overall pattern.\nWe can improve the plot by reordering the level of religion using fct_reorder():\nrelig \u0026lt;- gss_cat %\u0026gt;% group_by(relig) %\u0026gt;% summarize(tvhours = mean(tvhours, na.rm = TRUE)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) relig %\u0026gt;% mutate(relig = fct_reorder(relig, tvhours)) %\u0026gt;% ggplot(aes(tvhours, relig)) + geom_point()   Reordering religion makes it much easier to see that people in the \u0026ldquo;Don\u0026rsquo;t know\u0026rdquo; category watch much more TV.\n    Bonus: Exercise 3  In exercise 2, we saw large differences in the average time spent watching TV across religions, but we should perhaps have a closer look at the data by plotting distributions.\nGo back to the previous Code Club session and decide which type of plot could be ideal with so many categories.\n  Hints (click here)  [`geom_density_ridges()`](https://wilkelab.org/ggridges/reference/geom_density_ridges.html) from the *ggridges* package is very well suited for a plot with so many categories.    Solutions (click here)  library(ggridges) ggplot(gss_cat, aes(x = tvhours, y = relig, fill = relig)) + geom_density_ridges(alpha = 0.8) + labs(x = 'Number of hours spent watching TV', y = 'Religion') + guides(fill = FALSE) + theme_minimal() #\u0026gt; Picking joint bandwidth of 0.586 #\u0026gt; Warning: Removed 10146 rows containing non-finite values (stat_density_ridges).      ","date":1610928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611345251,"objectID":"a8e91bcb80337e5e587f785ed259f392","permalink":"https://biodash.github.io/codeclub/06_factors/","publishdate":"2021-01-18T00:00:00Z","relpermalink":"/codeclub/06_factors/","section":"codeclub","summary":"In this sixth session of Code Club, we'll learn how to use factors to our advantage","tags":["codeclub","factors"],"title":"Session 6: Factors","type":"codeclub"},{"authors":["Jessica Cooperstone"],"categories":null,"content":"\n Prep homework Basic computer setup   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n  New to ggplot? Check out the last Code Club Session 4 on Visualizing Data.\nIf you\u0026rsquo;ve never used ggplot2 before (or even if you have), you may find this cheat sheet useful.\n Getting Started Script for today\u0026rsquo;s session # directory for Code Club Session 2: dir.create(\"S05\") # directory for our script # (\"recursive\" to create two levels at once.) dir.create(\"S05/scripts/\") # save the url location for today's script todays_R_script \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/05_ggplot-round-2/Session5_ggplot2.R' # indicate the name of the new script file Session5_script \u0026lt;- \"S05/scripts/Session5_script.R\" # go get that file!  download.file(url = todays_R_script, destfile = Session5_script)    1 - Why visualize our data? Artwork by Allison Horst\nWe make data visualizations for two main reasons:\n To explore our data To share our data with others  Often, we think about figure generation as the last part of the scientic process, something you do as you prepare a manuscript for publication. I hope to convince you that exploring your data, and making exploratory plots is a critical part of the data analysis and interpretation process.\nToday we will be using ggplot2 to make a series of plots that help us better understand the underlying structure in our dataset.\nWhen summary statistics don\u0026rsquo;t cut it\nThis \u0026ldquo;Datasaurus Dozen\u0026rdquo; shows the value of looking at your data beyond means and standard deviations. In the gif above, created by Alberto Cairo, each of these 13 datasets have identical means, standard eviations, and correlations to two decimal places. And one of the datasets is a dinosaur!\n What will we go over today\nThese geoms will help you to get better acquainted with your data.\n geom_col() - makes bar plots. I will show you how to do this and then recommend that you don\u0026rsquo;t. geom_boxplot() - makes infinitely useful boxplots. geom_violin() - makes violin plots, a hybrid between a boxplot and a density plot. Very musical. geom_density_ridges() - a density plot giving you the impression of a side view of a mountain range. Requires the package ggridges geom_jitter() - adds all datapoints to your plot, and jitters them to handle overplotting.  I will also go over a few tricks along the way, including coord_flip(), adding labels using labs(), and changing the overall look of the plot with theme(), or pre-set themes like theme_classic() which is my go-to.\n   2 - Accessing our data Let\u0026rsquo;s get set up and grab some data so that we can learn more about penguins (and ggplot2)\n You can do this locally, or at OSC. You can find instructions if you are having trouble here.  First load your libraries.\nlibrary(tidyverse)   Then let\u0026rsquo;s access the wintry palmerpenguins dataset. We will then look at penguins, the dataset we will be using for the first part of today\u0026rsquo;s Code Club. This data is collected on penguins from the Palmer Station Antarctica Long-Term Ecological Research study area.\nArtwork by Allison Horst\ninstall.packages(\"palmerpenguins\")   library(palmerpenguins)   Let\u0026rsquo;s look at the data in penguins.\n# look at the first 6 rows, all columns head(penguins) #\u0026gt; # A tibble: 6 x 8 #\u0026gt; species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex  #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; #\u0026gt; 1 Adelie Torge… 39.1 18.7 181 3750 male  #\u0026gt; 2 Adelie Torge… 39.5 17.4 186 3800 fema… #\u0026gt; 3 Adelie Torge… 40.3 18 195 3250 fema… #\u0026gt; 4 Adelie Torge… NA NA NA NA NA  #\u0026gt; 5 Adelie Torge… 36.7 19.3 193 3450 fema… #\u0026gt; 6 Adelie Torge… 39.3 20.6 190 3650 male  #\u0026gt; # … with 1 more variable: year \u0026lt;int\u0026gt; # check the structure # this tell us what is contained within our df glimpse(penguins) #\u0026gt; Rows: 344 #\u0026gt; Columns: 8 #\u0026gt; $ species \u0026lt;fct\u0026gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ade… #\u0026gt; $ island \u0026lt;fct\u0026gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgers… #\u0026gt; $ bill_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1,… #\u0026gt; $ bill_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1,… #\u0026gt; $ flipper_length_mm \u0026lt;int\u0026gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 18… #\u0026gt; $ body_mass_g \u0026lt;int\u0026gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475,… #\u0026gt; $ sex \u0026lt;fct\u0026gt; male, female, female, NA, female, male, female, mal… #\u0026gt; $ year \u0026lt;int\u0026gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 200…   This dataset contains the following measurements about penguins at Palmer Station in Antarctica:\n species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year  We are going to be plotting to get an understanding of bill_length_mm which is the length of the bill from the penguins face, protruding outwards (and more easily understood in the image below).\nArtwork by Allison Horst\n 3 - Removing NAs Sometimes you will have NAs (or missing data). That might be informative to you, but here we are going to remove missing data using drop_na(), and assign it to a new dataframe called penguins_noNA.\n# check dimensions of penguins dim(penguins) #\u0026gt; [1] 344 8 # remove NAs penguins_noNA \u0026lt;- penguins %\u0026gt;% drop_na() dim(penguins_noNA) # we have removed 11 observations #\u0026gt; [1] 333 8   Note - by removing NAs, we have gotten rid of 11 observations\n 4 - Bar charts with geom_col() and stat_summary() Often, people use bar charts, representing the height or the length of the bar as proportional to the average value that it represents. These charts are sometimes called dynamite plots because they resemble (when they have an error bar with whisker) those cartoon style dynamite sticks. Pow!\nHowever, these bar charts, even if you add a standard deviation/error, really can hide the true distribution of your data, and for this reason, I and others hope you don\u0026rsquo;t select to make them.\nI hope after today, you see that there is always a better chart type to make than a bar chart. But I will show you how to make them anyway.\nBefore we plot, let\u0026rsquo;s calculate some summary statistics so we know what we should expect.\n# calculating mean bill_length_mm by species penguins_noNA %\u0026gt;% group_by(species) %\u0026gt;% summarize(mean_bill_length = mean(bill_length_mm)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; species mean_bill_length #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Adelie 38.8 #\u0026gt; 2 Chinstrap 48.8 #\u0026gt; 3 Gentoo 47.6   Just calling geom_col() does not give us what we want. Look at the y-axis scale and how out of line this is with our summary statistics.\n# bar plot with geom_col() # this is wrong! penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm)) + geom_col()   Using geom_col() the right way.\n# bar plot, the right way with geom_col() penguins_noNA %\u0026gt;% group_by(species) %\u0026gt;% summarize(mean_bill_length = mean(bill_length_mm)) %\u0026gt;% ggplot(aes(x = species, y = mean_bill_length)) + geom_col() #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument)  # or you could do this in a less bulky way with stat_summary() penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm)) + stat_summary(fun = \"mean\", geom = \"bar\")    5 - Boxplots with geom_boxplot() A boxplot has the benefit of showing you more than the median and the standard deviation, so you can better see the true distribution of your data. In geom_boxplot():\n lower whisker = smallest observation greater than or equal to lower hinge - 1.5 * IQR lower hinge/bottom line of box part of boxplot = 25% quantile middle = median, 50% quantile upper hinge/top line of box part of boxplot = 75% quantile upper whisker = largest observation less than or equal to upper hinge + 1.5 * IQR  # vertical boxplot penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm)) + geom_boxplot()   Adding coord_flip() makes your vertical boxplot horizontal. You could do the same thing by flipping the variables on the x and y mappings.\n# horizontal boxplot penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm)) + geom_boxplot() + coord_flip()   Look at how much more information we have here than in our bar plots!\n 5 - Violin plots with geom_violin() A violin plot is boxplot-esque, but shows a mirrored density distribution. This type of plot is useful when you are trying to particularly show data distribution.\nNote here I have also mapped species to color, within the aes statement so it will apply globally to this plot.\n# violin plot penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm, color = species)) + geom_violin()   Adding geom_point() lets you add another layer of all the actual data points, on top of your violin plot. Remember that this is inherent in the design of ggplot2, that you can layer your plots, of different types, on top of each other.\n# violin plot with data points overlaid penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm, fill = species)) + geom_violin() + geom_point()   Note, I am now mapping species to fill instead of color. See the difference?\nThis doesn\u0026rsquo;t look too good because of overplotting, i.e., the smear of datapoints that doesn\u0026rsquo;t give you much information about distribution.\nWe can add geom_jitter() to introduce some small amount of randomness to our points to make us able to see them better. Seeing all your data points also lets the reader easily get a sense of your sample size.\n# violin plot with data points jittered penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm, fill = species)) + geom_violin() + geom_jitter()   geom_jitter() is a specialized version of geom_point(), but you could replace the geom_jitter() call with geom_point(position = \u0026quot;jitter) and get the same result. You can also use geom_point(position = position_jitterdodge()) if you only want jitter in the x, and don\u0026rsquo;t want any jitter in the y.\nWow, we now have so much more information about our data!\n 6 - Dot plots with geom_dotplot() A dot plot plots each individual datapoint, and can stack how you like. These look a lot like the SigmaPlot plots to me.\n binaxis can be set to \u0026ldquo;x\u0026rdquo; or \u0026ldquo;y\u0026rdquo; stackdir indicates how to stack the dots: \u0026ldquo;up\u0026rdquo; (default), \u0026ldquo;down\u0026rdquo;, \u0026ldquo;center\u0026rdquo;, \u0026ldquo;centerwhole\u0026rdquo; (centered, but with dots aligned) dotsize indicates the size of the dots, with 1 as default  # dotplot penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm, fill = species)) + geom_dotplot(binaxis = \"y\", stackdir = \"center\", dotsize = 0.5) #\u0026gt; `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`.    7 - Density ridge plots with geom_density_ridges() A density ridge plots with geom_density_ridges() requires the packages ggridges, and make multiple density plots in a staggered orientation.\nYou can adjust scale within geom_density_ridges() to adjust the size of each density plot, though I have left it on the default. Adding alpha sets transparency.\n# install.packages(\"ggridges\") library(ggridges) penguins_noNA %\u0026gt;% ggplot(aes(x = bill_length_mm, y = species, fill = species)) + geom_density_ridges(alpha = 0.8) #\u0026gt; Picking joint bandwidth of 1.08    8 - ggplot is made for layering! I have shown you a bunch of different plot types, and you can combine many of them together. Here is an example of combining geom_violin() and geom_jitter(), while mapping new variables to aesthetics.\npenguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm, color = sex, shape = island, group = species)) + geom_violin() + geom_jitter(position = position_jitterdodge(jitter.width = 2))    9 - Increase clarity and visual appeal We can quickly make our plot:\n prettier by setting a theme more clear by setting plot labels (eg., axes, titles, legend) with labs  penguins_noNA %\u0026gt;% ggplot(aes(x = species, y = bill_length_mm, color = sex, shape = island, group = species)) + geom_violin() + geom_jitter(position = position_jitterdodge(jitter.width = 2), alpha = 0.7) + theme_classic() + labs(title = \"Penguin Bill Length by Species, Sex and Location\", subtitle = \"Collected at Palmer Station, Antarctica\", x = \"Penguin Species\", # x axis label y = \"Bill length (mm)\", # y axis label color = \"Sex\", # legend title shape = \"Island\") # legend title    10 - Breakout rooms! Main exercises Get data We are going to use the NHANES dataset we used in Session 3 on joining. What was that data about again? Let\u0026rsquo;s refresh our memory.\n library(NHANES) knitr::kable(head(NHANES))     ID SurveyYr Gender Age AgeDecade AgeMonths Race1 Race3 Education MaritalStatus HHIncome HHIncomeMid Poverty HomeRooms HomeOwn Work Weight Length HeadCirc Height BMI BMICatUnder20yrs BMI_WHO Pulse BPSysAve BPDiaAve BPSys1 BPDia1 BPSys2 BPDia2 BPSys3 BPDia3 Testosterone DirectChol TotChol UrineVol1 UrineFlow1 UrineVol2 UrineFlow2 Diabetes DiabetesAge HealthGen DaysPhysHlthBad DaysMentHlthBad LittleInterest Depressed nPregnancies nBabies Age1stBaby SleepHrsNight SleepTrouble PhysActive PhysActiveDays TVHrsDay CompHrsDay TVHrsDayChild CompHrsDayChild Alcohol12PlusYr AlcoholDay AlcoholYear SmokeNow Smoke100 Smoke100n SmokeAge Marijuana AgeFirstMarij RegularMarij AgeRegMarij HardDrugs SexEver SexAge SexNumPartnLife SexNumPartYear SameSex SexOrientation PregnantNow     51624 2009_10 male 34 30-39 409 White NA High School Married 25000-34999 30000 1.36 6 Own NotWorking 87.4 NA NA 164.7 32.22 NA 30.0_plus 70 113 85 114 88 114 88 112 82 NA 1.29 3.49 352 NA NA NA No NA Good 0 15 Most Several NA NA NA 4 Yes No NA NA NA NA NA Yes NA 0 No Yes Smoker 18 Yes 17 No NA Yes Yes 16 8 1 No Heterosexual NA   51624 2009_10 male 34 30-39 409 White NA High School Married 25000-34999 30000 1.36 6 Own NotWorking 87.4 NA NA 164.7 32.22 NA 30.0_plus 70 113 85 114 88 114 88 112 82 NA 1.29 3.49 352 NA NA NA No NA Good 0 15 Most Several NA NA NA 4 Yes No NA NA NA NA NA Yes NA 0 No Yes Smoker 18 Yes 17 No NA Yes Yes 16 8 1 No Heterosexual NA   51624 2009_10 male 34 30-39 409 White NA High School Married 25000-34999 30000 1.36 6 Own NotWorking 87.4 NA NA 164.7 32.22 NA 30.0_plus 70 113 85 114 88 114 88 112 82 NA 1.29 3.49 352 NA NA NA No NA Good 0 15 Most Several NA NA NA 4 Yes No NA NA NA NA NA Yes NA 0 No Yes Smoker 18 Yes 17 No NA Yes Yes 16 8 1 No Heterosexual NA   51625 2009_10 male 4 0-9 49 Other NA NA NA 20000-24999 22500 1.07 9 Own NA 17.0 NA NA 105.4 15.30 NA 12.0_18.5 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA No NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 4 1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA   51630 2009_10 female 49 40-49 596 White NA Some College LivePartner 35000-44999 40000 1.91 5 Rent NotWorking 86.7 NA NA 168.4 30.57 NA 30.0_plus 86 112 75 118 82 108 74 116 76 NA 1.16 6.70 77 0.094 NA NA No NA Good 0 10 Several Several 2 2 27 8 Yes No NA NA NA NA NA Yes 2 20 Yes Yes Smoker 38 Yes 18 No NA Yes Yes 12 10 1 Yes Heterosexual NA   51638 2009_10 male 9 0-9 115 White NA NA NA 75000-99999 87500 1.84 6 Rent NA 29.8 NA NA 133.1 16.82 NA 12.0_18.5 82 86 47 84 50 84 50 88 44 NA 1.34 4.86 123 1.538 NA NA No NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 5 0 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA    # kable just formats as a scrollable table for this website # you can just use head(NHANES) or glimpse(NHANES)    Exercise 1  Create a new data frame includes the NHANES data only from individuals that are 20 years of age or older, and removes observations where there are NAs for either age subdivided by decade (AgeDecade) or total cholesterol (TotChol).\n  Hints (click here)  Try using a series of filter() statements. Remember, you can tell filter what you want, or what you don\u0026rsquo;t want. You can filter for if specific variables have NAs by using is.na() on your variable of interest. Also remember that ! means \u0026ldquo;not.\u0026rdquo; You will notice that if you want to use drop_NA() you need to specific which specific variables you want to use, or you will inadvertably drop a lot of observations which have missing data for variables other than those we are plotting..    Solutions (click here)  # here are a few ways to do this NHANES_over20_noNA \u0026lt;- NHANES %\u0026gt;% filter(Age \u0026gt;20) %\u0026gt;% drop_na(AgeDecade, TotChol) dim(NHANES_over20_noNA) #\u0026gt; [1] 6408 76 NHANES_over20_noNA \u0026lt;- NHANES %\u0026gt;% filter(Age \u0026gt;20, !is.na(AgeDecade), !is.na(TotChol)) dim(NHANES_over20_noNA) #\u0026gt; [1] 6408 76       Exercise 2  Create a boxplot to show the relationship between total cholesterol (TotChol) and age (AgeDecade).\n  Hints (click here)  Try geom_boxplot(). Map your variables of interest to the x and y aesthetics. Which you variable you put on x and y will determine if your boxplot is vertical or horizontal.    Solutions (click here)  NHANES_over20_noNA %\u0026gt;% ggplot(aes(x = AgeDecade, y = TotChol)) + geom_boxplot()       Exercise 3  Take your plot from Exercise 2 and make it a violin plot instead of a boxplot. Then color by age.\n  Hints (click here)  The geom for a violin plot is geom_violin(). You can change color by mapping to color or to fill.    Solutions (click here)  Note the difference between mapping to color vs. fill.\nNHANES_over20_noNA %\u0026gt;% ggplot(aes(x = AgeDecade, y = TotChol, color = AgeDecade)) + geom_violin()   NHANES_over20_noNA %\u0026gt;% ggplot(aes(x = AgeDecade, y = TotChol, fill = AgeDecade)) + geom_violin()       Exercise 4  Make add a boxplot to your violin plot from Exercise 3. Adjust the parameters so you the plot looks good to you.\n  Hints (click here)  In geom_boxplot(), you can adjust the width of the boxplot by setting width = X. A width of 1 is the default.    Solutions (click here)  NHANES_over20_noNA %\u0026gt;% ggplot(aes(x = AgeDecade, y = TotChol, color = AgeDecade)) + geom_violin() + geom_boxplot(width = 0.2)       Exercise 5  Add all of the data points on top of your boxplot from Exercise 2 of total cholesterol by age. Adjust the parameters so you the plot looks good to you. While you are at it, clean up your plot labels and give your plot a title.\n  Hints (click here)  Remember that ggplot layers your plots, so layers that are further down in your code, will be applied on top of those that come earlier.    Solutions (click here)  geom_boxplot(outlier.shape = NA) removes the outliers from geom_boxplot(), since we are plotting all of the points, we do not want the outliers appearing twice.\nNHANES_over20_noNA %\u0026gt;% ggplot(aes(x = AgeDecade, y = TotChol, color = AgeDecade)) + geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.3, alpha = 0.1) + labs(title = \"Total Cholesterol by Age\", subtitle = \"Data from the National Health and Nutrition Examination Survey (NHANES)\", x = \"Age, by Decade\", y = \"Total Cholesterol, mmol/L\", color = \"Age (years)\")       Bonus exercises Bonus 1  Make a density ridge plot for age by total cholesterol.\n  Hints (click here)  Try geom_density_ridges(), and remember, this is not a part of ggplot2, so be sure to call library(ggridges).    Solutions (click here)  # install.packages(\"ggridges\") library(ggridges) NHANES_over20_noNA %\u0026gt;% ggplot(aes(x = TotChol, y = AgeDecade, fill = AgeDecade)) + geom_density_ridges(alpha = 0.7) #\u0026gt; Picking joint bandwidth of 0.224       Bonus 2  Take your density ridge plot from Bonus 1, and try applying a theme from hrbrthemes to it.\n  Hints (click here)  hrbrthemes is not part of ggplot2 so remember to install the package, and then call library(hrbrthemes). You can google the package to see what all your theme options are. I like theme_ipsum_rc(), try that one if you like!    Solutions (click here)  # install.packages(\"hrbrthemes\") library(hrbrthemes) #\u0026gt; NOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes. #\u0026gt; Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and #\u0026gt; if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow NHANES_over20_noNA %\u0026gt;% ggplot(aes(x = TotChol, y = AgeDecade, fill = AgeDecade)) + geom_density_ridges(alpha = 0.7, scale = 0.9) + theme_ipsum_rc() #\u0026gt; Picking joint bandwidth of 0.224       Bonus 3  Tidy up your plot from Bonus 2 by giving it a title, axis labels, and try adding the median total cholesterol to each density ridge plot.\n  Hints (click here)  Using stat_summary() will help you add the median.\n   Solutions (click here)   theme(axis.title.x = element_text(hjust = 0.5)) makes the x-axis title center justified. you can change shape within stat_summary() to be anything you like, either an R shape, a specific keyboard key, or even a pasted emoji. The default is a point. when you set a theme(), anything that comes below will override what code comes previous, so for this reason, if you are going to amend a pre-made theme, first call the pre-made theme, and then make any changes you like below.  NHANES_over20_noNA %\u0026gt;% ggplot(aes(x = TotChol, y = AgeDecade, fill = AgeDecade)) + geom_density_ridges(alpha = 0.7, scale = 0.9) + stat_summary(fun = median) + theme_ipsum_rc() + theme(axis.title.x = element_text(hjust = 0.5), axis.title.y = element_text(hjust = 0.5)) + labs(title = \"Total Cholesterol by Age\", subtitle = \"Data from the National Health and Nutrition Examination Survey (NHANES)\", x = \"Total Cholesterol, mmol/L\", y = \"Age, by Decade\", fill = \"Age (years)\") #\u0026gt; Picking joint bandwidth of 0.224 #\u0026gt; Warning: Removed 6 rows containing missing values (geom_segment).       Bonus 4  Commonly used cutoffs for cholesterol are: \u0026lt; 5.2 mmol/L is normal, 5.2-6.2 mmol/L is borderline high and \u0026gt; 6.2 mmol is high. Add a vertical cutoff line showing the level below which cholesterol would be considered normal.\n  Hints (click here)  Using geom_vline() will let you add a vertical line with an xintercept that is appropriate.    Solutions (click here)  NHANES_over20_noNA %\u0026gt;% ggplot(aes(x = TotChol, y = AgeDecade, fill = AgeDecade)) + geom_density_ridges(alpha = 0.7, scale = 0.9) + stat_summary(fun = median) + geom_vline(aes(xintercept = 5.2)) + theme_ipsum_rc() + theme(axis.title.x = element_text(hjust = 0.5), axis.title.y = element_text(hjust = 0.5)) + labs(title = \"Total Cholesterol by Age\", subtitle = \"Data from the National Health and Nutrition Examination Survey (NHANES)\", caption = \"Vertical line indicates upper limit of normal cholesterol\", x = \"Total Cholesterol, mmol/L\", y = \"Age, by Decade\", fill = \"Age (years)\") #\u0026gt; Picking joint bandwidth of 0.224 #\u0026gt; Warning: Removed 6 rows containing missing values (geom_segment).       ","date":1610668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611108419,"objectID":"a799f7bb592979c0bb09905b9a132709","permalink":"https://biodash.github.io/codeclub/05_ggplot-round-2/","publishdate":"2021-01-15T00:00:00Z","relpermalink":"/codeclub/05_ggplot-round-2/","section":"codeclub","summary":"During this fifth session of Code Club, we will be continuing to learn to use ggplot2, including techniques that better enable us to see our true data distribution.","tags":null,"title":"Session 5: ggplot2, round 2","type":"codeclub"},{"authors":["Michael Broe"],"categories":null,"content":"\n New To Code Club?   First, check out the Code Club Computer Setup instructions, which also has some pointers that might be helpful if you\u0026rsquo;re new to R or RStudio.\n  Please open RStudio before Code Club to test things out \u0026ndash; if you run into issues, join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n   Session Goals  Learn the philosophy of coding a graphic. Learn the basic template of a ggplot2 graphic, so you can reuse it for multiple chart types. Learn how you can quickly add visual information to a graphic using aesthetics and layers.   Intro: The ggplot2 philosophy We have already seen that in R, instead of manually manipulating data frames as you might do when editing Excel sheets, we code the operations we want to perform using dplyr verbs like select(), mutate(), inner_join(), and so on.\nIn a similar way when performing visualization, instead of clicking on a chart type in Excel, we code the chart in R.\nAnd just as dplyr gives us efficient ways to manipulate data frames, ggplot2 (which is also part of the tidyverse) gives us efficient ways to manipulate charts/plots/graphics (we use these terms interchangeably).\nThe gg in ggplot2 stands for grammar of graphics, a systematic approach for designing statistical plots developed by Leland Wilkinson. The idea behind this was to think about \u0026lsquo;pulling apart\u0026rsquo; various plots into their shared component pieces, then provide code that could put them together again. We can then create new plots like we create new sentences (once we understand this grammar).\nThere are two parts to this. First, the \u0026lsquo;nouns and verbs\u0026rsquo; we need to work with plots are very different than those we need to work with data frames. ggplot2 is like a mini-language of its own, with its own verbs and syntax.\nSecond, this notion of pulling apart a graphic leads to the idea of layers. You can build up a plot of any complexity by overlaying different views of the same data.\nThere\u0026rsquo;s a learning curve here for sure, but there are a couple of things that help us.\nFirst, every graphic shares a common template. This is like thinking about the sentence \u0026ldquo;The cat sat on the mat\u0026rdquo; grammatically as the template NP V PP (Noun Phrase \u0026ldquo;The cat\u0026rdquo;, Verb \u0026ldquo;sat\u0026rdquo;, Prepositional Phrase \u0026ldquo;on the mat\u0026rdquo;). Once you understand this structure you can \u0026ldquo;say\u0026rdquo; a lot of different things.\n(And I mean a lot. The ggplot cheat sheet lists over 40 plot-types, but because this is a language, users can create their own extensions that you can also utilize, adding over 80 more.)\nSecond, the way we put layers together is identical to the way we use pipes. You can read %\u0026gt;% as \u0026ldquo;and then\u0026rdquo;: select() and then mutate() and then summarize(). In graphics, we can say \u0026ldquo;show this layer, and then overlay this layer, and then overlay this layer\u0026rdquo;, etc., using a very similar syntax.\n Examples So how does this work in practice? We\u0026rsquo;ll work through visualizing the iris dataset that you\u0026rsquo;ve seen before. This is an extremely famous dataset that was first analyzed by R. A. Fisher in 1936: The use of multiple measurements in taxonomic problems. He was attempting to use petal and sepal measurements to discriminate one species from another.\nggplot2 is part of the tidyverse package so we need to load that first:\n# this assumes you've already installed tidyverse library(tidyverse) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.2 ✔ purrr  0.3.4 #\u0026gt; ✔ tibble  3.0.4 ✔ dplyr  0.8.5 #\u0026gt; ✔ tidyr  1.0.3 ✔ stringr 1.4.0 #\u0026gt; ✔ readr  1.3.1 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag()   And recall that the iris dataset (3 species, 50 observations per species) is automatically available to us:\nhead(iris) #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; 1 5.1 3.5 1.4 0.2 setosa #\u0026gt; 2 4.9 3.0 1.4 0.2 setosa #\u0026gt; 3 4.7 3.2 1.3 0.2 setosa #\u0026gt; 4 4.6 3.1 1.5 0.2 setosa #\u0026gt; 5 5.0 3.6 1.4 0.2 setosa #\u0026gt; 6 5.4 3.9 1.7 0.4 setosa   What is the correlation between petal length and width in these species? Are longer petals also wider? We can visualize this with a scatterplot. But first let\u0026rsquo;s look a the ggplot template. (Note the package is ggplot2, the command is ggplot.)\nggplot(data = \u0026lt;DATA\u0026gt;) + \u0026lt;GEOM_FUNCTION\u0026gt;(mapping = aes(\u0026lt;MAPPINGS\u0026gt;))  These are the obligatory parts of any plot. The first argument to ggplot() is the data frame:\nggplot(data = iris)   This is not very interesting! but it\u0026rsquo;s notable that it is something. ggplot() has created a base coordinate system (a base layer) that we can add visual layers to. The add a layer operator is \u0026ldquo;+\u0026rdquo;, which is the ggplot equivalent of the pipe symbol, and it must occur at the end of the line.\nThe next argument specifies the kind plot we want: scatterplot, bar chart, fitted line, boxplot, pie chart, etc. ggplot2 refers to these as geoms: the geometrical object that a plot uses to represent data. You can see an overview of many of these geoms in the cheat sheet. The geom for a scatterplot is geom_point().\nBut we also require a mapping argument, which maps the variables in the dataset we want to focus on to their visual representation in the plot.\nAnd finally we need to specify an aesthetic for the geometric objects in the plot, which will control things like shape, color, transparency, etc. Perhaps surprisingly, for a scatterplot, the x and y coordinates are aesthetics, since these control, not the shape or color, but the relative position of the points in the coordinate system.\nHere is our complete plot:\nggplot(data = iris) + geom_point(mapping = aes(x = Petal.Length, y = Petal.Width))   There is clearly a positive correlation between length and width. And we can make this even more apparent by visually fitting a line to the data, by overlaying another geom in the same plot.\nggplot(data = iris) + geom_point(mapping = aes(x = Petal.Length, y = Petal.Width)) + geom_smooth(mapping = aes(x = Petal.Length, y = Petal.Width)) #\u0026gt; `geom_smooth()` using method = 'loess' and formula 'y ~ x'   There is clearly some code redundancy here, and we really don\u0026rsquo;t want the x, y mapping of these two layers to be independent. We can extract the common mapping information and move it to the top level:\nggplot(data = iris, (mapping = aes(x = Petal.Length, y = Petal.Width))) + geom_point() + geom_smooth() #\u0026gt; `geom_smooth()` using method = 'loess' and formula 'y ~ x'   So we have the possibility of local layer specifications, and global specifications. Global specifications are inherited by all the local layers.\nThe power of aesthetics The aim of Fisher\u0026rsquo;s paper was to try to discriminate different species based on their morphological measurements. It looks from this plot that there are two distinct clusters. Do these clusters correspond to different species? There are two clusters, but three species. How can we explore this further?\nOur current plot uses two numeric variables: Petal.Length and Petal.width. We can add a third categorical variable, like Species, to a two dimensional scatterplot by mapping it to a different visual aesthetic. We\u0026rsquo;ve mapped length and width to x,y coordinates. Now we\u0026rsquo;ll simultaneously map species to color by expanding our list of aesthetics:\nggplot(data = iris) + (mapping = aes(x = Petal.Length, y = Petal.Width, color = Species)) + geom_point()   The R help for a specific geoms will list, among other things, all the aesthetics that geom supports.\nBreakout Rooms In the exercises we\u0026rsquo;ll be looking a little more at the iris data, and in addition, the NHANES data we used last week, and the left-joined bird dataset we built last week in Excercise 7.\nIf you haven\u0026rsquo;t installed the NHANES dataset do:\ninstall.packages(\"NHANES\", repos = \"http://cran.us.r-project.org\") #\u0026gt;  #\u0026gt; The downloaded binary packages are in #\u0026gt; /var/folders/d4/h4yjqs1560zbsgvrrwbmbp5r0000gn/T//RtmpPvm8W9/downloaded_packages   Once installed, load it with:\nlibrary(NHANES)   A prebuilt joined data set has been loaded on github.\n# create a data directory for the new file if you haven't done so yet: dir.create('data/birds', recursive = TRUE) #\u0026gt; Warning in dir.create(\"data/birds\", recursive = TRUE): 'data/birds' already exists # set the url joined_data_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/04_ggplot2/joined_data.tsv' # set the path for the downloaded file joined_file \u0026lt;- 'data/birds/joined_data.tsv' #download to file download.file(url = joined_data_url, destfile = joined_file) # read file joined_data \u0026lt;- read_tsv(joined_file) #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; adult_body_mass_g = col_double(), #\u0026gt; adult_svl_cm = col_double(), #\u0026gt; longevity_y = col_double(), #\u0026gt; litter_or_clutch_size_n = col_double() #\u0026gt; )   Exercise 1 Revisit the iris data set, and plot sepal width (y) against sepal length (x) colored by species. Which morphological character, petals or sepals, provides the greatest discrimination between species?\n  Hints (click here)  Simply reuse the code we used for petals. You can often leverage code from an old plot for a new one.    Solution (click here)  ggplot(data = iris) + (mapping = aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + geom_point()   Note this solution shows yet another way to position global mapping information: as its own layer. This can help readability and avoid too many nested parentheses.\n   Exercise 2 Use the NHANES data set to plot body mass index (y) against height (x). Color by gender. Which gender has the highest BMI?\n  Hints (click here)  glimpse() the dataset to identify the variable names.    Solution (click here)  ggplot(data = NHANES) + geom_point(mapping = (aes(x = Height, y = BMI, color = Gender))) #\u0026gt; Warning: Removed 366 rows containing missing values (geom_point).      Exercise 3 Use the same plot but now color by physical activity. How active are those people with the highest BMI?\n  Hints (click here)  Again, glimpse() the dataset to identify the variable names.    Solution (click here)  ggplot(data = NHANES) + geom_point(mapping = (aes(x = Height, y = BMI, color = PhysActive))) #\u0026gt; Warning: Removed 366 rows containing missing values (geom_point).      Exercise 4 Often plotting the data allows us to identify outliers, which may be data-entry errors, or genuinely extreme data. Using the joined_data set, plot adult body mass (y) against longevity (x). Identify extreme data points at the high end of body mass. How can we identify what these points represent?\n  Hints (click here)  Examine the plot to find an appropriate threshold value, and filter the data using that value. How many data points are there passing that threshold? What species are represented by these data points? How many weights are reported? Why is the plot misleading here?    Solution (click here)  ggplot(data = joined_data) + geom_point(mapping = (aes(x = longevity_y, y = adult_body_mass_g))) #\u0026gt; Warning: Removed 24089 rows containing missing values (geom_point).   joined_data %\u0026gt;% filter(adult_body_mass_g \u0026gt; 10000) #\u0026gt; # A tibble: 228 x 9 #\u0026gt; species locality stateProvince eventDate species_en #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dttm\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Cygnus… Findlay Ohio 2008-02-17 00:00:00 Mute Swan  #\u0026gt; 2 Cygnus… Dundee Ohio 2004-02-16 00:00:00 Mute Swan  #\u0026gt; 3 Cygnus… 44805 A… Ohio 2006-02-18 00:00:00 Mute Swan  #\u0026gt; 4 Cygnus… 45011 H… Ohio 2005-02-19 00:00:00 Mute Swan  #\u0026gt; 5 Cygnus… 45042 M… Ohio 2009-02-13 00:00:00 Trumpeter… #\u0026gt; 6 Cygnus… 44813 B… Ohio 2007-02-19 00:00:00 Mute Swan  #\u0026gt; 7 Cygnus… Spencer Ohio 2008-02-16 00:00:00 Mute Swan  #\u0026gt; 8 Cygnus… 44903 M… Ohio 2009-02-16 00:00:00 Mute Swan  #\u0026gt; 9 Cygnus… 44601 A… Ohio 2002-02-16 00:00:00 Mute Swan  #\u0026gt; 10 Cygnus… Avon La… Ohio 2007-02-17 00:00:00 Mute Swan  #\u0026gt; # … with 218 more rows, and 4 more variables: adult_body_mass_g \u0026lt;dbl\u0026gt;, #\u0026gt; # adult_svl_cm \u0026lt;dbl\u0026gt;, longevity_y \u0026lt;dbl\u0026gt;, litter_or_clutch_size_n \u0026lt;dbl\u0026gt;   joined_data %\u0026gt;% filter(adult_body_mass_g \u0026gt; 10000) %\u0026gt;% select(species) %\u0026gt;% distinct() #\u0026gt; # A tibble: 2 x 1 #\u0026gt; species  #\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Cygnus olor  #\u0026gt; 2 Cygnus buccinator   joined_data %\u0026gt;% filter(adult_body_mass_g \u0026gt; 10000) %\u0026gt;% select(adult_body_mass_g) %\u0026gt;% distinct() #\u0026gt; # A tibble: 2 x 1 #\u0026gt; adult_body_mass_g #\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 10230 #\u0026gt; 2 10300     Bonus, a new geom! Revisit the iris data and generate a density histogram for sepal length, categorized by species.\n  Hints (click here)  Use geom_density(). Check the help to see what aesthetics it supports. Note that while you 'color' a point, you 'fill' an area.    Solution (click here)  ggplot(data = iris) + (mapping = (aes(x = Sepal.Length, fill = Species))) + geom_density(alpha = 0.5)   Note, what does the alpha aesthetic control?    \n","date":1607558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608135268,"objectID":"cbba979dcba464a35bad36bb366cb927","permalink":"https://biodash.github.io/codeclub/04_ggplot2/","publishdate":"2020-12-10T00:00:00Z","relpermalink":"/codeclub/04_ggplot2/","section":"codeclub","summary":"In this session of Code Club, we'll look at how to visualize data in R using **ggplot2**.","tags":null,"title":"Session 4: Visualizing Data","type":"codeclub"},{"authors":["Mike Sovic"],"categories":null,"content":"\n New To Code Club?   First, check out the Code Club Computer Setup instructions, which also has some pointers that might be helpful if you\u0026rsquo;re new to R or RStudio.\n  Please open RStudio before Code Club to test things out \u0026ndash; if you run into issues, join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n   Session Goals  Differentiate between different types of joins\u0026hellip;  inner_join() full_join() left_join() right_join()   Use a join function to add new variables to the birds dataset Keep practicing with dplyr core verbs from last week, esp\u0026hellip;  select() filter()   Answer the question \u0026ldquo;What Ohio bird species have the longest and shortest average lifespans?\u0026rdquo;.   Intro: Merging/Joining Datasets Sometimes you don\u0026rsquo;t have all your data in the same place. For example, maybe you have multiple Excel sheets for a project - each storing a different type of data for the same set of samples. Or maybe you\u0026rsquo;re interested in analyzing various metrics for US states and are getting the data from different places online - economic data from one database, climate data from another, and so on. As part of the process of data wrangling, it\u0026rsquo;s often useful to merge the separate datasets together according to a variable they share, possibly \u0026ldquo;SampleID\u0026rdquo; or \u0026ldquo;State Name\u0026rdquo; for the two above examples, respectively. R offers several ways to do this, but we\u0026rsquo;ll focus here on the set of *_join() functions available in dplyr. They include\u0026hellip;\n inner_join() full_join() left_join() right_join() semi_join() anti_join()  Check out the \u0026lsquo;Combine Data Sets\u0026rsquo; section of this cheat sheet for a brief look at these functions.\nYou can also get more details here, or, as with any R function, by accessing the function\u0026rsquo;s documentation inside R with the \u0026lsquo;?\u0026rsquo;. For example, type ?inner_join at your R prompt and hit Enter. (Make sure the package the function comes from is loaded first! In this case, you need dplyr, which is loaded as part of tidyverse.)\n Examples Below we\u0026rsquo;ll go through a few examples of joins. You\u0026rsquo;re welcome to follow along and run this code on your own, but it\u0026rsquo;s not necessary - the exercises in the breakout rooms are independent of these examples and will give you a chance to try these things out on your own.\nIf you want to follow along, you can find the code here.\n Since the *_join() functions come from the dplyr package, which is part of tidyverse, I\u0026rsquo;ll load that first\u0026hellip;\n#this assumes you've already installed tidyverse library(tidyverse)   The National Health and Nutrition Examination Survey (NHANES) dataset contains survey data obtained annually from ~5,000 individuals on a variety of health and lifestyle-related metrics. A subset of the data are available as an R package - install and load it\u0026hellip;\ninstall.packages(\"NHANES\", repos = \"http://cran.us.r-project.org\") #\u0026gt;  #\u0026gt; The downloaded binary packages are in #\u0026gt; /var/folders/s7/y_mgh3c54h9fjcyw9wqdkb8x4zs_jy/T//RtmpdHHxzY/downloaded_packages library(NHANES)   Now preview the dataset\u0026hellip;\nglimpse(NHANES) #\u0026gt; Rows: 10,000 #\u0026gt; Columns: 76 #\u0026gt; $ ID \u0026lt;int\u0026gt; 51624, 51624, 51624, 51625, 51630, 51638, 51646, 516… #\u0026gt; $ SurveyYr \u0026lt;fct\u0026gt; 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10… #\u0026gt; $ Gender \u0026lt;fct\u0026gt; male, male, male, male, female, male, male, female, … #\u0026gt; $ Age \u0026lt;int\u0026gt; 34, 34, 34, 4, 49, 9, 8, 45, 45, 45, 66, 58, 54, 10,… #\u0026gt; $ AgeDecade \u0026lt;fct\u0026gt; 30-39, 30-39, 30-39, 0-9, 40-49, 0-9, 0-9, 4… #\u0026gt; $ AgeMonths \u0026lt;int\u0026gt; 409, 409, 409, 49, 596, 115, 101, 541, 541, 541, 795… #\u0026gt; $ Race1 \u0026lt;fct\u0026gt; White, White, White, Other, White, White, White, Whi… #\u0026gt; $ Race3 \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ Education \u0026lt;fct\u0026gt; High School, High School, High School, NA, Some Coll… #\u0026gt; $ MaritalStatus \u0026lt;fct\u0026gt; Married, Married, Married, NA, LivePartner, NA, NA, … #\u0026gt; $ HHIncome \u0026lt;fct\u0026gt; 25000-34999, 25000-34999, 25000-34999, 20000-24999, … #\u0026gt; $ HHIncomeMid \u0026lt;int\u0026gt; 30000, 30000, 30000, 22500, 40000, 87500, 60000, 875… #\u0026gt; $ Poverty \u0026lt;dbl\u0026gt; 1.36, 1.36, 1.36, 1.07, 1.91, 1.84, 2.33, 5.00, 5.00… #\u0026gt; $ HomeRooms \u0026lt;int\u0026gt; 6, 6, 6, 9, 5, 6, 7, 6, 6, 6, 5, 10, 6, 10, 10, 4, 3… #\u0026gt; $ HomeOwn \u0026lt;fct\u0026gt; Own, Own, Own, Own, Rent, Rent, Own, Own, Own, Own, … #\u0026gt; $ Work \u0026lt;fct\u0026gt; NotWorking, NotWorking, NotWorking, NA, NotWorking, … #\u0026gt; $ Weight \u0026lt;dbl\u0026gt; 87.4, 87.4, 87.4, 17.0, 86.7, 29.8, 35.2, 75.7, 75.7… #\u0026gt; $ Length \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ HeadCirc \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ Height \u0026lt;dbl\u0026gt; 164.7, 164.7, 164.7, 105.4, 168.4, 133.1, 130.6, 166… #\u0026gt; $ BMI \u0026lt;dbl\u0026gt; 32.22, 32.22, 32.22, 15.30, 30.57, 16.82, 20.64, 27.… #\u0026gt; $ BMICatUnder20yrs \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ BMI_WHO \u0026lt;fct\u0026gt; 30.0_plus, 30.0_plus, 30.0_plus, 12.0_18.5, 30.0_plu… #\u0026gt; $ Pulse \u0026lt;int\u0026gt; 70, 70, 70, NA, 86, 82, 72, 62, 62, 62, 60, 62, 76, … #\u0026gt; $ BPSysAve \u0026lt;int\u0026gt; 113, 113, 113, NA, 112, 86, 107, 118, 118, 118, 111,… #\u0026gt; $ BPDiaAve \u0026lt;int\u0026gt; 85, 85, 85, NA, 75, 47, 37, 64, 64, 64, 63, 74, 85, … #\u0026gt; $ BPSys1 \u0026lt;int\u0026gt; 114, 114, 114, NA, 118, 84, 114, 106, 106, 106, 124,… #\u0026gt; $ BPDia1 \u0026lt;int\u0026gt; 88, 88, 88, NA, 82, 50, 46, 62, 62, 62, 64, 76, 86, … #\u0026gt; $ BPSys2 \u0026lt;int\u0026gt; 114, 114, 114, NA, 108, 84, 108, 118, 118, 118, 108,… #\u0026gt; $ BPDia2 \u0026lt;int\u0026gt; 88, 88, 88, NA, 74, 50, 36, 68, 68, 68, 62, 72, 88, … #\u0026gt; $ BPSys3 \u0026lt;int\u0026gt; 112, 112, 112, NA, 116, 88, 106, 118, 118, 118, 114,… #\u0026gt; $ BPDia3 \u0026lt;int\u0026gt; 82, 82, 82, NA, 76, 44, 38, 60, 60, 60, 64, 76, 82, … #\u0026gt; $ Testosterone \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ DirectChol \u0026lt;dbl\u0026gt; 1.29, 1.29, 1.29, NA, 1.16, 1.34, 1.55, 2.12, 2.12, … #\u0026gt; $ TotChol \u0026lt;dbl\u0026gt; 3.49, 3.49, 3.49, NA, 6.70, 4.86, 4.09, 5.82, 5.82, … #\u0026gt; $ UrineVol1 \u0026lt;int\u0026gt; 352, 352, 352, NA, 77, 123, 238, 106, 106, 106, 113,… #\u0026gt; $ UrineFlow1 \u0026lt;dbl\u0026gt; NA, NA, NA, NA, 0.094, 1.538, 1.322, 1.116, 1.116, 1… #\u0026gt; $ UrineVol2 \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ UrineFlow2 \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ Diabetes \u0026lt;fct\u0026gt; No, No, No, No, No, No, No, No, No, No, No, No, No, … #\u0026gt; $ DiabetesAge \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ HealthGen \u0026lt;fct\u0026gt; Good, Good, Good, NA, Good, NA, NA, Vgood, Vgood, Vg… #\u0026gt; $ DaysPhysHlthBad \u0026lt;int\u0026gt; 0, 0, 0, NA, 0, NA, NA, 0, 0, 0, 10, 0, 4, NA, NA, 0… #\u0026gt; $ DaysMentHlthBad \u0026lt;int\u0026gt; 15, 15, 15, NA, 10, NA, NA, 3, 3, 3, 0, 0, 0, NA, NA… #\u0026gt; $ LittleInterest \u0026lt;fct\u0026gt; Most, Most, Most, NA, Several, NA, NA, None, None, N… #\u0026gt; $ Depressed \u0026lt;fct\u0026gt; Several, Several, Several, NA, Several, NA, NA, None… #\u0026gt; $ nPregnancies \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, 1, 1, 1, NA, NA, NA, NA, … #\u0026gt; $ nBabies \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, N… #\u0026gt; $ Age1stBaby \u0026lt;int\u0026gt; NA, NA, NA, NA, 27, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ SleepHrsNight \u0026lt;int\u0026gt; 4, 4, 4, NA, 8, NA, NA, 8, 8, 8, 7, 5, 4, NA, 5, 7, … #\u0026gt; $ SleepTrouble \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, No, No, … #\u0026gt; $ PhysActive \u0026lt;fct\u0026gt; No, No, No, NA, No, NA, NA, Yes, Yes, Yes, Yes, Yes,… #\u0026gt; $ PhysActiveDays \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, 5, 5, 5, 7, 5, 1, NA, 2,… #\u0026gt; $ TVHrsDay \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ CompHrsDay \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #\u0026gt; $ TVHrsDayChild \u0026lt;int\u0026gt; NA, NA, NA, 4, NA, 5, 1, NA, NA, NA, NA, NA, NA, 4, … #\u0026gt; $ CompHrsDayChild \u0026lt;int\u0026gt; NA, NA, NA, 1, NA, 0, 6, NA, NA, NA, NA, NA, NA, 3, … #\u0026gt; $ Alcohol12PlusYr \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, Yes, … #\u0026gt; $ AlcoholDay \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, 3, 3, 3, 1, 2, 6, NA, NA,… #\u0026gt; $ AlcoholYear \u0026lt;int\u0026gt; 0, 0, 0, NA, 20, NA, NA, 52, 52, 52, 100, 104, 364, … #\u0026gt; $ SmokeNow \u0026lt;fct\u0026gt; No, No, No, NA, Yes, NA, NA, NA, NA, NA, No, NA, NA,… #\u0026gt; $ Smoke100 \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, Yes, No,… #\u0026gt; $ Smoke100n \u0026lt;fct\u0026gt; Smoker, Smoker, Smoker, NA, Smoker, NA, NA, Non-Smok… #\u0026gt; $ SmokeAge \u0026lt;int\u0026gt; 18, 18, 18, NA, 38, NA, NA, NA, NA, NA, 13, NA, NA, … #\u0026gt; $ Marijuana \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, NA, Y… #\u0026gt; $ AgeFirstMarij \u0026lt;int\u0026gt; 17, 17, 17, NA, 18, NA, NA, 13, 13, 13, NA, 19, 15, … #\u0026gt; $ RegularMarij \u0026lt;fct\u0026gt; No, No, No, NA, No, NA, NA, No, No, No, NA, Yes, Yes… #\u0026gt; $ AgeRegMarij \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 20, 15, … #\u0026gt; $ HardDrugs \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, No, Yes,… #\u0026gt; $ SexEver \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, Yes, … #\u0026gt; $ SexAge \u0026lt;int\u0026gt; 16, 16, 16, NA, 12, NA, NA, 13, 13, 13, 17, 22, 12, … #\u0026gt; $ SexNumPartnLife \u0026lt;int\u0026gt; 8, 8, 8, NA, 10, NA, NA, 20, 20, 20, 15, 7, 100, NA,… #\u0026gt; $ SexNumPartYear \u0026lt;int\u0026gt; 1, 1, 1, NA, 1, NA, NA, 0, 0, 0, NA, 1, 1, NA, NA, 1… #\u0026gt; $ SameSex \u0026lt;fct\u0026gt; No, No, No, NA, Yes, NA, NA, Yes, Yes, Yes, No, No, … #\u0026gt; $ SexOrientation \u0026lt;fct\u0026gt; Heterosexual, Heterosexual, Heterosexual, NA, Hetero… #\u0026gt; $ PregnantNow \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …   To try out merging/joining, we\u0026rsquo;ll create two separate data frames by pulling out some variables from this NHANES dataset. One will contain demographic variables, and the other with have some physical measurements. Then we\u0026rsquo;ll join them back together. Let\u0026rsquo;s create the two sub-datasets first\u0026hellip;\n#Filter out rows with data from 2009-2010 and Age \u0026gt; 5,  #select a subset (4) of the variables, then get rid of  #all duplicate rows. Assign the output to object 'dem_data'. dem_data \u0026lt;- NHANES %\u0026gt;% filter(SurveyYr == \"2009_10\") %\u0026gt;% filter(Age \u0026gt; 5) %\u0026gt;% select(ID, Gender, Age, Education) %\u0026gt;% distinct() #similar as above, but with a different filter and  #selecting different variables. Save as 'phys_data' phys_data \u0026lt;- NHANES %\u0026gt;% filter(SurveyYr == \"2009_10\") %\u0026gt;% filter(Height \u0026lt; 180) %\u0026gt;% select(ID, Height, BMI, Pulse) %\u0026gt;% distinct()   Now explore them a bit\u0026hellip;\n#view the first 6 rows of each - note the shared ID column head(dem_data) #\u0026gt; # A tibble: 6 x 4 #\u0026gt; ID Gender Age Education  #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt;  #\u0026gt; 1 51624 male 34 High School  #\u0026gt; 2 51630 female 49 Some College #\u0026gt; 3 51638 male 9 NA  #\u0026gt; 4 51646 male 8 NA  #\u0026gt; 5 51647 female 45 College Grad #\u0026gt; 6 51654 male 66 Some College head(phys_data) #\u0026gt; # A tibble: 6 x 4 #\u0026gt; ID Height BMI Pulse #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 51624 165. 32.2 70 #\u0026gt; 2 51625 105. 15.3 NA #\u0026gt; 3 51630 168. 30.6 86 #\u0026gt; 4 51638 133. 16.8 82 #\u0026gt; 5 51646 131. 20.6 72 #\u0026gt; 6 51647 167. 27.2 62 #preview in another way - note the different numbers of observations (rows) glimpse(dem_data) #\u0026gt; Rows: 3,217 #\u0026gt; Columns: 4 #\u0026gt; $ ID \u0026lt;int\u0026gt; 51624, 51630, 51638, 51646, 51647, 51654, 51656, 51657, 516… #\u0026gt; $ Gender \u0026lt;fct\u0026gt; male, female, male, male, female, male, male, male, female,… #\u0026gt; $ Age \u0026lt;int\u0026gt; 34, 49, 9, 8, 45, 66, 58, 54, 10, 58, 50, 9, 33, 60, 16, 56… #\u0026gt; $ Education \u0026lt;fct\u0026gt; High School, Some College, NA, NA, College Grad, Some Colle… glimpse(phys_data) #\u0026gt; Rows: 3,021 #\u0026gt; Columns: 4 #\u0026gt; $ ID \u0026lt;int\u0026gt; 51624, 51625, 51630, 51638, 51646, 51647, 51654, 51657, 51659,… #\u0026gt; $ Height \u0026lt;dbl\u0026gt; 164.7, 105.4, 168.4, 133.1, 130.6, 166.7, 169.5, 169.4, 141.8,… #\u0026gt; $ BMI \u0026lt;dbl\u0026gt; 32.22, 15.30, 30.57, 16.82, 20.64, 27.24, 23.67, 26.03, 19.20,… #\u0026gt; $ Pulse \u0026lt;int\u0026gt; 70, NA, 86, 82, 72, 62, 60, 76, 80, 94, 74, 92, 84, 76, 64, 70…   Let\u0026rsquo;s use the shared ID column to join the two datasets together. We\u0026rsquo;ll do this in 4 different ways to compare different types of joins: inner_join(), left_join(), right_join(), and full_join(). Pay attention to the number of rows in the joined dataset each time and how it relates to the number of rows in each of the two individual datasets.\nThe basic structure of the dplyr *_join() functions is\u0026hellip;\n*_join(dataframe 'x', dataframe 'y', by = shared column name)\n 1 - inner_join() #perform an inner join join_inner \u0026lt;- inner_join(dem_data, phys_data, by = \"ID\") #preview the new object head(join_inner) #\u0026gt; # A tibble: 6 x 7 #\u0026gt; ID Gender Age Education Height BMI Pulse #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 51624 male 34 High School 165. 32.2 70 #\u0026gt; 2 51630 female 49 Some College 168. 30.6 86 #\u0026gt; 3 51638 male 9 NA 133. 16.8 82 #\u0026gt; 4 51646 male 8 NA 131. 20.6 72 #\u0026gt; 5 51647 female 45 College Grad 167. 27.2 62 #\u0026gt; 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_inner) #\u0026gt; [1] 2806 7   2 - left_join() #perform an left join join_left \u0026lt;- left_join(dem_data, phys_data, by = \"ID\") #preview the new object head(join_left) #\u0026gt; # A tibble: 6 x 7 #\u0026gt; ID Gender Age Education Height BMI Pulse #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 51624 male 34 High School 165. 32.2 70 #\u0026gt; 2 51630 female 49 Some College 168. 30.6 86 #\u0026gt; 3 51638 male 9 NA 133. 16.8 82 #\u0026gt; 4 51646 male 8 NA 131. 20.6 72 #\u0026gt; 5 51647 female 45 College Grad 167. 27.2 62 #\u0026gt; 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_left) #\u0026gt; [1] 3217 7   3 - right_join() #perform an right join join_right \u0026lt;- right_join(dem_data, phys_data, by = \"ID\") #preview the new object head(join_right) #\u0026gt; # A tibble: 6 x 7 #\u0026gt; ID Gender Age Education Height BMI Pulse #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 51624 male 34 High School 165. 32.2 70 #\u0026gt; 2 51630 female 49 Some College 168. 30.6 86 #\u0026gt; 3 51638 male 9 NA 133. 16.8 82 #\u0026gt; 4 51646 male 8 NA 131. 20.6 72 #\u0026gt; 5 51647 female 45 College Grad 167. 27.2 62 #\u0026gt; 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_right) #\u0026gt; [1] 3021 7   4 - full_join() #perform an full join join_full \u0026lt;- full_join(dem_data, phys_data, by = \"ID\") #preview the new object head(join_full) #\u0026gt; # A tibble: 6 x 7 #\u0026gt; ID Gender Age Education Height BMI Pulse #\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 51624 male 34 High School 165. 32.2 70 #\u0026gt; 2 51630 female 49 Some College 168. 30.6 86 #\u0026gt; 3 51638 male 9 NA 133. 16.8 82 #\u0026gt; 4 51646 male 8 NA 131. 20.6 72 #\u0026gt; 5 51647 female 45 College Grad 167. 27.2 62 #\u0026gt; 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_full) #\u0026gt; [1] 3432 7    Breakout rooms We\u0026rsquo;re going to add to our backyard birds dataset. I found a dataset that has life history data for a large number of species (birds and others). We\u0026rsquo;ll use species names to merge some of these life history variables in to the occurrence data we already have.\nIf you\u0026rsquo;re new and haven\u0026rsquo;t yet gotten the backyard bird dataset, get it first by running the code below. Otherwise, you can skip this step\u0026hellip;\n# create a directory called data that contains a subdirectory called birds dir.create('data/birds/', recursive = TRUE) # set the location of the file birds_file_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv' # set the path for the downloaded file birds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' #download download.file(url = birds_file_url, destfile = birds_file)   Now (everybody), read in the bird data for this session\u0026hellip;\nbirds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' birds \u0026lt;- read_tsv(birds_file) #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; decimalLatitude = col_double(), #\u0026gt; decimalLongitude = col_double(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; range = col_character() #\u0026gt; )   Exercise 1  Reduce the backyard bird dataset and keep just the following columns: species, locality, stateProvince, eventDate, species_en\n  Hints (click here)  Use select() to pull out the columns you want.    Solution (click here)  birds \u0026lt;- birds %\u0026gt;% select(species, locality, stateProvince, eventDate, species_en)      Exercise 2  Check to make sure things look right - how many columns does the birds dataset now have?\n  Hints (click here)  Use the dim() function. Or the ncol() function. Or glimpse(). Or head(). Or str(). Or even summary(). There\u0026rsquo;s lots of ways to do this.    Solution (click here)  dim(birds) #\u0026gt; [1] 311441 5       Exercise 3  Now download and read in the new life history dataset (tab separated) available at https://github.com/biodash/biodash.github.io/raw/master/assets/data/birds/esa_life_history_data_cc.tsv. Then explore it a bit - how many rows and columns are there?\n  Hints (click here)  Use the download.file() function like we did previously for the bird dataset. You\u0026rsquo;ll need to define the arguments \u0026lsquo;url\u0026rsquo; and \u0026lsquo;destfile\u0026rsquo; inside the parentheses. You can put the file anywhere you want, but I\u0026rsquo;d suggest in the same directory as the bird file we got, so, for example, the destination file could be \u0026ldquo;data/birds/life_history_data.tsv\u0026rdquo;.    Solution (click here)  #download the file from online and save it as a '.tsv' file (since it's tab delimited) download.file(url = \"https://github.com/biodash/biodash.github.io/raw/master/assets/data/birds/esa_life_history_data_cc.tsv\", destfile = \"data/birds/life_history_data.tsv\") #read the data in to R as an object named 'life_hist' life_hist \u0026lt;- read_tsv(file = \"data/birds/life_history_data.tsv\") #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; common_name = col_character(), #\u0026gt; female_maturity_d = col_double(), #\u0026gt; litter_or_clutch_size_n = col_double(), #\u0026gt; litters_or_clutches_per_y = col_double(), #\u0026gt; adult_body_mass_g = col_double(), #\u0026gt; maximum_longevity_y = col_double(), #\u0026gt; egg_mass_g = col_double(), #\u0026gt; incubation_d = col_double(), #\u0026gt; fledging_age_d = col_double(), #\u0026gt; longevity_y = col_double(), #\u0026gt; adult_svl_cm = col_double() #\u0026gt; ) #preview the data glimpse(life_hist) #\u0026gt; Rows: 21,322 #\u0026gt; Columns: 16 #\u0026gt; $ class \u0026lt;chr\u0026gt; \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Av… #\u0026gt; $ order \u0026lt;chr\u0026gt; \"Accipitriformes\", \"Accipitriformes\", \"Acci… #\u0026gt; $ family \u0026lt;chr\u0026gt; \"Accipitridae\", \"Accipitridae\", \"Accipitrid… #\u0026gt; $ genus \u0026lt;chr\u0026gt; \"Accipiter\", \"Accipiter\", \"Accipiter\", \"Acc… #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Accipiter albogularis\", \"Accipiter badius\"… #\u0026gt; $ common_name \u0026lt;chr\u0026gt; \"Pied Goshawk\", \"Shikra\", \"Bicolored Hawk\",… #\u0026gt; $ female_maturity_d \u0026lt;dbl\u0026gt; NA, 363.468, NA, NA, 363.468, NA, NA, 547.8… #\u0026gt; $ litter_or_clutch_size_n \u0026lt;dbl\u0026gt; NA, 3.250, 2.700, NA, 4.000, NA, 2.700, 4.2… #\u0026gt; $ litters_or_clutches_per_y \u0026lt;dbl\u0026gt; NA, 1, NA, NA, 1, NA, NA, 1, NA, 1, NA, 1, … #\u0026gt; $ adult_body_mass_g \u0026lt;dbl\u0026gt; 251.500, 140.000, 345.000, 142.000, 203.500… #\u0026gt; $ maximum_longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 19.90000, NA, 2… #\u0026gt; $ egg_mass_g \u0026lt;dbl\u0026gt; NA, 21.00, 32.00, NA, 21.85, NA, 32.00, 19.… #\u0026gt; $ incubation_d \u0026lt;dbl\u0026gt; NA, 30.00, NA, NA, 32.50, NA, NA, 33.00, NA… #\u0026gt; $ fledging_age_d \u0026lt;dbl\u0026gt; NA, 32.00, NA, NA, 42.50, NA, NA, 24.25, NA… #\u0026gt; $ longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 12.58333, NA, 1… #\u0026gt; $ adult_svl_cm \u0026lt;dbl\u0026gt; NA, 30.00, 39.50, NA, 33.50, NA, 39.50, 29.…       Exercise 4  This new dataset contains life history data for more than just birds. What Classes of organisms are represented in the \u0026lsquo;Class\u0026rsquo; variable?\n  Hints (click here)  Try using a combination of the select() and distinct() functions to pull out the column you\u0026rsquo;re interested in, and then to get the distinct values, respectively.    Solutions (click here)  life_hist %\u0026gt;% select(class) %\u0026gt;% distinct() #\u0026gt; # A tibble: 3 x 1 #\u0026gt; class  #\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Aves  #\u0026gt; 2 Mammalia #\u0026gt; 3 Reptilia       Exercise 5  Reduce the life history dataset down to keep just the rows for Class Aves and the columns species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n. What are the dimensions now?\n  Hints (click here)  Use filter() along with an appropriate logical expression to keep the rows we want. Use select() to get the desired columns.    Solutions (click here)  # pull out target rows and columns life_hist_aves \u0026lt;- life_hist %\u0026gt;% filter(class == \"Aves\") %\u0026gt;% select(species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n) dim(life_hist_aves) #\u0026gt; [1] 9802 5       Exercise 6  Preview each dataset again, just to make sure you\u0026rsquo;re clear about what\u0026rsquo;s in each one. Are there any columns that are shared between the two?\n  Hints (click here)  Consider glimpse() or head() to preview the datasets (tibbles/data frames). If you want to use a function to find shared columns, try a combination of intersect() and names().\n   Solutions (click here)  glimpse(birds) #\u0026gt; Rows: 311,441 #\u0026gt; Columns: 12 #\u0026gt; $ class \u0026lt;chr\u0026gt; \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Ave… #\u0026gt; $ order \u0026lt;chr\u0026gt; \"Passeriformes\", \"Passeriformes\", \"Passeriformes\", \"… #\u0026gt; $ family \u0026lt;chr\u0026gt; \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Cor… #\u0026gt; $ genus \u0026lt;chr\u0026gt; \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitt… #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Cyanocitta cristata\", \"Cyanocitta cristata\", \"Cyano… #\u0026gt; $ locality \u0026lt;chr\u0026gt; \"44805 Ashland\", \"45244 Cincinnati\", \"44132 Euclid\",… #\u0026gt; $ stateProvince \u0026lt;chr\u0026gt; \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohi… #\u0026gt; $ decimalLatitude \u0026lt;dbl\u0026gt; 40.86166, 39.10666, 41.60768, 39.24236, 39.28207, 41… #\u0026gt; $ decimalLongitude \u0026lt;dbl\u0026gt; -82.31558, -84.32972, -81.50085, -84.35545, -84.4688… #\u0026gt; $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 200… #\u0026gt; $ species_en \u0026lt;chr\u0026gt; \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blu… #\u0026gt; $ range \u0026lt;chr\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … glimpse(life_hist_aves) #\u0026gt; Rows: 9,802 #\u0026gt; Columns: 5 #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Accipiter albogularis\", \"Accipiter badius\", … #\u0026gt; $ adult_body_mass_g \u0026lt;dbl\u0026gt; 251.500, 140.000, 345.000, 142.000, 203.500, … #\u0026gt; $ adult_svl_cm \u0026lt;dbl\u0026gt; NA, 30.00, 39.50, NA, 33.50, NA, 39.50, 29.00… #\u0026gt; $ longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 12.58333, NA, 12.… #\u0026gt; $ litter_or_clutch_size_n \u0026lt;dbl\u0026gt; NA, 3.250, 2.700, NA, 4.000, NA, 2.700, 4.250… intersect(names(birds), names(life_hist_aves)) #\u0026gt; [1] \"species\"       Exercise 7  Now lets join them together based on their shared variable. Not all species in the backyard bird (Ohio) dataset are included in the life history dataset. Likewise, there are life history data for many species that aren\u0026rsquo;t in the Ohio dataset. We want to keep all the Ohio observations, and merge in life history data for species where it\u0026rsquo;s availble, but we also don\u0026rsquo;t want to add in life history data for species that aren\u0026rsquo;t in the Ohio dataset. Choose an appropriate join function with those things in mind.\n  Hints (click here)  Try a left_join(), defining the Ohio backyard bird dataset as the \u0026lsquo;x\u0026rsquo; dataset in the join and the life history data as the \u0026lsquo;y\u0026rsquo; dataset. Get details on that function with ?left_join.    Solutions (click here)  joined_data \u0026lt;- left_join(x = birds, y = life_hist_aves, by = \"species\")       Exercise 8  What are the longest- and shortest-living bird species in Ohio based on the data in the longevity_y column?\n  Hints (click here)  Try using select() to pull out just the columns species and longevity_y, then use distinct() to get the unique rows, then arrange() based on the longevity_y column. You might also find the dplyr function desc() helpful.\nAlternatively, you could try grouping by species, then use summarise() to get either the max, min, or mean value for longevity_y for each species (there\u0026rsquo;s just one value for each species, so all of those statistics give the same value in this case). Then sort (arrange) the resulting summarized data frame on the longevity value.\n   Solutions (click here)  #option 1 - shortest-lived birds joined_data %\u0026gt;% select(species, longevity_y) %\u0026gt;% distinct() %\u0026gt;% arrange(longevity_y) #\u0026gt; # A tibble: 171 x 2 #\u0026gt; species longevity_y #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Loxia leucoptera 4  #\u0026gt; 2 Spiza americana 4  #\u0026gt; 3 Certhia americana 4.6  #\u0026gt; 4 Acanthis hornemanni 4.6  #\u0026gt; 5 Tringa flavipes 4.75 #\u0026gt; 6 Podiceps grisegena 4.8  #\u0026gt; 7 Calcarius lapponicus 5  #\u0026gt; 8 Anthus rubescens 5.1  #\u0026gt; 9 Perdix perdix 5.17 #\u0026gt; 10 Regulus satrapa 5.32 #\u0026gt; # … with 161 more rows #option 1 - longest-lived birds joined_data %\u0026gt;% select(species, longevity_y) %\u0026gt;% distinct() %\u0026gt;% arrange(desc(longevity_y)) #\u0026gt; # A tibble: 171 x 2 #\u0026gt; species longevity_y #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Larus argentatus 33.4 #\u0026gt; 2 Larus glaucoides 33  #\u0026gt; 3 Larus thayeri 33  #\u0026gt; 4 Haliaeetus leucocephalus 33.0 #\u0026gt; 5 Larus fuscus 32.8 #\u0026gt; 6 Aquila chrysaetos 32  #\u0026gt; 7 Anas platyrhynchos 29  #\u0026gt; 8 Larus delawarensis 28.6 #\u0026gt; 9 Asio otus 27.8 #\u0026gt; 10 Cygnus olor 27.7 #\u0026gt; # … with 161 more rows #option 2 - shortest-lived birds joined_data %\u0026gt;% group_by(species) %\u0026gt;% summarise(longevity = max(longevity_y)) %\u0026gt;% arrange(longevity) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 171 x 2 #\u0026gt; species longevity #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Loxia leucoptera 4  #\u0026gt; 2 Spiza americana 4  #\u0026gt; 3 Acanthis hornemanni 4.6  #\u0026gt; 4 Certhia americana 4.6  #\u0026gt; 5 Tringa flavipes 4.75 #\u0026gt; 6 Podiceps grisegena 4.8  #\u0026gt; 7 Calcarius lapponicus 5  #\u0026gt; 8 Anthus rubescens 5.1  #\u0026gt; 9 Perdix perdix 5.17 #\u0026gt; 10 Regulus satrapa 5.32 #\u0026gt; # … with 161 more rows #option 2 - longest-lived birds joined_data %\u0026gt;% group_by(species) %\u0026gt;% summarise(longevity = max(longevity_y)) %\u0026gt;% arrange(desc(longevity)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 171 x 2 #\u0026gt; species longevity #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Larus argentatus 33.4 #\u0026gt; 2 Larus glaucoides 33  #\u0026gt; 3 Larus thayeri 33  #\u0026gt; 4 Haliaeetus leucocephalus 33.0 #\u0026gt; 5 Larus fuscus 32.8 #\u0026gt; 6 Aquila chrysaetos 32  #\u0026gt; 7 Anas platyrhynchos 29  #\u0026gt; 8 Larus delawarensis 28.6 #\u0026gt; 9 Asio otus 27.8 #\u0026gt; 10 Cygnus olor 27.7 #\u0026gt; # … with 161 more rows       Bonus time! Bonus 1  What species in Ohio has the largest ratio of adult body mass to length (measured as snout vent length, or \u0026lsquo;adult_svl_cm\u0026rsquo;)?\n  Hints (click here)  Use mutate() to create a new variable containing the body mass divided by svl, then arrange the dataset using that new variable to get the species with the highest value.\n   Solutions (click here)  joined_data %\u0026gt;% mutate(ratio = adult_body_mass_g/adult_svl_cm) %\u0026gt;% select(species_en, ratio) %\u0026gt;% distinct() %\u0026gt;% arrange(desc(ratio)) #\u0026gt; # A tibble: 170 x 2 #\u0026gt; species_en ratio #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Mute Swan 71.8 #\u0026gt; 2 Wild Turkey 68.0 #\u0026gt; 3 Trumpeter Swan 64.9 #\u0026gt; 4 Bald Eagle 59.2 #\u0026gt; 5 Golden Eagle 56.2 #\u0026gt; 6 Canada Goose 48.3 #\u0026gt; 7 Tundra Swan 47.0 #\u0026gt; 8 Cackling Goose 44.4 #\u0026gt; 9 Snow Goose 35.1 #\u0026gt; 10 Snowy Owl 32.8 #\u0026gt; # … with 160 more rows       Bonus 2  There are 2 additional joins we haven\u0026rsquo;t talked about - semi_join() and anti_join(). Take a look at the documentation to see what these do. Use one of them to find what species in the backyard birds dataset are not in the life history dataset.\n  Hints (click here)  Use anti_join() and distinct().\n   Solutions (click here)  anti_join(birds, life_hist_aves, by = \"species\") %\u0026gt;% select(species, species_en) %\u0026gt;% distinct() #\u0026gt; # A tibble: 6 x 2 #\u0026gt; species species_en  #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 Dendrocopos pubescens Downy Woodpecker  #\u0026gt; 2 Spizelloides arborea American Tree Sparrow #\u0026gt; 3 Otus asio Eastern Screech Owl  #\u0026gt; 4 Larus minutus Little Gull  #\u0026gt; 5 Anas rubripes x platyrhynchos NA  #\u0026gt; 6 NA NA       Bonus 3  The life history dataset we downloaded above is actually a modified version of the original file, which is located at \u0026lsquo;http://www.esapubs.org/archive/ecol/E096/269/Data_Files/Amniote_Database_Aug_2015.csv\u0026rsquo;\nTry starting with the original file and repeating what we did above - merging the variables species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n in to the original birds dataset. First, make sure to get it read in correctly. Then pay attention to the species column in the life history dataset - what needs to be done before a join/merge can be performed?\n  Hints (click here)  Pay attention to how missing data are coded in this dataset (it\u0026rsquo;s -999). Also, data are very sparse for some of the variables - in other words, they have lots of missing data. This seems to cause a problem with the read_csv() function, as it only considers the first 1000 rows for the purpose of defining the class of each column. This can be a problem if all of the first 1000 rows are missing. Finally, it appears that even though this is a comma separated file (commas define the column breaks), there are a few instances where commas are used within a field. This happens in the \u0026lsquo;common name\u0026rsquo; column in a few cases where multiple common names are listed for a specific observation. This is one example of something that can become quite frustrating when trying to get data loaded in, and is worth keeping an eye out for. Fortunately, in our case, it only seems to happen for non-bird species in this dataset, which we filter out anyway, so it can be dealt with. However, if it had impacted any of the bird observations, I think fixing this might require a solution outside of R - possibly a command line approach.\n   Solutions (click here)  #download download.file(url = \"http://www.esapubs.org/archive/ecol/E096/269/Data_Files/Amniote_Database_Aug_2015.csv\", destfile = \"data/birds/orig_life_history.csv\") #read the data in to R as an object named 'full_life_hist' full_life_hist \u0026lt;- read_csv(\"data/birds/orig_life_history.csv\", na = \"-999\", col_types = cols(birth_or_hatching_svl_cm = col_double(), weaning_d = col_double(),gestation_d = col_double(), weaning_weight_g = col_double(), male_svl_cm = col_double(), female_svl_cm = col_double(), no_sex_svl_cm = col_double(), female_body_mass_at_maturity_g = col_double(), female_svl_at_maturity_cm = col_double())) #get the original version of the birds dataset birds \u0026lt;- read_tsv('data/birds/backyard-birds_Ohio.tsv') #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; decimalLatitude = col_double(), #\u0026gt; decimalLongitude = col_double(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; range = col_character() #\u0026gt; ) #subset each for the columns and rows we want life_hist_aves \u0026lt;- full_life_hist %\u0026gt;% filter(class == \"Aves\") %\u0026gt;% select(species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n) birds \u0026lt;- birds %\u0026gt;% select(species, locality, stateProvince, eventDate, species_en) glimpse(birds) #\u0026gt; Rows: 311,441 #\u0026gt; Columns: 5 #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Cyanocitta cristata\", \"Cyanocitta cristata\", \"Cyanocit… #\u0026gt; $ locality \u0026lt;chr\u0026gt; \"44805 Ashland\", \"45244 Cincinnati\", \"44132 Euclid\", \"4… #\u0026gt; $ stateProvince \u0026lt;chr\u0026gt; \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\",… #\u0026gt; $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 2007-0… #\u0026gt; $ species_en \u0026lt;chr\u0026gt; \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue J… glimpse(life_hist_aves) #\u0026gt; Rows: 9,802 #\u0026gt; Columns: 5 #\u0026gt; $ species \u0026lt;chr\u0026gt; \"albogularis\", \"badius\", \"bicolor\", \"brachyur… #\u0026gt; $ adult_body_mass_g \u0026lt;dbl\u0026gt; 251.500, 140.000, 345.000, 142.000, 203.500, … #\u0026gt; $ adult_svl_cm \u0026lt;dbl\u0026gt; NA, 30.00, 39.50, NA, 33.50, NA, 39.50, 29.00… #\u0026gt; $ longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 12.58333, NA, 12.… #\u0026gt; $ litter_or_clutch_size_n \u0026lt;dbl\u0026gt; NA, 3.250, 2.700, NA, 4.000, NA, 2.700, 4.250… #notice the species column in the life history data doesn't include the genus name. Since the names don't match in the species column from each dataset, a join won't work. Add the genus variable in from the original life history data... life_hist_aves \u0026lt;- full_life_hist %\u0026gt;% filter(class == \"Aves\") %\u0026gt;% select(genus, species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n) #now use mutate to replace the species column so it includes both the genus and species... life_hist_aves \u0026lt;- life_hist_aves %\u0026gt;% mutate(species = paste0(genus, \" \", species)) %\u0026gt;% select(-genus) #preview again glimpse(birds) #\u0026gt; Rows: 311,441 #\u0026gt; Columns: 5 #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Cyanocitta cristata\", \"Cyanocitta cristata\", \"Cyanocit… #\u0026gt; $ locality \u0026lt;chr\u0026gt; \"44805 Ashland\", \"45244 Cincinnati\", \"44132 Euclid\", \"4… #\u0026gt; $ stateProvince \u0026lt;chr\u0026gt; \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\",… #\u0026gt; $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 2007-0… #\u0026gt; $ species_en \u0026lt;chr\u0026gt; \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue J… glimpse(life_hist_aves) #\u0026gt; Rows: 9,802 #\u0026gt; Columns: 5 #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Accipiter albogularis\", \"Accipiter badius\", … #\u0026gt; $ adult_body_mass_g \u0026lt;dbl\u0026gt; 251.500, 140.000, 345.000, 142.000, 203.500, … #\u0026gt; $ adult_svl_cm \u0026lt;dbl\u0026gt; NA, 30.00, 39.50, NA, 33.50, NA, 39.50, 29.00… #\u0026gt; $ longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 12.58333, NA, 12.… #\u0026gt; $ litter_or_clutch_size_n \u0026lt;dbl\u0026gt; NA, 3.250, 2.700, NA, 4.000, NA, 2.700, 4.250… #now we can join joined_data \u0026lt;- left_join(birds, life_hist_aves, by = \"species\")       \n","date":1607040000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629215857,"objectID":"27c93c3c265ed2c0052748376945f941","permalink":"https://biodash.github.io/codeclub/03_joining-datasets/","publishdate":"2020-12-04T00:00:00Z","relpermalink":"/codeclub/03_joining-datasets/","section":"codeclub","summary":"In this session of Code Club, we'll explore some methods for combining datasets according to a shared variable, with primary focus on the `*_join()` set of functions from **dplyr**. We'll also keep practicing with some of the core dplyr verbs from last session.","tags":null,"title":"Session 3: Joining Datasets","type":"codeclub"},{"authors":["Jessica Cooperstone"],"categories":null,"content":"\n Prep homework Basic computer setup   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n  New to dplyr? If you\u0026rsquo;ve never used dplyr before (or even if you have), you may find this cheat sheet useful.\n Getting Started Want to download an R script with the content from today\u0026rsquo;s session? # directory for Code Club Session 2: dir.create(\"S02\") # directory for our script # (\"recursive\" to create two levels at once.) dir.create(\"S02/scripts/\") # save the url location for today's script todays_R_script \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/02_dplyr-core-verbs/2_Dplyr_one-table_verbs.R' # indicate the name of the new script file Session2_dplyr_core \u0026lt;- \"S02/scripts/Session2_script.R\" # go get that file!  download.file(url = todays_R_script, destfile = Session2_dplyr_core)    1 - What is data wrangling? It has been estimated that the process of getting your data into the appropriate formats takes about 80% of the total time of analysis. We will talk about formatting as tidy data (e.g., such that each column is a single variable, each row is a single observation, and each cell is a single value, you can learn more about tidy data here) in a future session of Code Club.\nThe package dplyr, as part of the tidyverse has a number of very helpful functions that will help you get your data into a format suitable for your analysis.\n What will we go over today\nThese five core dplyr() verbs will help you get wrangling.\n select() - picks variables (i.e., columns) based on their names filter() - picks observations (i.e., rows) based on their values mutate() - makes new variables, keeps existing columns arrange() - sorts rows based on values in columns summarize() - reduces values down to a summary form     2 - Get ready to wrangle Let\u0026rsquo;s get set up and grab some data so that we can get familiar with these verbs\n You can do this locally, or at OSC. You can find instructions if you are having trouble here.  First load your libraries.\nlibrary(tidyverse) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.2 ✔ purrr  0.3.4 #\u0026gt; ✔ tibble  3.0.4 ✔ dplyr  1.0.2 #\u0026gt; ✔ tidyr  1.1.2 ✔ stringr 1.4.0 #\u0026gt; ✔ readr  1.4.0 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag()   Then let\u0026rsquo;s access the iris dataset that comes pre-loaded in base R. We will take that data frame and assign it to a new object called iris_data. Then we will look at our data.\niris_data \u0026lt;- iris # look at the first 6 rows, all columns head(iris_data) #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; 1 5.1 3.5 1.4 0.2 setosa #\u0026gt; 2 4.9 3.0 1.4 0.2 setosa #\u0026gt; 3 4.7 3.2 1.3 0.2 setosa #\u0026gt; 4 4.6 3.1 1.5 0.2 setosa #\u0026gt; 5 5.0 3.6 1.4 0.2 setosa #\u0026gt; 6 5.4 3.9 1.7 0.4 setosa # check the structure of iris_data glimpse(iris_data) #\u0026gt; Rows: 150 #\u0026gt; Columns: 5 #\u0026gt; $ Sepal.Length \u0026lt;dbl\u0026gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4… #\u0026gt; $ Sepal.Width \u0026lt;dbl\u0026gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3… #\u0026gt; $ Petal.Length \u0026lt;dbl\u0026gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1… #\u0026gt; $ Petal.Width \u0026lt;dbl\u0026gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0… #\u0026gt; $ Species \u0026lt;fct\u0026gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, …   This dataset contains the measurements (in cm) of Sepal.Length, Sepal.Width, Petal.Length, and Petal.Width for three different Species of iris, setosa, versicolor, and virginica.\n 3 - Using select() select() allows you to pick certain columns to be included in your data frame.\nWe will create a dew data frame called iris_petals_species that includes the columns Species, Petal.Length and Petal.Width.\niris_petals_species \u0026lt;- iris_data %\u0026gt;% select(Species, Petal.Length, Petal.Width)   What does our new data frame look like?\nhead(iris_petals_species) #\u0026gt; Species Petal.Length Petal.Width #\u0026gt; 1 setosa 1.4 0.2 #\u0026gt; 2 setosa 1.4 0.2 #\u0026gt; 3 setosa 1.3 0.2 #\u0026gt; 4 setosa 1.5 0.2 #\u0026gt; 5 setosa 1.4 0.2 #\u0026gt; 6 setosa 1.7 0.4   Note - look what happened to the order of the columns!\nThis is not the only way to select columns.\nYou could also subset by indexing with the square brackets, but you can see how much more readable using select() is. It\u0026rsquo;s nice not to have to refer back to remember what column is which index.\niris_data_indexing \u0026lt;- iris_data[,3:5] head(iris_data_indexing) #\u0026gt; Petal.Length Petal.Width Species #\u0026gt; 1 1.4 0.2 setosa #\u0026gt; 2 1.4 0.2 setosa #\u0026gt; 3 1.3 0.2 setosa #\u0026gt; 4 1.5 0.2 setosa #\u0026gt; 5 1.4 0.2 setosa #\u0026gt; 6 1.7 0.4 setosa   iris_data_c \u0026lt;- iris_data[,c(\"Petal.Length\", \"Petal.Width\", \"Species\")] head(iris_data_c) #\u0026gt; Petal.Length Petal.Width Species #\u0026gt; 1 1.4 0.2 setosa #\u0026gt; 2 1.4 0.2 setosa #\u0026gt; 3 1.3 0.2 setosa #\u0026gt; 4 1.5 0.2 setosa #\u0026gt; 5 1.4 0.2 setosa #\u0026gt; 6 1.7 0.4 setosa     4 - Using filter()  Artwork by Allison Horst.  filter() allows you to pick certain observations (i.e, rows) based on their values to be included in your data frame.\nWe will create a new data frame that only includes information about the irises where their Species is setosa.\niris_setosa \u0026lt;- iris_data %\u0026gt;% filter(Species == \"setosa\")   Let\u0026rsquo;s check the dimensions of our data frame. Remember, our whole data set is 150 observations, and we are expecting 50 observations per Species.\ndim(iris_setosa) #\u0026gt; [1] 50 5    5 - Using mutate()  Artwork by Allison Horst.  mutate() allows you to make new variables, while keeping all your existing columns.\nLet\u0026rsquo;s make a new column that is the ratio of Sepal.Length/Sepal.Width\niris_sepal_length_to_width \u0026lt;- iris_data %\u0026gt;% mutate(Sepal.Length_div_Sepal.Width = Sepal.Length/Sepal.Width)   head(iris_sepal_length_to_width) #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; 1 5.1 3.5 1.4 0.2 setosa #\u0026gt; 2 4.9 3.0 1.4 0.2 setosa #\u0026gt; 3 4.7 3.2 1.3 0.2 setosa #\u0026gt; 4 4.6 3.1 1.5 0.2 setosa #\u0026gt; 5 5.0 3.6 1.4 0.2 setosa #\u0026gt; 6 5.4 3.9 1.7 0.4 setosa #\u0026gt; Sepal.Length_div_Sepal.Width #\u0026gt; 1 1.457143 #\u0026gt; 2 1.633333 #\u0026gt; 3 1.468750 #\u0026gt; 4 1.483871 #\u0026gt; 5 1.388889 #\u0026gt; 6 1.384615   Note \u0026ndash; see the new column location\n 6 - Using arrange() Very often you will want to order your data frame by some values. To do this, you can use arrange().\nLet\u0026rsquo;s arrange the values in our iris_data by Sepal.Length.\niris_data_sort_Sepal.Length \u0026lt;- iris_data %\u0026gt;% arrange(Sepal.Length) head(iris_data_sort_Sepal.Length) #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; 1 4.3 3.0 1.1 0.1 setosa #\u0026gt; 2 4.4 2.9 1.4 0.2 setosa #\u0026gt; 3 4.4 3.0 1.3 0.2 setosa #\u0026gt; 4 4.4 3.2 1.3 0.2 setosa #\u0026gt; 5 4.5 2.3 1.3 0.3 setosa #\u0026gt; 6 4.6 3.1 1.5 0.2 setosa   What if we want to arrange by Sepal.Length, but within Species? We can do that using the helper group_by().\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% arrange(Sepal.Length) #\u0026gt; # A tibble: 150 x 5 #\u0026gt; # Groups: Species [3] #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt;  #\u0026gt; 1 4.3 3 1.1 0.1 setosa  #\u0026gt; 2 4.4 2.9 1.4 0.2 setosa  #\u0026gt; 3 4.4 3 1.3 0.2 setosa  #\u0026gt; 4 4.4 3.2 1.3 0.2 setosa  #\u0026gt; 5 4.5 2.3 1.3 0.3 setosa  #\u0026gt; 6 4.6 3.1 1.5 0.2 setosa  #\u0026gt; 7 4.6 3.4 1.4 0.3 setosa  #\u0026gt; 8 4.6 3.6 1 0.2 setosa  #\u0026gt; 9 4.6 3.2 1.4 0.2 setosa  #\u0026gt; 10 4.7 3.2 1.3 0.2 setosa  #\u0026gt; # … with 140 more rows    7 - Using summarize() By using summarize(), you can create a new data frame that has the summary output you have requested.\nWe can calculate the mean Sepal.Length across our dataset.\niris_data %\u0026gt;% summarize(mean = mean(Sepal.Length)) #\u0026gt; mean #\u0026gt; 1 5.843333   What if we want to calculate means for each Species?\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% summarize(mean = mean(Sepal.Length)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; Species mean #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 setosa 5.01 #\u0026gt; 2 versicolor 5.94 #\u0026gt; 3 virginica 6.59   We can integrate some helper functions into our code to simply get out a variety of outputs. We can use across() to apply our summary aross a set of columns. I really like this function.\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% summarize(across(where(is.numeric), mean)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 5 #\u0026gt; Species Sepal.Length Sepal.Width Petal.Length Petal.Width #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 setosa 5.01 3.43 1.46 0.246 #\u0026gt; 2 versicolor 5.94 2.77 4.26 1.33  #\u0026gt; 3 virginica 6.59 2.97 5.55 2.03   This can also be useful for counting observations per group. Here, how many iris observations do we have per Species?\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% tally() #\u0026gt; # A tibble: 3 x 2 #\u0026gt; Species n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 setosa 50 #\u0026gt; 2 versicolor 50 #\u0026gt; 3 virginica 50 iris_data %\u0026gt;% count(Species) #\u0026gt; Species n #\u0026gt; 1 setosa 50 #\u0026gt; 2 versicolor 50 #\u0026gt; 3 virginica 50 iris_data %\u0026gt;% group_by(Species) %\u0026gt;% summarize(n = n()) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; Species n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 setosa 50 #\u0026gt; 2 versicolor 50 #\u0026gt; 3 virginica 50    8 - Breakout rooms! Read in data Now you try! We are going to use the Great Backyard Birds dataset we downloaded two weeks ago and you will apply the functions we have learned above to investigate this dataset.\nIf you weren\u0026rsquo;t here for Session 1, get the birds data set.\n# create a directory called S02 dir.create('S02') # within S02, create a directory called data, within, a directory called birds dir.create('data/birds/', recursive = TRUE)   Download the file from the internet.\n# set the location of the file birds_file_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv' # set the path for the downloaded file birds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' # download  download.file(url = birds_file_url, destfile = birds_file)   If you were here for Session 1, join back in! Let\u0026rsquo;s read in our data.\nbirds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' birds \u0026lt;- read_tsv(birds_file) #\u0026gt;  #\u0026gt; ── Column specification ──────────────────────────────────────────────────────── #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; decimalLatitude = col_double(), #\u0026gt; decimalLongitude = col_double(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; range = col_character() #\u0026gt; )   Exercises Below you can find our breakout room exercises for today.\nExercise 1  Investigate the structure of the birds dataset.\n  Solution (click here)  glimpse(birds) #\u0026gt; Rows: 311,441 #\u0026gt; Columns: 12 #\u0026gt; $ class \u0026lt;chr\u0026gt; \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Ave… #\u0026gt; $ order \u0026lt;chr\u0026gt; \"Passeriformes\", \"Passeriformes\", \"Passeriformes\", \"… #\u0026gt; $ family \u0026lt;chr\u0026gt; \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Cor… #\u0026gt; $ genus \u0026lt;chr\u0026gt; \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitt… #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Cyanocitta cristata\", \"Cyanocitta cristata\", \"Cyano… #\u0026gt; $ locality \u0026lt;chr\u0026gt; \"44805 Ashland\", \"45244 Cincinnati\", \"44132 Euclid\",… #\u0026gt; $ stateProvince \u0026lt;chr\u0026gt; \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohi… #\u0026gt; $ decimalLatitude \u0026lt;dbl\u0026gt; 40.86166, 39.10666, 41.60768, 39.24236, 39.28207, 41… #\u0026gt; $ decimalLongitude \u0026lt;dbl\u0026gt; -82.31558, -84.32972, -81.50085, -84.35545, -84.4688… #\u0026gt; $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 200… #\u0026gt; $ species_en \u0026lt;chr\u0026gt; \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blu… #\u0026gt; $ range \u0026lt;chr\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …       Exercise 2  Create a new data frame that removes the column range.\n  Hints (click here)  \nTry using select(). Remember, you can tell select() what you want to keep, and what you want to remove.    Solutions (click here)  birds_no_range \u0026lt;- birds %\u0026gt;% select(-range) head(birds_no_range) #\u0026gt; # A tibble: 6 x 11 #\u0026gt; class order family genus species locality stateProvince decimalLatitude #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Aves Pass… Corvi… Cyan… Cyanoc… 44805 A… Ohio 40.9 #\u0026gt; 2 Aves Pass… Corvi… Cyan… Cyanoc… 45244 C… Ohio 39.1 #\u0026gt; 3 Aves Pass… Corvi… Cyan… Cyanoc… 44132 E… Ohio 41.6 #\u0026gt; 4 Aves Pass… Corvi… Cyan… Cyanoc… 45242 C… Ohio 39.2 #\u0026gt; 5 Aves Pass… Corvi… Cyan… Cyanoc… 45246 C… Ohio 39.3 #\u0026gt; 6 Aves Pass… Corvi… Cyan… Cyanoc… 44484 W… Ohio 41.2 #\u0026gt; # … with 3 more variables: decimalLongitude \u0026lt;dbl\u0026gt;, eventDate \u0026lt;dttm\u0026gt;, #\u0026gt; # species_en \u0026lt;chr\u0026gt;       Exercise 3  How many unique species of birds have been observed?.\n  Hints (click here)  Try using summarize() with a group_by() helper.    Solutions (click here)  # using a combo of group_by() and summarize() unique_birds \u0026lt;- birds %\u0026gt;% group_by(species_en) %\u0026gt;% summarize() #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) dim(unique_birds) # question - are there really 170 different birds observed? take a look at this summary #\u0026gt; [1] 170 1 # a one line, base R approach length(unique(birds$species_en)) #\u0026gt; [1] 170 # another base R approach using distinct() and nrow() birds %\u0026gt;% distinct(species_en) %\u0026gt;% # find distinct occurences nrow() # counts rows #\u0026gt; [1] 170 # using n_distinct() birds %\u0026gt;% summarize(n_distinct(species_en)) #\u0026gt; # A tibble: 1 x 1 #\u0026gt; `n_distinct(species_en)` #\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 170       Exercise 4  How many times have Bald Eagles been observed?.\n  Hints (click here)  Try using filter(). Remember the syntax you need to use to indicate you are looking for a Bald Eagle.    Solutions (click here)  birds_bald_eagle \u0026lt;- birds %\u0026gt;% filter(species_en == \"Bald Eagle\") dim(birds_bald_eagle) #\u0026gt; [1] 381 12       Exercise 5  How many times have any kind of eagle been observed?. Group hint: there are only Bald Eagle and Golden Eagle in this dataset.\n  Hints (click here)  There is a way to denote OR within filter().    More Hints (click here)  You denote OR by using the vertical bar.    Solutions (click here)  birds_alleagles \u0026lt;- birds %\u0026gt;% filter(species_en == \"Bald Eagle\" | species_en == \"Golden Eagle\") dim(birds_alleagles) #\u0026gt; [1] 386 12       Exercise 6  What is the northern most location of the bird observations in Ohio?\n  Hints (click here)  Try using arrange(). You can arrange in both ascending and descending order. You can also use your Ohio knowledge to check if you\u0026rsquo;ve done this correctly.    Solutions (click here)  birds_sort_lat \u0026lt;- birds %\u0026gt;% arrange(-decimalLatitude) head(birds_sort_lat) #\u0026gt; # A tibble: 6 x 12 #\u0026gt; class order family genus species locality stateProvince decimalLatitude #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Aves Pass… Cardi… Card… Cardin… Conneaut Ohio 41.9 #\u0026gt; 2 Aves Pass… Ember… Zono… Zonotr… Conneaut Ohio 41.9 #\u0026gt; 3 Aves Colu… Colum… Zena… Zenaid… Conneaut Ohio 41.9 #\u0026gt; 4 Aves Pici… Picid… Dend… Dendro… Conneaut Ohio 41.9 #\u0026gt; 5 Aves Anse… Anati… Anas Anas p… Conneaut Ohio 41.9 #\u0026gt; 6 Aves Pass… Turdi… Sial… Sialia… Conneaut Ohio 41.9 #\u0026gt; # … with 4 more variables: decimalLongitude \u0026lt;dbl\u0026gt;, eventDate \u0026lt;dttm\u0026gt;, #\u0026gt; # species_en \u0026lt;chr\u0026gt;, range \u0026lt;chr\u0026gt;       Bonus time! Bonus 1  What is the most commonly observed bird in Ohio?\n  Hints (click here)  Try using tally() and a little helper term.\n   Solutions (click here)  unique_birds_tally \u0026lt;- birds %\u0026gt;% group_by(species_en) %\u0026gt;% tally(sort = TRUE) head(unique_birds_tally) #\u0026gt; # A tibble: 6 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Northern Cardinal 23064 #\u0026gt; 2 Mourning Dove 19135 #\u0026gt; 3 Dark-eyed Junco 18203 #\u0026gt; 4 Downy Woodpecker 17196 #\u0026gt; 5 House Sparrow 15939 #\u0026gt; 6 Blue Jay 15611 # another option birds %\u0026gt;% count(species_en, sort = TRUE) #\u0026gt; # A tibble: 170 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Northern Cardinal 23064 #\u0026gt; 2 Mourning Dove 19135 #\u0026gt; 3 Dark-eyed Junco 18203 #\u0026gt; 4 Downy Woodpecker 17196 #\u0026gt; 5 House Sparrow 15939 #\u0026gt; 6 Blue Jay 15611 #\u0026gt; 7 American Goldfinch 14732 #\u0026gt; 8 House Finch 14551 #\u0026gt; 9 Tufted Titmouse 14409 #\u0026gt; 10 Black-capped Chickadee 13471 #\u0026gt; # … with 160 more rows       Bonus 2  What is the least commonly observed bird (or birds) in Ohio?\n  Hints (click here)  Try using the data frame you\u0026rsquo;ve created in the previous exercise.    Solutions (click here)  unique_birds_tally %\u0026gt;% arrange(n) #\u0026gt; # A tibble: 170 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Arctic Redpoll 1 #\u0026gt; 2 Clay-colored Sparrow 1 #\u0026gt; 3 Dickcissel 1 #\u0026gt; 4 Eurasian Wigeon 1 #\u0026gt; 5 Great Egret 1 #\u0026gt; 6 Green Heron 1 #\u0026gt; 7 Grey Partridge 1 #\u0026gt; 8 Harris's Sparrow 1 #\u0026gt; 9 Lesser Yellowlegs 1 #\u0026gt; 10 Lincoln's Sparrow 1 #\u0026gt; # … with 160 more rows # or, if you knew the rarest was those observed only once  unique_birds_tally %\u0026gt;% filter(n == 1) #\u0026gt; # A tibble: 19 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Arctic Redpoll 1 #\u0026gt; 2 Clay-colored Sparrow 1 #\u0026gt; 3 Dickcissel 1 #\u0026gt; 4 Eurasian Wigeon 1 #\u0026gt; 5 Great Egret 1 #\u0026gt; 6 Green Heron 1 #\u0026gt; 7 Grey Partridge 1 #\u0026gt; 8 Harris's Sparrow 1 #\u0026gt; 9 Lesser Yellowlegs 1 #\u0026gt; 10 Lincoln's Sparrow 1 #\u0026gt; 11 Loggerhead Shrike 1 #\u0026gt; 12 Nelson's Sparrow 1 #\u0026gt; 13 Northern Rough-winged Swallow 1 #\u0026gt; 14 Orchard Oriole 1 #\u0026gt; 15 Prairie Falcon 1 #\u0026gt; 16 Red-throated Loon 1 #\u0026gt; 17 Ross's Goose 1 #\u0026gt; 18 Warbling Vireo 1 #\u0026gt; 19 Western Osprey 1       Bonus 3  In what year were the most Bald Eagles observed?\n  Hints (click here)  You may want to convert your date column to a more simplified year-only date. Check out the package lubridate.    Solutions (click here)  library(lubridate) #\u0026gt;  #\u0026gt; Attaching package: 'lubridate' #\u0026gt; The following objects are masked from 'package:base': #\u0026gt;  #\u0026gt; date, intersect, setdiff, union birds_bald_eagle_year \u0026lt;- birds_bald_eagle %\u0026gt;% mutate(year = year(eventDate)) %\u0026gt;% # year() takes a date and outputs only year group_by(year) %\u0026gt;% tally() arrange(birds_bald_eagle_year, -n) #\u0026gt; # A tibble: 11 x 2 #\u0026gt; year n #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 2008 81 #\u0026gt; 2 2006 66 #\u0026gt; 3 2009 58 #\u0026gt; 4 2007 40 #\u0026gt; 5 2005 30 #\u0026gt; 6 2004 26 #\u0026gt; 7 2000 23 #\u0026gt; 8 2001 23 #\u0026gt; 9 2003 15 #\u0026gt; 10 2002 14 #\u0026gt; 11 1999 5      \n","date":1606694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606593313,"objectID":"83eb9b3aa4eba14930c3c05a7e4ad0bc","permalink":"https://biodash.github.io/codeclub/02_dplyr-core-verbs/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/codeclub/02_dplyr-core-verbs/","section":"codeclub","summary":"During this second session of Code Club, we will be learning how to use some of the most popular dplyr one-table functions, including filter, select, mutate, arrange, and summarize.","tags":null,"title":"Session 2: dplyr core verbs","type":"codeclub"},{"authors":["Jelmer Poelstra"],"categories":[],"content":"\n Prep homework Basic computer setup If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions.\nTest if it works Please open RStudio locally or start an OSC RStudio Server session.\nNov 19 addition: If you\u0026rsquo;re working locally, test if you can load the tidyverse package with library(\u0026quot;tidyverse\u0026quot;) inside R. (If you haven\u0026rsquo;t installed the tidyverse yet, please go to the Code Club Computer Setup instructions.)\nIf you have not used RStudio before, take a moment to explore what\u0026rsquo;s in the panels and tabs. (It may help to check out Mike Sovic\u0026rsquo;s 1-minute intro to the RStudio interface or RStudio\u0026rsquo;s 3-minute intro.)\nIf you\u0026rsquo;re able to do so, please open RStudio again a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll troubleshoot.\nNew to R? If you\u0026rsquo;re completely new to R, it will be useful to have a look at some of the resources listed on our New to R? page prior to Code Club.\n Slides On Friday, we started with a couple of introductory slides.\n  1 - Create an RStudio Project Projects are an RStudio-specific concept that create a special file (.Rproj), primarily to designate a directory as the working directory for everything within it. We recommend creating exactly one separate Project for each research project with an R component \u0026ndash; and for things like Code Club.\n Why use Projects?\nIn brief, Projects help you to organize your work and to make it more portable.\n  They record which scripts (and R Markdown files) are open in RStudio, and will reopen all of those when you reopen the project. This becomes quite handy, say, when you work on three different projects, each of which uses a number of scripts.\n  When using Projects, you generally don\u0026rsquo;t have to manually set your working directory, and can use relative file paths to refer to files within the project. This way, even if you move the project directory, or copy it to a different computer, the same paths will still work. (This would not be the case if you used setwd() which will generally require you to use an absolute path, e.g. setwd(\u0026quot;C:/Users/Jelmer/Documents/\u0026quot;).)\n  Projects encourage you to organize research projects inside self-contained directories, rather than with files spread around your computer. This can save you a lot of headaches and increases reproducibility. And because R will restart whenever you switch Projects, there is no risk of unwanted cross-talk between your projects.\n    Let\u0026rsquo;s create an RStudio Project for Code Club:\n  Open RStudio locally or start an OSC RStudio Server session.\n(If you\u0026rsquo;re at OSC, you should see a file 0_CODECLUB.md that\u0026rsquo;s open in your top-left panel. You can ignore/close this file.)\n  If you\u0026rsquo;re working locally, create a directory wherever you like on your computer for all things Code Club. You can do this in R using dir.create(\u0026quot;path/to/your/dir\u0026quot;), or outside of R.\n(If you\u0026rsquo;re at OSC, skip this step because you\u0026rsquo;re automatically inside a Code Club-specific, personal directory.)\n  Click File (top menu bar) \u0026gt; New Project, and then select Existing Directory.\n  If you\u0026rsquo;re working locally, select the Code Club directory that you created in the previous step.\n  If you\u0026rsquo;re working at OSC, keep the default choice \u0026ldquo;~\u0026rdquo; (i.e., home), which is the directory you started in when entering the RStudio Server session.\n    After RStudio automatically reloads, you should see the file ending in .Rproj in the RStudio Files tab in the lower right pane, and you will have the Project open. All done for now!\n  (For future Code Club sessions: RStudio will by default reopen the most recently used Project, and therefore, OSC users will have the Project automatically opened. If you\u0026rsquo;re working locally and are also using other Projects, you can open this Project with File \u0026gt; Open Project inside RStudio, or by clicking the .Rproj file in your file browser, which will open RStudio and the Project.)\n 2 - Orienting ourselves Where are we? We don\u0026rsquo;t need to set our working directory, because our newly created Project is open, and therefore, our working directory is the directory that contains the .Rproj file.\nTo see where you are, type or copy into the console (bottom left):\n# Print the working directory: getwd() # List the files in your current directory: dir() # This should print at least the `.RProj` file.   Create directories Create two new directories \u0026ndash; one for this session, and one for a dataset that we will download shortly (and will be reusing across sessions):\n# Dir for Code Club Session 1: dir.create(\"S01\") # Dir for our bird data: # (\"recursive\" to create two levels at once.) dir.create(\"data/birds/\", recursive = TRUE)   Create a script To keep a record of what we are doing, and to easily modify and rerun earlier commands, we\u0026rsquo;ll want to save our commands in a script and execute them from there, rather than typing our commands directly in the console.\n  Click File (top menu bar) \u0026gt; New File \u0026gt; R script.\n  Save the script (File \u0026gt; Save) as S01.R inside your S01 directory.\n  First line of the script We will now load the core set of 8 tidyverse packages all at once. To do so, type/copy the command below on the first line of the script, and then execute it by clicking Run (top right of script pane) or by pressing Ctrl Enter (Windows/Linux, this should also work in your browser) or ⌘ Enter (Mac).\n# If you're working locally, and did not install it yet: # install.packages(\"tidyverse\") # Load the tidyverse (meta)package: library(tidyverse) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.2 ✔ purrr  0.3.4 #\u0026gt; ✔ tibble  3.0.4 ✔ dplyr  1.0.2 #\u0026gt; ✔ tidyr  1.1.2 ✔ stringr 1.4.0 #\u0026gt; ✔ readr  1.3.1 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag()   If this worked, you should get the same output as shown in the code block above: it attached 8 packages, and it warns that some of its functions are now \u0026ldquo;masking\u0026rdquo; base R functions.\n The tidyverse is a very popular and useful ecosystem of R packages for data analysis, which we will be using a lot in Code Club.\nWhen we refer to \u0026ldquo;base R\u0026rdquo; as opposed to the tidyverse, we mean functions that are loaded in R by default (without loading a package), and that can perform similar operations in a different way.\n   3 - Getting our dataset We downloaded a Great Backyard Bird Count (GBBC) dataset from the Global Biodiversity Information Facility (GBIF). Because the file was 3.1 GB large, we selected only the records from Ohio and removed some uninformative columns. We also added columns with English names and the breeding range for each species. We\u0026rsquo;ll download the resulting much smaller file (41.5 MB) from our Github repo.\n The Great Backyard Bird Count The GBBC is an annual citizen science event where everyone is encouraged to to identify and count birds in their backyard \u0026ndash; or anywhere else \u0026ndash; for at least 15 minutes, and report their sightings online. Since 2013, it is a global event, but it has been organized in the US and Canada since 1998.\n  Download the data Let\u0026rsquo;s download the dataset using the download.file() function:\n# The URL to our file: birds_file_url \u0026lt;- \"https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv\" # The path to the file we want to download to: birds_file \u0026lt;- \"data/birds/backyard-birds_Ohio.tsv\" # Download: download.file(url = birds_file_url, destfile = birds_file)   Read the data Now, let\u0026rsquo;s read the file into R. The .tsv extension (\u0026ldquo;tab-separated values\u0026rdquo;) tells us this is a plain text file in which columns are separated by tabs, so we will use a convenience function from the readr package (which is loaded as part of the core set tidyverse packages) for exactly this type of file:\n# Read the data: birds \u0026lt;- read_tsv(file = birds_file) #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; decimalLatitude = col_double(), #\u0026gt; decimalLongitude = col_double(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; range = col_character() #\u0026gt; )   Done! We have now read our data into a tibble, which is a type of data frame (formally a data.frame): R\u0026rsquo;s object class to deal with tabular data wherein each column can contain a different type of data (numeric, characters/strings, etc).\n 4 - Exploring backyard birds Exercise 1 What\u0026rsquo;s in the dataset?\n  Explore the dataset using some functions and methods you may know to get a quick overview of data(frames), and try to understand what you see. What does a single row represent, and what is in each column? (Be sure to check out the hints below at some point, especially if you\u0026rsquo;re stuck.)\n  Pay attention to the data types (e.g., \u0026ldquo;character\u0026rdquo; or chr) of the different columns, which several of these functions print. The output of our read_tsv() command also printed this information \u0026ndash; this function parsed our columns as the types we see now. Were all the columns parsed correctly?\n  How many rows and how many columns does the dataset have?\n  What are some questions you would like to explore with this dataset? We\u0026rsquo;ll collect some of these and try to answer them in later sessions. If your group has sufficient R skills already, you are also welcome to go ahead and try to answer one or more of these questions.\n    Hints (click here)  # Type an object's name to print it to screen: birds # Same as above, but explicitly calling print(): print(birds) # For column-wise information (short for \"structure\"): str(birds) # tidyverse version of str(): glimpse(birds) # In RStudio, open object in a separate tab: View(birds)     Note that in R, dbl (for \u0026ldquo;double\u0026rdquo;) and num (for \u0026ldquo;numeric\u0026rdquo;) are both used, and almost interchangeably so, for floating point numbers. (Integers are a separate type that are simply called \u0026ldquo;integers\u0026rdquo; and abbreviated as int, but we have no integer columns in this dataset.)\n  read_tsv() parsed our date as a \u0026ldquo;date-time\u0026rdquo; (dttm or POSIXct for short), which contains both a date and a time. In our case, it looks like the time is always \u0026ldquo;00:00:00\u0026rdquo; and thus doesn\u0026rsquo;t provide any information.\n     Solutions (click here)  # Just printing the glimpse() output, # which will show the number of rows and columns: glimpse(birds) #\u0026gt; Rows: 311,441 #\u0026gt; Columns: 12 #\u0026gt; $ class \u0026lt;chr\u0026gt; \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Ave… #\u0026gt; $ order \u0026lt;chr\u0026gt; \"Passeriformes\", \"Passeriformes\", \"Passeriformes\", \"… #\u0026gt; $ family \u0026lt;chr\u0026gt; \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Cor… #\u0026gt; $ genus \u0026lt;chr\u0026gt; \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitt… #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Cyanocitta cristata\", \"Cyanocitta cristata\", \"Cyano… #\u0026gt; $ locality \u0026lt;chr\u0026gt; \"44805 Ashland\", \"45244 Cincinnati\", \"44132 Euclid\",… #\u0026gt; $ stateProvince \u0026lt;chr\u0026gt; \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohi… #\u0026gt; $ decimalLatitude \u0026lt;dbl\u0026gt; 40.86166, 39.10666, 41.60768, 39.24236, 39.28207, 41… #\u0026gt; $ decimalLongitude \u0026lt;dbl\u0026gt; -82.31558, -84.32972, -81.50085, -84.35545, -84.4688… #\u0026gt; $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 200… #\u0026gt; $ species_en \u0026lt;chr\u0026gt; \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blu… #\u0026gt; $ range \u0026lt;chr\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …   # You can also check the number of rows and columns directly using: dim(birds) # Will return the number of rows and columns #\u0026gt; [1] 311441 12 nrow(birds) # Will return the number of rows #\u0026gt; [1] 311441 ncol(birds) # Will return the number of columns #\u0026gt; [1] 12     \n  Bonus material If your breakout group is done with Exercise 1, you can have a look at the bonus material below which includes another exercise. You can also have a look at this as homework. Or not at all!\n readr options for challenging files Earlier, we successfully read in our file without specifying any arguments other than the file name to the read_tsv() function, i.e. with all the default options. It is not always this easy!\nSome options for more complex cases:\n  The more general counterpart of this function is read_delim(), which allows you to specify the delimiter using the sep argument, e.g. delim=\u0026quot;\\t\u0026quot; for tabs.\n  There are also arguments to these functions for when you need to skip lines, when you don\u0026rsquo;t have column headers, when you need to specify the column types of some or all the columns, and so forth \u0026ndash; see this example:\nmy_df \u0026lt;- read_delim( file = \"file.txt\", delim = \"\\t\", # Specify tab as delimiter col_names = FALSE, # First line is not a header skip = 3, # Skip the first three lines comment = \"#\", # Skip any line beginning with a \"#\" col_types = cols( # Specify column types col1 = col_character(), # ..We only need to specify columns for  col2 = col_double() # ..which we need non-automatic typing ) )       Exercise 2 (Optional) Read this file!\nTry to read the following file into R, which is a modified and much smaller version of the bird dataset.\nMake the function parse the \u0026ldquo;order\u0026rdquo; column as a factor, and the \u0026ldquo;year\u0026rdquo;, \u0026ldquo;month\u0026rdquo;, and \u0026ldquo;day\u0026rdquo; columns as whatever you think is sensible.\n# Download and read the file: birds2_file_url \u0026lt;- \"https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_read-challenge.txt\" birds2_file \u0026lt;- \"data/birds/backyard-birds_read-challenge.txt\" download.file(url = birds2_file_url, destfile = birds2_file)   # Your turn! birds2 \u0026lt;- read_ # Complete the command     Hints (click here)    The file is saved as .txt, so the delimiter is not obvious \u0026ndash; first have a look at it (open it in RStudio, a text editor, or the terminal) to determine the delimiter. Then, use read_delim() with manual specification of the delimiter using the delim argument, or use a specialized convenience function.\n  Besides a leading line with no data, there is another problematic line further down. You will need both the skip and comment arguments to circumvent these.\n  Note that readr erroneously parses month as a character column if you don\u0026rsquo;t manually specify its type.\n  Note that you can also use a succinct column type specification like col_types = \u0026quot;fc\u0026quot;, which would parse, for a two-column file, the first column as a factor and the second as a character \u0026ndash; type e.g. ?read_tsv for details.\n     Bare solution (click here)  # With succint column type specification: birds2 \u0026lt;- read_csv( file = birds2_file, skip = 1, comment = \"$\", col_types = \"fcdiii\" ) # With long column type specification: birds2 \u0026lt;- read_csv( file = birds2_file, skip = 1, comment = \"$\", col_types = cols( order = col_factor(), year = col_integer(), month = col_integer(), day = col_integer() ) )      Solution with explanations (click here)  # With succinct column type specification: birds2 \u0026lt;- read_csv( # `read_csv()`: file is comma-delimited file = birds2_file, skip = 1, # First line is not part of the dataframe comment = \"$\", # Line 228 is a comment that starts with `$` col_types = \"fcdiii\" # \"f\" for factor, \"c\" for character, ) # ..\"d\" for double (=numeric), # ..\"i\" for integer. # With long column type specification: birds2 \u0026lt;- read_csv( file = birds2_file, skip = 1, comment = \"$\", col_types = cols( # We can omit columns for which we order = col_factor(), # ..accept the automatic parsing, year = col_integer(), # ..when using the long specification.  month = col_integer(), day = col_integer() ) )      Other options for reading tabular data There are also functions in base R that read tabular data, such as read.table() and read.delim().\nThese are generally slower than the readr functions, and have less sensible default options to their arguments. Particularly relevant is how columns with characters (strings) are parsed \u0026ndash; until R 4.0, which was released earlier this year, base R\u0026rsquo;s default behavior was to parse them as factors, and this is generally not desirable1. readr functions will never convert columns with strings to factors.\nIf speed is important, such as when reading in very large files (~ 100s of MBs or larger), you should consider using the fread() function from the data.table package.\nFinally, some examples of reading other types of files:\n Read excel files directly using the readxl package. Read Google Sheets directly from the web using the googlesheets4 package. Read non-tabular data using the base R readLines() function.    \n  You can check which version of R you are running by typing sessionInfo(). You can also check directly how strings are read by default with default.stringsAsFactors(). To avoid conversion to factors, specify stringsAsFactors = FALSE in your read.table() / read.delim() function call. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1604448000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605969915,"objectID":"5b8cbf273e25c833a3e7f4cd2615654b","permalink":"https://biodash.github.io/codeclub/01_backyard-birds/","publishdate":"2020-11-04T00:00:00Z","relpermalink":"/codeclub/01_backyard-birds/","section":"codeclub","summary":"In the first session of Code Club, we'll make sure that everyone is properly set up, create an RStudio Project, and start working with some data from the Great Backyard Bird Count.","tags":["codeclub","backyard-birds"],"title":"Session 1: Backyard Birds","type":"codeclub"},{"authors":["Jelmer Poelstra","Mike Sovic","Stephen Opiyo","Michael Broe","Jessica Cooperstone"],"categories":[],"content":" Welcome to OSU Code Club! Materials for each episode will be provided in posts like this one, collected in the Code Club Sessions page.\n  For more information about OSU Code Club, and a form to sign up, see the About Code Club page.\n  For info on upcoming sessions, see here.\n  You can code locally or in your browser, see our page with computer setup instructions.\n  If you are completely new to R, see our page with resources and tips.\n  You can also suggest a topic to be covered at Code Club.\n   \n","date":1603065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604625794,"objectID":"fa58e17bb7648ba3c1d43d18ecb64a3a","permalink":"https://biodash.github.io/codeclub/00_welcome-to-codeclub/","publishdate":"2020-10-19T00:00:00Z","relpermalink":"/codeclub/00_welcome-to-codeclub/","section":"codeclub","summary":"Welcome to OSU Code Club! In this brief post, we point you to information related to Code Club on the website.","tags":["codeclub"],"title":"Welcome to Code Club","type":"codeclub"},{"authors":null,"categories":null,"content":"All material is released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","date":1578092400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601687264,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"https://biodash.github.io/license/","publishdate":"2020-01-04T00:00:00+01:00","relpermalink":"/license/","section":"","summary":"All material is released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616606334,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://biodash.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"About OSU Code Club   Code Club restarts for the fall '21 semester on Thursday August 26th \u0026ndash; see the schedule. If you're interested in joining us, please fill out the form at the bottom of this page!   OSU Code Club is a regularly occurring, interactive, online gathering to improve coding skills. We aim for a supportive and fun culture of learning together, and hope to offer something to participants at any experience level.\nIn each meeting, a presenter first introduces a concept or tool to be used for a challenge. Then, we work on the challenge in pairs or trios in Zoom \u0026ldquo;breakout rooms,\u0026rdquo; and finally, we reconvene to see what approaches were taken and to share lessons learned.\nThe idea for this Code Club was taken from a recent paper in PLoS Computational Biology: Ten simple rules to increase computational skills among biologists with Code Clubs. We liked this idea because of the high level of interaction and because gradual, well-spaced practice is an excellent way to retain what you learn.\nJoin us \u0026mdash; and perhaps present a session too! As the organizers, we are happy to present sessions, but we hope that as a participant, you will also want to do so.\nFor example, you could consult the group about an actual challenge you are facing in your data analysis. You could also introduce everyone to an new package or approach you\u0026rsquo;ve been using, or one that you are excited about and want to dive into \u0026ndash; teaching a topic can be one of the best ways to learn it!\n Practical information  In the first series, we will focus on all things R: from data analysis and visualization to efficient coding, R Markdown, and so on. There will be no consistent analysis type or data type \u0026mdash; instead, we will focus on building general skills and applying those to a wide variety of data. Each week, materials and suggested reading will be posted up front at the Sessions page. Like at a Journal Club, doing some preparatory homework by reading these materials will help you get the most out of it. Each session is intended to be mostly stand-alone to allow for occasional participation. To allow for a welcoming environment for participants at all levels of experience, we ask everyone to be respectful, patient, and collaborative when interacting at Code Club. This is not a competitive event. We have a separate page with computer setup instructions, where you\u0026rsquo;ll see that we also accommodate participating through your browser without any installations. We also have a form to suggest topics for Code Club!   Organizers  Jelmer Poelstra - bioinformatician at MCIC Wooster Mike Sovic - bioinformatician at CAPS Stephen Opiyo - biostatistician at MCIC Columbus Michael Broe - bioinformatician at EEOB Jessica Cooperstone - Asst. Professor at HCS \u0026amp; FST   Sign up To sign up, please fill out the Google Form below. Hope to see you at Code Club!\nLoading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628701896,"objectID":"affd8a75456abca4d01de73213cffddb","permalink":"https://biodash.github.io/codeclub-about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-about/","section":"","summary":"About OSU Code Club   Code Club restarts for the fall '21 semester on Thursday August 26th \u0026ndash; see the schedule. If you're interested in joining us, please fill out the form at the bottom of this page!","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Other Events  On this page, we will list upcoming events related to computational biology, coding, and data analysis. If you know of an event that you think should be listed here, please use the form in the About page.\n Calendar   Recurring Events  CAPS Tn-seq working group  A working group dedicated to the analysis of Transposon-seq (Tn-seq) data. Every Monday from 10-11 am. Contact Mike Sovic for details.     MCIC bioinformatics office hour  Need some quick advice or help? Drop by! Every Tuesday from 2-4 pm: Zoom link. Advance notice to Jelmer Poelstra is appreciated. Anyone at OSU is welcome, and if you\u0026rsquo;re outside of OSU, feel free to inquire.     Center of Microbiome Center working groups  CoMS is running Virome, Microbiome, and Advanced Ecological Statistics working groups, see their page for more details.     Spring \u0026lsquo;21 Course: Practical Computing Skills for Biologists Jelmer Poelstra will teach a computing course as a section of PlantPath 8300 in the \u0026lsquo;21 spring semester.\n Focused on the command line, bash and Python scripting, and reproducible science with version control and automated workflows. 14 weeks, 2 credits, online-only Zoom sessions on Tuesdays and Thursdays from 3:55-4:55 pm. Graduate level, but undergraduates may be eligible to take the course as an IS. Sign up for class number 35953. Contact Jelmer for more information and a syllabus.   Upcoming Workshops None right now!\n Upcoming Outside of OSU  For Ohio Supercomputer Center events, such as regular introductory sessions to computing at OSC, see the OSC Events page.   Misc. Relevant OSU Courses  M5161: Introduction to Computational Genomics M8161: Microbiome Informatics PLNTPTH 7003.01: Agricultural Genomics: Principles and Applications HCS 7806: Current Topics and Methods Courses  Includes \u0026ldquo;Genome Analytics\u0026rdquo; and \u0026ldquo;Methods in Data Visualization\u0026rdquo;.   ENR8600: Introduction to R for Environmental Sciences MOLGEN 5645: Quantitative, Population, and Evolutionary Genetics MOLGEN 5623: Genetics and Genomics STAT 6625: Statistical Analysis of Genetic Data STAT 6730: Introduction to Computational Statistics FDSCTE 7600: Metabolomics, Principles and Practice   Past Events TBA\n  \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629301688,"objectID":"426d522fcb82973f95d828bcc08f03ff","permalink":"https://biodash.github.io/events/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/events/","section":"","summary":"Other Events  On this page, we will list upcoming events related to computational biology, coding, and data analysis. If you know of an event that you think should be listed here, please use the form in the About page.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Material  Here, we will post tutorials, analysis pipelines, instructional videos, slidedecks, materials from past workshops, and so on.\n  MCIC/MCBL\u0026rsquo;s Read-the-Docs site with tutorials.\n  CAPS/Mike Sovic\u0026rsquo;s Youtube Channel.\n  Slides from RNA-seq intro meetings, Jan-Feb 2021.\n    \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613140153,"objectID":"4f38a30d7b59cc95eec7edb025f56bf6","permalink":"https://biodash.github.io/material/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/material/","section":"","summary":"Material  Here, we will post tutorials, analysis pipelines, instructional videos, slidedecks, materials from past workshops, and so on.\n  MCIC/MCBL\u0026rsquo;s Read-the-Docs site with tutorials.\n  CAPS/Mike Sovic\u0026rsquo;s Youtube Channel.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Suggest a topic or event  If there is a topic you would like to see covered on this website, an event you would like to see happen, or an event you think should be listed under Events, please fill out the form below. You can also indicate whether you would like to help with this content or event!\nLoading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605479556,"objectID":"ec134bd5815c50401fba8e9a987eda12","permalink":"https://biodash.github.io/suggest/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/suggest/","section":"","summary":"Suggest a topic or event  If there is a topic you would like to see covered on this website, an event you would like to see happen, or an event you think should be listed under Events, please fill out the form below.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Bioinformatics support  Available support Need assistance with bioinformatics, high-throughput sequencing data analysis, working with big data, etc? See below for a list of support options for OSU researchers\u0026hellip;\nMCIC The Molecular and Cellular Imaging Center (MCIC) is an OSU core facility with locations at the Wooster and Columbus campuses. Among other things, the MCIC provides end-to-end support for genomics projects \u0026mdash; from experimental design, library preparation, and sequencing, to infrastructure for and assistance with data analysis.\nThe bioinformatics section of the MCIC, the MCBL (MCIC Computational Biology Laboratory), works based on a membership model. MCBL members have access to bioinformatics support, our project at the Ohio Supercomputer Center for storage and computing, our two in-house servers, our computer lab in Wooster, and free access to workshops. To become a member, please fill out this form.\nFor bioinformatics consultation, anyone is free to contact Jelmer Poelstra or drop by at the Bioinformatics Office Hour over Zoom every Tuesday between 2 and 4 pm (Zoom link - advance notice is appreciated!).\nCAPS The Center for Applied Plant Sciences (CAPS) supports OSU researchers working in the plant sciences. CAPS research scientist Mike Sovic leads bioinformatic support efforts for the Center. Details on opportunities and resources available through CAPS are at http://caps.osu.edu/bioinformatics.\nEEOB Research Scientist Michael Broe provides bioinformatics support to faculty and students in the Department of Evolution, Ecology and Organismal Biology. His primary role is to assist graduate students learning various types of computational analysis, but he also works directly with PIs. Types of analysis include whole genome assembly, genome annotation, transcriptomics, RADseq, hybrid capture pipelines, variant calling etc. Michael also teaches a 7 week Introduction to Computation in Biology for incoming EEOB graduate students each year, covering R, Python, and Unix.\n Request support Loading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605742851,"objectID":"6f03e42d6bae7b75ea525bec87eb719f","permalink":"https://biodash.github.io/support/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/support/","section":"","summary":"Bioinformatics support  Available support Need assistance with bioinformatics, high-throughput sequencing data analysis, working with big data, etc? See below for a list of support options for OSU researchers\u0026hellip;\nMCIC The Molecular and Cellular Imaging Center (MCIC) is an OSU core facility with locations at the Wooster and Columbus campuses.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"An introduction to RNA-seq data processing and analysis     Date Topic Slides     2021-01-08 Introductory notes on RNA-seq and NGS data    2021-01-29 Running FastQC for many files at OSC    2021-02-05 Interpreting FastQC output    2021-02-12 Running MultiQC    2021-02-17 Preprocessing FASTQ files    2021-02-17 Intro to RNAseq alignment and STAR    2021-02-26 RNAseq read alignment with STAR    2021-03-05 Getting to know BAM files    2021-03-12/19 Creating a gene count table with feautureCounts    2021-03-26 Differential expression analysis with DESeq2 \u0026ndash; Part I       \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629301395,"objectID":"55d204a66b59da84421ea7308e9df8ba","permalink":"https://biodash.github.io/tutorials/2021-01_rnaseq/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tutorials/2021-01_rnaseq/","section":"tutorials","summary":"An introduction to RNA-seq data processing and analysis     Date Topic Slides     2021-01-08 Introductory notes on RNA-seq and NGS data    2021-01-29 Running FastQC for many files at OSC    2021-02-05 Interpreting FastQC output    2021-02-12 Running MultiQC    2021-02-17 Preprocessing FASTQ files    2021-02-17 Intro to RNAseq alignment and STAR    2021-02-26 RNAseq read alignment with STAR    2021-03-05 Getting to know BAM files    2021-03-12/19 Creating a gene count table with feautureCounts    2021-03-26 Differential expression analysis with DESeq2 \u0026ndash; Part I","tags":null,"title":"","type":"tutorials"},{"authors":null,"categories":null,"content":"\nThe BioDASH website aims to assemble bioinformatic and computational training resources for researchers at The Ohio State University. It\u0026rsquo;s a joint initiative by bioinformaticians at OSU\u0026rsquo;s Molecular and Cellular Imaging Center (MCIC) - Computational Biology Lab, the Center for Applied Plant Sciences (CAPS), and the Department of Evolution, Ecology and Organismal Biology (EEOB).\nMain Contributors   Jelmer Poelstra, MCIC Wooster\n  Mike Sovic, CAPS\n  Michael Broe, EEOB\n  Suggest a topic or event If there is a topic you would like to see covered on this website, an OSU event you would like to see happen, or an event you think should be listed under Events, please fill out the form below. You can also indicate whether you would like to help with this content or event!\nLoading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629301608,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://biodash.github.io/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"The BioDASH website aims to assemble bioinformatic and computational training resources for researchers at The Ohio State University. It\u0026rsquo;s a joint initiative by bioinformaticians at OSU\u0026rsquo;s Molecular and Cellular Imaging Center (MCIC) - Computational Biology Lab, the Center for Applied Plant Sciences (CAPS), and the Department of Evolution, Ecology and Organismal Biology (EEOB).","tags":null,"title":"About the BioDASH website","type":"page"},{"authors":null,"categories":null,"content":" Here, you will find general information on computer setup for Code Club. Additional setup instructions for individual sessions will appear in the posts for each session.\nSummary   You can work in your browser at the Ohio Supercomputer Center (OSC) or you can work with local software installations.\n  If you plan to work at OSC:\n  You should receive an email from OSC that you have been added to the Code Club OSC project. Follow the instructions from that email, including to sign up for an OSC account itself if you don\u0026rsquo;t have one.\n  Test if you can start an RStudio Server session at OSC OnDemand, and optionally test if you can load the tidyverse package.\n    If you plan to work with local software installations:\n  Install R and RStudio. (If you already have R but a version below R 3.6, then update R.)\n  Optionally, install the tidyverse package and test if you can load it.\n    Run into issues or have questions? Don\u0026rsquo;t hesitate to contact Jelmer or one of the other organizers. You can also join the Code Club Zoom call 15 minutes early, and one or more of the organizers will be on there already.\n   Option 1 \u0026ndash; OSC All Code Club participants will get access to the Ohio Supercomputer Center (OSC) Classroom Project for Code Club (PAS1838). This way, you can code in RStudio from your browser rather than with a local installation. This is a good option if you prefer not to install anything or if you run into problems during installations.\nAfter signing up for Code Club, you should receive an email from OSC that you have been added to the Code Club OSC project.\n  If you already have an OSC account, you shouldn\u0026rsquo;t need to do anything to gain access, although the email may ask you to confirm/accept your being added to project.\n  If you do not yet have an OSC account, the email you received from OSC should have a link to do so. Alternatively, follow the instructions below to sign up and get access to the project.\n  Instructions to sign up at OSC (click here)  To sign up:\n  Go to https://my.osc.edu/ and click the blue \u0026ldquo;Sign Up\u0026rdquo; bar.\n  In the bottom right portion of the form where you provide your info (see screenshot below), you should enter Code Club\u0026rsquo;s Project Code, which is PAS1838. If you want to use OSC, please do this on a day prior to your first Code Club participation. This way, there is time to troubleshoot if needed. Moreover, the Code Club option on the Interactive Apps page below can take a few hours to appear after you become a member of the project.\n    Enter Project Code PAS1838 in the red box (click to enlarge)     Run RStudio Server from the OSC website OSC OnDemand lets you access OSC resources through your browser and run applications like RStudio. It has a separate access point, https://class.osc.edu/, for \u0026ldquo;classroom projects\u0026rdquo; such as this one.\n  To get started, go to https://class.osc.edu/ and log in with your OSC username and password.\n  Click on Apps in the blue top bar, and select RStudio Server: Form, as shown below:\n     Now, you\u0026rsquo;re on a page from which you can launch an RStudio server that will run on an OSC cluster. As shown below, make sure that \u0026ldquo;Code Club\u0026rdquo; is selected under Class Materials, and change the select Number of hours to 2. Then click Launch.\n    You should see a box like this:\n    Your job usually starts running within seconds, and the color of the top bar will then switch from blue (\u0026ldquo;Queued\u0026rdquo; and then \u0026ldquo;Starting\u0026rdquo;) to green (\u0026ldquo;Running\u0026rdquo;):\n    Click Connect to RStudio Server at the bottom of the box, and an RStudio Server instance will open.\n  Test whether you can load the tidyverse (optional) Several commonly used packages will be automatically available to you at OSC, and that should include the tidyverse. Test whether you can load the tidyverse by running library(tidyverse), and check whether you get output similar to what is shown below:\nlibrary(tidyverse) #\u0026gt; ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ── #\u0026gt; ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 #\u0026gt; ✓ tibble 3.1.3 ✓ dplyr 1.0.7 #\u0026gt; ✓ tidyr 1.1.3 ✓ stringr 1.4.0 #\u0026gt; ✓ readr 2.0.1 ✓ forcats 0.5.1 #\u0026gt; ── Conflicts ───────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; x dplyr::filter() masks stats::filter() #\u0026gt; x dplyr::lag() masks stats::lag() If you get an error, install the tidyverse as follows:\ninstall.packages(\u0026#34;tidyverse\u0026#34;) More about OSC The above instructions should be all you need to access RStudio using OSC, but there is lot more to OSC than that! For more information about using OSC, see the excellent Getting Started materials on their website (make sure not to miss the HOWTOs). Also, Mike Sovic has a YouTube playlist \u0026ldquo;Getting Started With High Performance Computing (HPC)\u0026quot; at his channel The Data Point.\n Option 2 \u0026ndash; Local installation  Already have R installed?   Please check your version of R, and update if it is below version 3.6.\nSee this page for instructions.\n  Make sure you have installed the tidyverse package.\n    Install R  Windows: Download and run the .exe file for the latest version of R from https://cran.r-project.org/bin/windows/base/, by clicking the large Download R [version-number] for Windows link at the top of the gray box. Mac: Download and run the .pkg file for the latest version of R from https://cran.r-project.org/bin/macosx/, by clicking the link just below Latest release. On a Linux distribution, you can also install R using the website above, but you may prefer to use a package manager instead \u0026ndash; for instance, seee these instructions for installing the latest R version on Ubuntu 20.04 using the apt package manager.  Install RStudio RStudio is a so-called Integrated Development Environment (IDE) for R, with side-by-side panes for an R script, an R concole, plots, help documents, and much more. While it is perfectly possible to use R without RStudio, RStudio has become the de facto standard for working with R and is very useful.\nTo install RStudio, go to the RStudio download page and download and run the installer file for your operating system.\nInstall the tidyverse (optional) To install or update the tidyverse, which is a collection of useful R packages, copy the following command into an R console, and press Enter:\ninstall.packages(\u0026#34;tidyverse\u0026#34;) Test whether you can load the tidyverse (optional) When you issue the command library(tidyverse) in your R console inside RStudio, you should get output similar to what is shown below:\nlibrary(tidyverse) #\u0026gt; ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.1 ── #\u0026gt; ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 #\u0026gt; ✓ tibble 3.1.3 ✓ dplyr 1.0.7 #\u0026gt; ✓ tidyr 1.1.3 ✓ stringr 1.4.0 #\u0026gt; ✓ readr 2.0.1 ✓ forcats 0.5.1 #\u0026gt; ── Conflicts ───────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; x dplyr::filter() masks stats::filter() #\u0026gt; x dplyr::lag() masks stats::lag() If you get an error instead, please try to troubleshoot it by following any instructions given, or by Googling the error message. It may be necessary to update R itself, see here for instructions. You can also send the organizers of Code Club an email.\n More info Please see our R Resources and Tips page for:\n Resources to get started with R Useful R and RStudio settings The basics of installing packages in R Instructions for updating R    \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629937637,"objectID":"a19fd71e3dc86af820a45dabc994dda5","permalink":"https://biodash.github.io/codeclub-setup/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-setup/","section":"","summary":"Here, you will find general information on computer setup for Code Club. Additional setup instructions for individual sessions will appear in the posts for each session.\nSummary   You can work in your browser at the Ohio Supercomputer Center (OSC) or you can work with local software installations.","tags":null,"title":"Computer Setup for Code Club","type":"page"},{"authors":null,"categories":null,"content":" Introduction   Each Code Club session should be represented by one post on the website at https://biodash.github.io/codeclub/.\n  Regular presenters will be given direct access to the Github repository and will be able to push a new post to the website directly.\n  Occasional presenters can either send their material directly to Jelmer or create a \u0026ldquo;pull request\u0026rdquo; with their new post.\n  Content should be written in R Markdown (.Rmd) or \u0026ldquo;plain\u0026rdquo; Markdown (.md). If you write in .Rmd, you need to render to .md locally. Conversion of .md to an HTML file suitable for the website will be done automatically upon pushing the master branch of the repository.\n  Make sure to get the session materials onto the website at least several days before the session.\n   Getting your files onto the site 1: Get the repo You only need to do this if you want to create a pull request or push your content to the website directly. If you want to send your (R) Markdown file by email, skip this and continue to Step 2.\nThe following assumes you have git installed, set up, have a Github account, and have your git linked up to Github.\nOption A: Fork the repo to prep for a Pull Request   Fork the repo: go to https://github.com/biodash/biodash.github.io and click the Fork button way in the top-right corner of the page.\n  Get the URL for your repo: In your forked repo, click the green Code button and copy the URL for the repo to your clipboard (either the HTTPS or the SSH URL; the former will be less likely to lead to authentication problems).\n  Go to a dir that you would like to be the parent dir of the Biodash/Codeclub repo:\ncd my-dir   Clone your forked repo, using the URL that you copied to your clipboard:\ngit clone https://github.com/\u0026lt;YOUR-USERNAME\u0026gt;/biodash.github.io.git   Move into the newly cloned (downloaded) repository dir:\ncd biodash.github.io   Add the original repository as an \u0026ldquo;upstream\u0026rdquo; remote:\ngit remote add upstream https://github.com/biodash/biodash.github.io.git  You can check which remote repos (i.e., repos on Github) are linked to your local repo using:\ngit remote -v This should show your forked repo as \u0026ldquo;origin\u0026rdquo;, and the original repo as \u0026ldquo;upstream\u0026rdquo;. You won\u0026rsquo;t be able to push to the original repo, but you can push to your forked repo and then submit a pull request, as we\u0026rsquo;ll do below.\n    Option B: Clone the repo directly (direct access required)   Go to a dir that you would like to be the parent dir of the Biodash/Codeclub repo:\ncd my-dir   Clone the website repo:\ngit clone https://github.com/biodash/biodash.github.io.git # Using HTTPS # Or: `git clone git@github.com:biodash/biodash.github.io.git` using SSH   Create a new branch (by way of example called \u0026ldquo;my-branch\u0026rdquo;) and switch to it:\ngit checkout -b my-branch Creating a new branch is not strictly necessary but it may be safer/easier to experiment in.\n   2: Create a Code Club post   Here, we\u0026rsquo;ll use the hugodown package to create a Markdown skeleton for our post, and below we\u0026rsquo;ll also use hugodown to preview the site.\nNote that you can easily bypass hugodown by simply copying the YAML header from the first code club session (see here for the .Rmd file) into a new file and taking it from there.  If you don\u0026rsquo;t have the hugodown package installed, install it:\nremotes::install_github(\u0026#34;r-lib/hugodown\u0026#34;) # Or equivalently, use devtools::install_githhub()   A post bundle is a separate folder for a post which will hold the R Markdown file that contains the post, as well as associated images and so on. To create a post bundle along with a R Markdown file that already has many useful YAML header tags:\nhugodown::use_post(\u0026#39;codeclub/\u0026lt;session-number\u0026gt;_\u0026lt;short-title\u0026gt;\u0026#39;) # An example would be: hugodown::use_post(\u0026#39;codeclub/01_intro-to-R\u0026#39;) The \u0026lt;session-number\u0026gt; is the actual Code Club session number, and \u0026lt;short-title\u0026gt; is a short title that you would like to give the post, which will be used for links and the folder name.\n The name of the .Rmd file will be index.Rmd, and it should keep that name! Keep this name also if you create your .Rmd manually or by copying the file from another Code Club session. It will eventually turn into index.html, which is the name that will trigger the file to be displayed on the website.     Fill out some of the YAML, such as the title, subtitle, authors (in kebab-case, e.g. john-doe, to link to your author profile; note that Jelmer\u0026rsquo;s name here is \u0026ldquo;admin\u0026rdquo;), and optionally tags and summary (the summary will appear on Biodash\u0026rsquo;s front page in the \u0026ldquo;Recent Posts\u0026rdquo; widget; this can be good to fill out here because the default summary can be awkward, as it combines headers and paragraphs).\n If you specify a date using the `date` tag in the YAML, and this date is in the future (e.g. the date of the Code Club session), the page will not be built and will thus not appear on the website! Specifiying the date using `date` or `lastmod` in the YAML is not particularly useful anyway -- when you edit the post after the specified date, it will use the edit date.     Write the contents of your Code Club session that you would like to share with participants, in R Markdown format. For formatting tips, see below.\n   If you want participants to load an R Markdown file or script:\nAn easy solution is to place the file in the same directory as your post, and include it in your git commit, so it will be uploaded to Github. In that case, the URL to the file for direct downloads for participants will be: https://raw.githubusercontent.com/biodash/biodash.github.io/master/docs/codeclub/\u0026lt;session-number\u0026gt;_\u0026lt;short-title\u0026gt;/\u0026lt;filename\u0026gt;.\nIn your post, include a function call like file.download(\u0026lt;script-URL\u0026gt;) for participants to get the file \u0026ndash; this will work both for participants working locally and those working in an OSC RStudio Server instance.\nIf your session contains a dataset:\nLike for the markdown/script, place the file(s) in the same directory as your post. If you have a markdown/script for participants, include file.download(\u0026lt;dataset-URL\u0026gt;) in this file, otherwise include it directly in your post.\n    Convert your .Rmd (R Markdown) file to a .md (Markdown) file.\n Hugo renders .md but not .Rmd to HTML, so we have to always render to .md first when writing in .Rmd.   Since your output is specified as hugodown::md_document, this is done most easily by \u0026ldquo;knitting\u0026rdquo; your post in RStudio by clicking Knit in the top bar, or by pressing Ctrl + Shift + K.\n   3: Preview your post or build the website (optional) You can do this in two ways, from RStudio or from the command line.\nOption A: In RStudio   Install Hugo:\nhugodown::hugo_install(\u0026#34;0.66.0\u0026#34;)   Preview the website:\nhugodown::hugo_start() #\u0026gt; Starting server on port 1313 This will provide a preview RStudio. To look at it in a browser, go to localhost:1313, where 1313 corresponds to the port returned in the R console (see above).\n  Option B: From the command line   Install Hugo using these instructions.\n  Serve the website locally:\nhugo serve You will see a message that includes \u0026ldquo;Web Server is available at [\u0026hellip;]\u0026rdquo;. Click the link or copy and paste the address into a browser, and you will see the rendered website.\nThe server will keep running and will update whenever you save changes in a file that is within the website directory, until you stop it using Ctrl + C.\n   Side note: Building the website Note that you don\u0026rsquo;t need to build the website, because it will be built automatically from Markdown files whenever you push to (the master branch of) the Github repo.\nBut as background info, or in case automatic builds fail, here is how you would build the site:\n  Using Hugo from the shell:\nhugo -d docs/   Using hugodown in R:\nhugodown::hugo_build(dest = \u0026#34;docs\u0026#34;)   The entire rendered website is in the docs/ dir; HTML files rendered from Markdown files will be placed there, any images and other files will be copied there, and so on.\n   4: Commit   Add the files from your post:\ngit add codeclub/\u0026lt;your-post-name\u0026gt;/* ## Or, e.g. if you added files elswehere too, or have built the site: # git add *   Check if all your changes and new files have been staged:\ngit status   Commit:\ngit commit -m \u0026#34;Add CodeClub session \u0026lt;session-nr\u0026gt; by \u0026lt;your-name\u0026gt;\u0026#34;    5: Push or submit pull request Your Markdown (.md) file(s) will be built along with the rest of the website by Hugo. Using Github Actions, this will be done automatically upon pushing to the master branch on Github, which is all we need to do. Note that the built website will be committed by Github Actions not to the master branch but to the gh-actions branch.\nOption A: Create a pull request When you create a pull request, you are asking the maintainers of a repository to pull your changes into their repository.\n  Pull from the original repo to make sure your repo is up-to-date:\ngit pull upstream master # \u0026#34;upstream\u0026#34; refers to the original Github repo This will first fetch the upstream changes and then merge them into your local repo, thus keeping your local changes. If git does not manage to perform this merge automatically, which can happen if the same parts of the same files have been edited both locally and upstream, there will be a merge conflict which you will need to resolve manually.\n  Push to your forked repo:\ngit push origin master # \u0026#34;origin\u0026#34; refers to your forked Github repo   Create the pull request:\n Go to the Pull requests page of our repo at https://github.com/biodash/biodash.github.io/pulls. Click the green button on the right that says New pull request. Under the large Compare changes header, click Compare across forks. In the drop-down menu to the right of the arrow, select your fork. Enter a title (e.g. \u0026ldquo;New Post: Session 6\u0026quot;) and description (say a little more about the post) for the pull request. Click the green button Send pull request.    For a more detailed step-by-step of creating a pull request from a fork, see here.\nOption B: Push to the site repo (direct access required)   Merge your branch with the main (master) branch:\ngit checkout master # Move to the master branch prior to merging git merge my-branch # Merge into master (assuming your branch was named \u0026#34;my-branch\u0026#34;)   Push to the master branch:\ngit push origin master    6: Install packages at OSC (optional) Many R packages are already installed at OSC (nearly 200 for R 4.0.2), including the tidyverse. You can check which packages have been installed by typing, in an R session at OSC:\nlibrary() This will list packages by library, which should include two locations available to all OSC users (starting with /usr/local/R), your personal library, and the Code Club library (/fs/ess/PAS1838/CODECLUB/Rpkgs).\nIf you want to make another package available to Code Club participants, you can do so as follows in an RStudio Server session at OSC:\ninstall.packages(\u0026#34;\u0026lt;pkg-name\u0026gt;\u0026#34;, lib = \u0026#34;/fs/ess/PAS1838/CODECLUB/Rpkgs\u0026#34;) This library is available to all members of the Code Club OSC classroom project. To check specifically which packages are available in this library \u0026ndash; and whether your newly installed package has indeed been installed here, type:\nlibrary(lib.loc = \u0026#34;/fs/ess/PAS1838/CODECLUB/Rpkgs\u0026#34;) Alternatively, you can let participants working at OSC install the packages themselves, like participants that work locally will have to do.\n Formatting tips Miscellaneous   If you want a Table of Contents (TOC) for your file, add a line toc: true to the YAML (not indented, as it is not an option of the output format).\n  To add an image, put it in the same directory as the markdown file, and refer to it without prepending a path.\n  \u0026lt;br\u0026gt; will insert a line break, which can be useful to get more space between sections.\n  I add lines above each major section header using ---- (preceded by a \u0026lt;br\u0026gt;).\n  Add a line that reads source_extension: '.Rmd' (not indented) to your R Markdown, which will ensure that there is a link to the source document at the top of your post.\nEDIT: I have removed these source links for now. They were also visible in the \u0026ldquo;Recent Posts\u0026rdquo; widget on the home page, and some people clicked on that link rather than the website link. Then, they ended up on in the Github repo but didn\u0026rsquo;t even know they were in the wrong place since the contents of the post is present.\n  Hidden sections It can be useful to provide solutions to small challenges in the file, but to hide them by default. This can be done with a little HTML:\n\u0026lt;details\u0026gt; \u0026lt;summary\u0026gt; Solution (click here) \u0026lt;/summary\u0026gt; \u0026lt;br\u0026gt; ... Your solution - this can be a long section including a code block... ```{r} install.packages(\u0026quot;tidyverse\u0026quot;) ``` \u0026lt;/details\u0026gt; This is rendered as:\n  Solution (click here)  \u0026hellip; Your solution - this can be a long section including a code block\u0026hellip;\ninstall.packages(\u0026quot;tidyverse\u0026quot;)  Info/alert notes To produce boxes to draw attention to specific content, you can use two classes specific to the Hugo Academic Theme (now branded as \u0026ldquo;Wowchemy\u0026rdquo;).\n  alert-note for a blue box with an info symbol:\n\u0026lt;div class=\u0026quot;alert alert-note\u0026quot;\u0026gt; \u0026lt;div\u0026gt; This is an alert note. \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Which is rendered as:\n This is an alert note.     alert-warning for a red box with a warning symbol:\n\u0026lt;div class=\u0026quot;alert alert-warning\u0026quot;\u0026gt; \u0026lt;div\u0026gt; This is an alert warning. \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Which is rendered as:\n This is an alert warning.     I also added a custom class, puzzle:\n\u0026lt;div class=\u0026quot;alert puzzle\u0026quot;\u0026gt; \u0026lt;div\u0026gt; This is a puzzle div, for do-it-yourself challenges. \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  This is a puzzle div, for do-it-yourself challenges.   Custom classes and other custom formatting can be written in CSS in the assets/scss/custom.scss file.\n  All of these classes can also be called using pandoc\u0026rsquo;s ::: notation when you\u0026rsquo;re writing in .Rmd (but not if you\u0026rsquo;re writing in .md), e.g.:\n:::puzzle This is a puzzle div, for do-it-yourself challenges. :::   Code highlighting  Code highlighting doesn't work with out of the box with .Rmd files. But it should be possible to get it to work, stay tuned!   Hugo supports the highlighting of specific lines of code using the syntax below in md documents:\n```r {hl_lines=[1,\u0026quot;3-4\u0026quot;]} library(\u0026quot;tidyverse\u0026quot;) weight_df %\u0026gt;% mutate(mean_weight = mean(weight)) %\u0026gt;% select(mean_weight, everything()) dim(weight_df) ``` library(\u0026#34;tidyverse\u0026#34;) weight_df %\u0026gt;% mutate(mean_weight = mean(weight)) %\u0026gt;% select(mean_weight, everything()) dim(weight_df) Shortcodes  Like code highlighting, shortcodes only work with .md files. The blogdown package has a shortcode() function to support them (see here), but hugodown does not support them.   Hugo shortcodes are little code snippets for specific content. Some of these are specific to Wowchemy, and others are available for any Hugo site.\nHighlight text You can highlight text as follows:\nHere is some {{\u0026lt; hl \u0026gt;}}highlighted text{{\u0026lt; /hl \u0026gt;}}. This will render as:\nHere is some highlighted text.\nIcons Wowchemy supports shortcodes for icons, for instance:\n {{\u0026lt; icon name=\u0026#34;r-project\u0026#34; pack=\u0026#34;fab\u0026#34; \u0026gt;}}   {{\u0026lt; icon name=\u0026#34;python\u0026#34; pack=\u0026#34;fab\u0026#34; \u0026gt;}}   {{\u0026lt; icon name=\u0026#34;terminal\u0026#34; pack=\u0026#34;fas\u0026#34; \u0026gt;}} General Hugo shortcodes   To embed a Youtube video, use the following, replacing \u0026ldquo;videoID\u0026rdquo; by the actual ID (https://www.youtube.com/watch?v=ID) in\n{{\u0026lt; youtube ID \u0026gt;}}   To embed a Tweet, use the following, replacing \u0026ldquo;tweetID\u0026rdquo; by the actual ID (https://twitter.com/user/status/ID):\n{{\u0026lt; tweet ID \u0026gt;}}   For more info and more shortcodes, see the Hugo documentation on shortcodes.\n   \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629301641,"objectID":"d2a87fb5a2b4f8e331f2a7033b4ca3df","permalink":"https://biodash.github.io/codeclub-present/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-present/","section":"","summary":"Introduction   Each Code Club session should be represented by one post on the website at https://biodash.github.io/codeclub/.\n  Regular presenters will be given direct access to the Github repository and will be able to push a new post to the website directly.","tags":null,"title":"Information for Code Club Presenters","type":"page"},{"authors":null,"categories":null,"content":" Fall 2021 sessions This fall, we will meet on Thursdays at 3 pm through Zoom.\nSign up using the form or email Jelmer to get the Zoom link.\n   Session Date Presenter Topic (+ link) Topic block     21 Aug 26 Jelmer R basics \u0026ndash; part I Back to basics in R   22 Sep 2 Mike S. R basics \u0026ndash; part II Back to basics in R   23 Sep 9 Michael B. R Markdown Back to basics in R   24 Sep 16 Jessica Tidyverse intro \u0026ndash; part I Back to basics in R   25 Sep 23 Stephen Tidyverse intro \u0026ndash; part II Back to basics in R   26 Sep 30 Michael B. ggplot intro \u0026ndash; part I Plotting in R   27 Oct 07 Jelmer ggplot intro \u0026ndash; part II Plotting in R   28 Oct 14 Mike S. Faceting, animating, and combining plots Plotting in R   29 Oct 28 Jessica Interactive plots with Plotly Plotting in R   30 Nov 04 Daniel Quiroz Moreno (HCS) Adding statistical results to plots using ggpubr Plotting in R   31 Nov 11 Matthew Teegarden (FST) Shiny bright like a diamond: an intro to building interactive applications in R Putting code to practice   32 Nov 18 Julia Vrtilek (EEOB) Analysis of bat social vocalizations with R at OSC (date tentative) Putting code to practice   33 Dec 02 TBD TBD Putting code to practice   34 Dec 09 TBD TBD Putting code to practice    We have also included these sessions in the BioDASH calendar.\n Past sessions Season 1: \u0026lsquo;20-\u0026lsquo;21    Session nr. Date Presenter Topic (+ link) Other     1 Nov 18, 2020 Jelmer RStudio Projects \u0026amp; getting started slides   2 Dec 2, 2020 Jessica dplyr core verbs    3 Dec 9, 2020 Mike S. Joining datasets    4 Dec 16, 2020 Michael B. ggplot2 \u0026ndash; round 1    5 Jan 15, 2021 Jessica ggplot2 \u0026ndash; round 2    6 Jan 22, 2021 Stephen Factors    7 Jan 29, 2021 Jelmer R Markdown    8 Feb 5, 2021 Mike S. Pivoting data    9 Feb 12, 2021 Michael B. Subsetting data    10 Feb 19, 2021 Jessica Faceting, animating, and combining plots    11 Feb 26, 2021 Stephen Making maps with ggmap    12 Mar 5, 2021 Jelmer Vectorization and loops    13 Mar 12, 2021 Mike S. The apply family of functions    14 Mar 19, 2021 Michael B. Writing your own functions    15 Mar 26, 2021 Jessica Interactive plots with Plotly    16 Apr 02, 2021 Stephen Working with dates with lubridate    17 Apr 09, 2021 Jelmer Introduction to regular expressions    18 Apr 16, 2021 Mike S. Regular Expressions: Part II    19 Apr 23, 2021 Michael B. Word Clouds via tidytext    20 Apr 30, 2021 Jessica Cleaning up variables names        \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629403239,"objectID":"21036bb90326781dbc3f5f76a5396fb3","permalink":"https://biodash.github.io/codeclub-schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-schedule/","section":"","summary":"Fall 2021 sessions This fall, we will meet on Thursdays at 3 pm through Zoom.\nSign up using the form or email Jelmer to get the Zoom link.\n   Session Date Presenter Topic (+ link) Topic block     21 Aug 26 Jelmer R basics \u0026ndash; part I Back to basics in R   22 Sep 2 Mike S.","tags":null,"title":"Schedule for Code Club","type":"page"},{"authors":null,"categories":null,"content":" Please use the form below to suggest a topic or concept to be covered at Code Club. You are also welcome to leave a suggestion relating to the general format, organization, or presentation of Code Club.\nIf you suggest a topic, a broad range of suggestions are welcome \u0026ndash; it need not fit neatly as a single Code Club session. So your suggestion can be as broad as \u0026ldquo;object-oriented programming\u0026rdquo; or as specific as a single R function that you happen to struggle with or that you just really like.\nLoading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629301641,"objectID":"aa47a17260af4b87dc29397d821ae7fd","permalink":"https://biodash.github.io/codeclub-suggest/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-suggest/","section":"","summary":"Please use the form below to suggest a topic or concept to be covered at Code Club. You are also welcome to leave a suggestion relating to the general format, organization, or presentation of Code Club.","tags":null,"title":"Suggest a Topic for Code Club!","type":"page"}]